{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # Optional: for heatmap styling\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Define window size\n",
        "window_size = 15  # Approximately 15 data points for 0.5 seconds\n",
        "\n",
        "# Initialize lists to store windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "# Segment the time-series data into windows\n",
        "for i in range(0, len(data) - window_size + 1, window_size):\n",
        "    window = data.iloc[i:i + window_size]\n",
        "    if len(window) == window_size:  # Ensure the window is complete\n",
        "        # Extract features from the window\n",
        "        window_features = {\n",
        "            'mean_acc_x': window['acc_x'].mean(),\n",
        "            'mean_acc_y': window['acc_y'].mean(),\n",
        "            'mean_acc_z': window['acc_z'].mean(),\n",
        "            'std_acc_x': window['acc_x'].std(),\n",
        "            'std_acc_y': window['acc_y'].std(),\n",
        "            'std_acc_z': window['acc_z'].std(),\n",
        "            'skew_acc_x': window['acc_x'].skew(),\n",
        "            'skew_acc_y': window['acc_y'].skew(),\n",
        "            'skew_acc_z': window['acc_z'].skew(),\n",
        "            'kurt_acc_x': window['acc_x'].kurt(),\n",
        "            'kurt_acc_y': window['acc_y'].kurt(),\n",
        "            'kurt_acc_z': window['acc_z'].kurt()\n",
        "        }\n",
        "        windowed_features.append(window_features)\n",
        "\n",
        "        # Assign label to the window (assuming it's the same for all samples within the window)\n",
        "        window_label = window['behavior'].iloc[0]  # Adjust based on your specific label\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X_windowed = pd.DataFrame(windowed_features)\n",
        "y_windowed = np.array(windowed_labels)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_windowed)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_windowed)\n",
        "\n",
        "# Split the data into train and test using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize a list to store accuracy results\n",
        "accuracies = []\n",
        "\n",
        "# Perform 10 iterations\n",
        "for i in range(1):\n",
        "    # Instantiate Random Forest classifier with random subspace\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "    # Train the Random Forest classifier\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the Random Forest model's performance\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "    # Gini score calculation\n",
        "    def gini_score(y_true, y_pred):\n",
        "        true_positive_rate = recall_score(y_true, y_pred, average='weighted')\n",
        "        false_positive_rate = 1 - precision_score(y_true, y_pred, average='weighted')\n",
        "        return 2 * (true_positive_rate - false_positive_rate)\n",
        "\n",
        "    gini = gini_score(y_test, y_pred_rf)\n",
        "\n",
        "    accuracies.append(accuracy_rf)\n",
        "    print(f\"Accuracy on test data (Random Forest with 0.5-second window size) for iteration {i + 1}: {accuracy_rf * 100:.2f}%\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"Gini Score: {gini:.2f}\")\n",
        "\n",
        "# Print average accuracy over all iterations\n",
        "print(f\"Average Accuracy over 10 iterations: {np.mean(accuracies) * 100:.2f}%\")\n",
        "\n",
        "# Plot confusion matrix for the last iteration\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Get the unique labels and their corresponding encoded values\n",
        "unique_labels, label_encoding = np.unique(y_windowed, return_inverse=True)\n",
        "\n",
        "# Print the unique labels with their corresponding numbers\n",
        "for i, label in enumerate(unique_labels):\n",
        "    print(f\"Encoded label {i} corresponds to behavior: {label}\")\n"
      ],
      "metadata": {
        "id": "Gd_opSj2D6L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Plot confusion matrix for the last iteration\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Normalize the confusion matrix by dividing by the sum of each row to get percentages\n",
        "conf_matrix_percentage = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "# Plot the normalized confusion matrix with percentages\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_percentage, annot=True, fmt='.2f', cmap='Blues',\n",
        "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (in Percentages)')\n",
        "plt.show()\n",
        "\n",
        "# Get the unique labels and their corresponding encoded values\n",
        "unique_labels, label_encoding = np.unique(y_windowed, return_inverse=True)\n",
        "\n",
        "# Print the unique labels with their corresponding numbers\n",
        "for i, label in enumerate(unique_labels):\n",
        "    print(f\"Encoded label {i} corresponds to behavior: {label}\")"
      ],
      "metadata": {
        "id": "Ic_sDycNtMjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KTwr5s3AyTVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Mbop_AeotG-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate Gini score from predicted probabilities\n",
        "def gini_score(y_true, y_pred_proba):\n",
        "    \"\"\"\n",
        "    Gini score calculation based on predicted probabilities for binary classification.\n",
        "    :param y_true: True labels\n",
        "    :param y_pred_proba: Predicted probabilities for the positive class\n",
        "    :return: Gini coefficient score\n",
        "    \"\"\"\n",
        "    # Sort the true values and predictions by predicted probabilities\n",
        "    sorted_indices = np.argsort(y_pred_proba)\n",
        "    sorted_y_true = np.array(y_true)[sorted_indices]\n",
        "\n",
        "\n",
        "# Assuming y_pred_proba is the predicted probabilities from RandomForest\n",
        "# Example usage (predicting probabilities instead of hard predictions):\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get predicted probabilities for the positive class (in binary classification)\n",
        "y_pred_proba_rf = rf_classifier.predict_proba(X_test)[:, 1]  # Only take probabilities of the positive class\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the Gini score using the predicted probabilities\n",
        "gini = gini_score(y_test, y_pred_proba_rf)\n",
        "\n",
        "# Calculate other metrics\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_rf * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "U-QGSugoZUqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# After making predictions\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Normalize the confusion matrix by converting counts to percentages\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False)\n",
        "\n",
        "plt.title(\"Confusion Matrix (in %)\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()\n",
        "\n",
        "# Get the unique labels and their corresponding encoded values\n",
        "unique_labels, label_encoding = np.unique(y_windowed, return_inverse=True)\n",
        "\n",
        "# Print the unique labels with their corresponding numbers\n",
        "for i, label in enumerate(unique_labels):\n",
        "    print(f\"Encoded label {i} corresponds to behavior: {label}\")\n"
      ],
      "metadata": {
        "id": "4cEruAWSYCSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Gini score calculation using AUC-ROC\n",
        "def gini_score(y_true, y_pred_proba):\n",
        "    # Calculate AUC-ROC score\n",
        "    auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n",
        "    # Gini coefficient is derived from AUC\n",
        "    return 2 * auc - 1\n",
        "\n",
        "# Perform 10 iterations\n",
        "for i in range(10):\n",
        "    # Instantiate Random Forest classifier with random subspace\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "    # Train the Random Forest classifier\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_rf = rf_classifier.predict(X_test)\n",
        "    y_pred_proba_rf = rf_classifier.predict_proba(X_test)  # Get predicted probabilities\n",
        "\n",
        "    # Evaluate the Random Forest model's performance\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "    # Calculate Gini score using predicted probabilities\n",
        "    gini = gini_score(y_test, y_pred_proba_rf)\n",
        "\n",
        "    accuracies.append(accuracy_rf)\n",
        "    print(f\"Accuracy on test data (Random Forest with 0.5-second window size) for iteration {i + 1}: {accuracy_rf * 100:.2f}%\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"Gini Score: {gini:.2f}\")\n",
        "\n",
        "# Print average accuracy over all iterations\n",
        "print(f\"Average Accuracy over 10 iterations: {np.mean(accuracies) * 100:.2f}%\")\n",
        "\n",
        "# Plot confusion matrix for the last iteration\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zm7CatNQZ51T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix for the last iteration\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4V13Ts_MbkOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix as percentages for the last iteration\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "conf_matrix_percent = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_percent, annot=True, fmt='.2f', cmap='Blues',\n",
        "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (Percentages)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "et1kLTuDbsgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # Optional: for heatmap styling\n",
        "\n",
        "# Define file names\n",
        "file_names = [\"cow1.csv\", \"cow2.csv\", \"cow3.csv\", \"cow4.csv\", \"cow5.csv\", \"cow6.csv\"]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "all_data = []\n",
        "\n",
        "# Iterate over each file and read them\n",
        "for file_name in file_names:\n",
        "    data = pd.read_csv(file_name)\n",
        "    all_data.append(data)\n",
        "\n",
        "# Concatenate all the data into one DataFrame\n",
        "combined_data = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# Define window size\n",
        "window_size = 15  # Approximately 15 data points for 0.5 seconds\n",
        "\n",
        "# Initialize lists to store windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "# Segment the time-series data into windows\n",
        "for i in range(0, len(combined_data) - window_size + 1, window_size):\n",
        "    window = combined_data.iloc[i:i + window_size]\n",
        "    if len(window) == window_size:  # Ensure the window is complete\n",
        "        # Extract features from the window\n",
        "        window_features = {\n",
        "            'mean_acc_x': window['AccX'].mean(),\n",
        "            'mean_acc_y': window['AccY'].mean(),\n",
        "            'mean_acc_z': window['AccZ'].mean(),\n",
        "            'std_acc_x': window['AccX'].std(),\n",
        "            'std_acc_y': window['AccY'].std(),\n",
        "            'std_acc_z': window['AccZ'].std(),\n",
        "            'skew_acc_x': window['AccX'].skew(),\n",
        "            'skew_acc_y': window['AccY'].skew(),\n",
        "            'skew_acc_z': window['AccZ'].skew(),\n",
        "            'kurt_acc_x': window['AccX'].kurt(),\n",
        "            'kurt_acc_y': window['AccY'].kurt(),\n",
        "            'kurt_acc_z': window['AccZ'].kurt()\n",
        "        }\n",
        "        windowed_features.append(window_features)\n",
        "\n",
        "        # Assign label to the window (assuming it's the same for all samples within the window)\n",
        "        window_label = window['Label'].iloc[0]\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X_windowed = pd.DataFrame(windowed_features)\n",
        "y_windowed = np.array(windowed_labels)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_windowed)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE with a reduced number of neighbors\n",
        "smote = SMOTE(random_state=42, k_neighbors=2)  # Reduce k_neighbors to 2\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_windowed)\n",
        "\n",
        "# Split the data into train and test using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize a list to store accuracy results\n",
        "accuracies = []\n",
        "\n",
        "# Gini score calculation using AUC-ROC\n",
        "def gini_score(y_true, y_pred_proba):\n",
        "    # Calculate AUC-ROC score\n",
        "    auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n",
        "    # Gini coefficient is derived from AUC\n",
        "    return 2 * auc - 1\n",
        "\n",
        "# Perform 1 iteration\n",
        "for i in range(1):\n",
        "    # Instantiate Random Forest classifier with random subspace\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "    # Train the Random Forest classifier\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_rf = rf_classifier.predict(X_test)\n",
        "    y_pred_proba_rf = rf_classifier.predict_proba(X_test)  # Get predicted probabilities\n",
        "\n",
        "    # Evaluate the Random Forest model's performance\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "    # Calculate Gini score using predicted probabilities\n",
        "    gini = gini_score(y_test, y_pred_proba_rf)\n",
        "\n",
        "    accuracies.append(accuracy_rf)\n",
        "    print(f\"Accuracy on test data (Random Forest with 0.5-second window size) for iteration {i + 1}: {accuracy_rf * 100:.2f}%\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"Gini Score: {gini:.2f}\")"
      ],
      "metadata": {
        "id": "rgUIf82IECF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Plot confusion matrix for the last iteration\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Normalize the confusion matrix by dividing by the sum of each row to get percentages\n",
        "conf_matrix_percentage = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "# Plot the normalized confusion matrix with percentages\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_percentage, annot=True, fmt='.2f', cmap='Blues',\n",
        "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (in Percentages)')\n",
        "plt.show()\n",
        "\n",
        "# Get the unique labels and their corresponding encoded values\n",
        "unique_labels, label_encoding = np.unique(y_windowed, return_inverse=True)\n",
        "\n",
        "# Print the unique labels with their corresponding numbers\n",
        "for i, label in enumerate(unique_labels):\n",
        "    print(f\"Encoded label {i} corresponds to behavior: {label}\")"
      ],
      "metadata": {
        "id": "k5xDP6agXn6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Calculate time difference\n",
        "time_diff = data['date'].diff().dropna()  # Drop NA values and calculate time difference\n",
        "\n",
        "# Calculate frequency (assuming uniform sampling)\n",
        "mean_time_diff = time_diff.mean()\n",
        "frequency = 1 / mean_time_diff.total_seconds()  # Convert to Hz\n",
        "\n",
        "print(\"Sampling frequency for combined data:\", frequency, \"Hz\")\n",
        "\n",
        "# Calculate window size based on frequency\n",
        "window_duration = 0.5  # Seconds\n",
        "window_size = int(frequency * window_duration)\n",
        "\n",
        "if window_size == 0:\n",
        "    print(\"Window size is zero, adjusting to 1\")\n",
        "    window_size = 1\n",
        "\n",
        "# Extract windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "for i in range(0, len(data), window_size):\n",
        "    window = data.iloc[i:i+window_size]\n",
        "    if len(window) == window_size:\n",
        "        # Compute mean values as features for this window\n",
        "        window_features = window.mean()\n",
        "        window_label = window['label'].iloc[0]\n",
        "        windowed_features.append(window_features)\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X = pd.DataFrame(windowed_features).drop(columns=['date'])  # Drop 'date' column for features\n",
        "y = np.array(windowed_labels)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test accuracy for combined data:\", accuracy * 100, \"%\")\n",
        "\n",
        "# Gini score calculation using AUC-ROC\n",
        "def gini_score(y_true, y_pred_proba):\n",
        "    # Calculate AUC-ROC score\n",
        "    auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n",
        "    # Gini coefficient is derived from AUC\n",
        "    return 2 * auc - 1\n",
        "\n",
        "# Perform 1 iteration\n",
        "for i in range(1):\n",
        "    # Instantiate Random Forest classifier with random subspace\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "    # Train the Random Forest classifier\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_rf = rf_classifier.predict(X_test)\n",
        "    y_pred_proba_rf = rf_classifier.predict_proba(X_test)  # Get predicted probabilities\n",
        "\n",
        "    # Evaluate the Random Forest model's performance\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "    # Calculate Gini score using predicted probabilities\n",
        "    gini = gini_score(y_test, y_pred_proba_rf)\n",
        "\n",
        "    accuracies.append(accuracy_rf)\n",
        "    print(f\"Accuracy on test data (Random Forest with 0.5-second window size) for iteration {i + 1}: {accuracy_rf * 100:.2f}%\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"Gini Score: {gini:.2f}\")"
      ],
      "metadata": {
        "id": "sKNktAVoED4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"dataset_6.csv\")\n",
        "\n",
        "# Define window size\n",
        "window_size = 15  # Approximately 15 data points for 0.5 seconds\n",
        "\n",
        "# Initialize lists to store windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "# Segment the time-series data into windows\n",
        "for i in range(0, len(data) - window_size + 1, window_size):\n",
        "    window = data.iloc[i:i + window_size]\n",
        "    if len(window) == window_size:  # Ensure the window is complete\n",
        "        # Extract features from the window\n",
        "        window_features = {\n",
        "            'mean_acc_x': window['acc_x'].mean(),\n",
        "            'mean_acc_y': window['acc_y'].mean(),\n",
        "            'mean_acc_z': window['acc_z'].mean(),\n",
        "            'std_acc_x': window['acc_x'].std(),\n",
        "            'std_acc_y': window['acc_y'].std(),\n",
        "            'std_acc_z': window['acc_z'].std(),\n",
        "            'skew_acc_x': window['acc_x'].skew(),\n",
        "            'skew_acc_y': window['acc_y'].skew(),\n",
        "            'skew_acc_z': window['acc_z'].skew(),\n",
        "            'kurt_acc_x': window['acc_x'].kurt(),\n",
        "            'kurt_acc_y': window['acc_y'].kurt(),\n",
        "            'kurt_acc_z': window['acc_z'].kurt()\n",
        "        }\n",
        "        windowed_features.append(window_features)\n",
        "\n",
        "        # Assign label to the window (assuming it's the same for all samples within the window)\n",
        "        window_label = window['label'].iloc[0]\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X_windowed = pd.DataFrame(windowed_features)\n",
        "y_windowed = np.array(windowed_labels)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_windowed)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_windowed)\n",
        "\n",
        "# Split the data into train and test using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "accuracies = []\n",
        "\n",
        "# Perform 10 iterations\n",
        "for i in range(10):\n",
        "    # Instantiate Random Forest classifier with random subspace\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "    # Train the Random Forest classifier\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the Random Forest model's performance\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "    accuracies.append(accuracy_rf)\n",
        "    f1_scores.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "    print(f\"Iteration {i + 1}:\")\n",
        "    print(f\"  Accuracy: {accuracy_rf * 100:.2f}%\")\n",
        "    print(f\"  F1 Score: {f1:.2f}\")\n",
        "    print(f\"  Precision: {precision:.2f}\")\n",
        "    print(f\"  Recall: {recall:.2f}\")\n",
        "\n",
        "# Print average metrics\n",
        "print(\"\\nAverage Metrics over 10 iterations:\")\n",
        "print(f\"  Average Accuracy: {np.mean(accuracies) * 100:.2f}%\")\n",
        "print(f\"  Average F1 Score: {np.mean(f1_scores):.2f}\")\n",
        "print(f\"  Average Precision: {np.mean(precisions):.2f}\")\n",
        "print(f\"  Average Recall: {np.mean(recalls):.2f}\")\n",
        "\n",
        "# Plot confusion matrix for the last iteration\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BFnX-KMaED_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Plot confusion matrix for the last iteration\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Normalize the confusion matrix by dividing by the sum of each row to get percentages\n",
        "conf_matrix_percentage = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "# Plot the normalized confusion matrix with percentages\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_percentage, annot=True, fmt='.2f', cmap='Blues',\n",
        "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (in Percentages)')\n",
        "plt.show()\n",
        "\n",
        "# Get the unique labels and their corresponding encoded values\n",
        "unique_labels, label_encoding = np.unique(y_windowed, return_inverse=True)\n",
        "\n",
        "# Print the unique labels with their corresponding numbers\n",
        "for i, label in enumerate(unique_labels):\n",
        "    print(f\"Encoded label {i} corresponds to behavior: {label}\")"
      ],
      "metadata": {
        "id": "TRb7vfAB10xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # Optional: for heatmap styling\n",
        "# Gini score calculation using AUC-ROC\n",
        "def gini_score(y_true, y_pred_proba):\n",
        "    # Calculate AUC-ROC score\n",
        "    auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n",
        "    # Gini coefficient is derived from AUC\n",
        "    return 2 * auc - 1\n",
        "\n",
        "# Perform 1 iteration\n",
        "for i in range(1):\n",
        "    # Instantiate Random Forest classifier with random subspace\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "    # Train the Random Forest classifier\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_rf = rf_classifier.predict(X_test)\n",
        "    y_pred_proba_rf = rf_classifier.predict_proba(X_test)  # Get predicted probabilities\n",
        "\n",
        "    # Evaluate the Random Forest model's performance\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "    # Calculate Gini score using predicted probabilities\n",
        "    gini = gini_score(y_test, y_pred_proba_rf)\n",
        "\n",
        "    print(f\"Gini Score: {gini:.2f}\")"
      ],
      "metadata": {
        "id": "4PtlssobgWa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the dataset (replace 'CURC.csv' with your actual file path)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Convert the 'Time' column to datetime format (assuming Time is in HH:MM:SS format)\n",
        "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S').dt.time\n",
        "\n",
        "# Define a larger window size in seconds\n",
        "window_size_seconds = 6  # Adjust this value as needed\n",
        "window_size_samples = window_size_seconds  # 6 seconds = 6 data points\n",
        "\n",
        "# Initialize lists to store windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "# Segment the time-series data into windows\n",
        "for i in range(0, len(data) - window_size_samples + 1, window_size_samples):\n",
        "    window = data.iloc[i:i + window_size_samples]\n",
        "    if len(window) == window_size_samples:  # Ensure the window is complete\n",
        "        # Extract features from the window\n",
        "        window_features = {\n",
        "            'mean_x': window['X-axis (g)'].mean(),\n",
        "            'mean_y': window['Y-axis (g)'].mean(),\n",
        "            'mean_z': window['Z-axis (g)'].mean(),\n",
        "            'std_x': window['X-axis (g)'].std(),\n",
        "            'std_y': window['Y-axis (g)'].std(),\n",
        "            'std_z': window['Z-axis (g)'].std(),\n",
        "            'skew_x': window['X-axis (g)'].skew(),\n",
        "            'skew_y': window['Y-axis (g)'].skew(),\n",
        "            'skew_z': window['Z-axis (g)'].skew(),\n",
        "            'kurt_x': window['X-axis (g)'].kurt(),\n",
        "            'kurt_y': window['Y-axis (g)'].kurt(),\n",
        "            'kurt_z': window['Z-axis (g)'].kurt()\n",
        "        }\n",
        "        windowed_features.append(window_features)\n",
        "\n",
        "        # Assign labels to the window based on 'IteragreementLocom' and 'IteragreementFeeding'\n",
        "        locomotion_label = window['IteragreementLocom'].mode().iloc[0]\n",
        "        feeding_label = window['IteragreementFeeding'].mode().iloc[0]\n",
        "        combined_label = f\"{locomotion_label}{feeding_label}\"\n",
        "        windowed_labels.append(combined_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X_windowed = pd.DataFrame(windowed_features)\n",
        "y_windowed = np.array(windowed_labels)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_windowed)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_windowed)\n",
        "\n",
        "# Split the data into train and test using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "gini_scores = []\n",
        "\n",
        "# Gini score calculation using AUC-ROC\n",
        "def gini_score(y_true, y_pred_proba):\n",
        "    if y_pred_proba.ndim == 1:  # Binary classification\n",
        "        auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    else:  # Multi-class classification\n",
        "        auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n",
        "    return 2 * auc - 1\n",
        "\n",
        "# Perform 10 iterations\n",
        "for i in range(10):\n",
        "    # Instantiate Random Forest classifier with random subspace\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "    # Train the Random Forest classifier\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_rf = rf_classifier.predict(X_test)\n",
        "    y_pred_proba_rf = rf_classifier.predict_proba(X_test)  # Get predicted probabilities\n",
        "\n",
        "    # Evaluate the Random Forest model's performance\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "    # Calculate Gini score using predicted probabilities\n",
        "    gini = gini_score(y_test, y_pred_proba_rf)\n",
        "\n",
        "    # Append metrics to lists\n",
        "    accuracies.append(accuracy_rf)\n",
        "    f1_scores.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    gini_scores.append(gini)\n",
        "\n",
        "    print(f\"Iteration {i + 1}:\")\n",
        "    print(f\"  Accuracy: {accuracy_rf * 100:.2f}%\")\n",
        "    print(f\"  F1 Score: {f1:.2f}\")\n",
        "    print(f\"  Precision: {precision:.2f}\")\n",
        "    print(f\"  Recall: {recall:.2f}\")\n",
        "    print(f\"  Gini Score: {gini:.2f}\")\n",
        "\n",
        "# Print average metrics\n",
        "print(\"\\nAverage Metrics over 10 iterations:\")\n",
        "print(f\"  Average Accuracy: {np.mean(accuracies) * 100:.2f}%\")\n",
        "print(f\"  Average F1 Score: {np.mean(f1_scores):.2f}\")\n",
        "print(f\"  Average Precision: {np.mean(precisions):.2f}\")\n",
        "print(f\"  Average Recall: {np.mean(recalls):.2f}\")\n",
        "print(f\"  Average Gini Score: {np.mean(gini_scores):.2f}\")\n"
      ],
      "metadata": {
        "id": "j4Ne22NcDx3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# After making predictions\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Normalize the confusion matrix by converting counts to percentages\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False)\n",
        "\n",
        "plt.title(\"Confusion Matrix (in %)\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gGbiOeErW457"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np  # Make sure to import numpy as well\n",
        "\n",
        "# After making predictions\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Normalize the confusion matrix by converting counts to percentages\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})  # Increase annotation size\n",
        "plt.xlabel(\"Predicted Labels\", fontsize=16)  # Increase x-axis label size\n",
        "plt.ylabel(\"True Labels\", fontsize=16)      # Increase y-axis label size\n",
        "plt.xticks(fontsize=14)  # Increase x-axis ticks size\n",
        "plt.yticks(fontsize=14)  # Increase y-axis ticks size\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iFuuXWcPZYhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Example normalized confusion matrix values (replace these with your own)\n",
        "cm_normalized = np.array(\n",
        "    [89.06, 7.81, 3.12],\n",
        "    [21.54, 70.77, 7.69],\n",
        "    [0.00, 1.54, 98.46,\n",
        "    [0.00, 1.54, 98.46]\n",
        "])\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})  # Increase annotation size\n",
        "plt.xlabel(\"Predicted Labels\", fontsize=16)  # Increase x-axis label size\n",
        "plt.ylabel(\"True Labels\", fontsize=16)      # Increase y-axis label size\n",
        "plt.xticks(fontsize=14)  # Increase x-axis ticks size\n",
        "plt.yticks(fontsize=14)  # Increase y-axis ticks size\n",
        "\n",
        "# Make the plot more aesthetically pleasing\n",
        "plt.title(\"Normalized Confusion Matrix\", fontsize=18, fontweight='bold')\n",
        "plt.tight_layout()  # Adjust layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1uGb784Ws09Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Normalized confusion matrix values (replace these with your own)\n",
        "cm_normalized = np.array([\n",
        "    [89.06, 7.81, 3.12],\n",
        "    [21.54, 70.77, 7.69],\n",
        "    [0.00, 1.54, 98.46]\n",
        "])\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 16})  # Increase annotation size\n",
        "plt.xlabel(\"Predicted Labels\", fontsize=16, fontweight='bold')  # Increase x-axis label size\n",
        "plt.ylabel(\"True Labels\", fontsize=16, fontweight='bold')      # Increase y-axis label size\n",
        "plt.xticks(fontsize=14)  # Increase x-axis ticks size\n",
        "plt.yticks(fontsize=14)  # Increase y-axis ticks size\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nFJ6ZNYbtQ7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Normalized confusion matrix values (replace these with your own)\n",
        "cm_normalized = np.array([\n",
        "    [89.06, 7.81, 3.12],\n",
        "    [21.54, 70.77, 7.69],\n",
        "    [0.00, 1.54, 98.46]\n",
        "])\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 20, \"weight\": \"bold\"})  # Increase annotation size and bold\n",
        "plt.xlabel(\"Predicted Labels\", fontsize=20, fontweight='bold')  # Increase x-axis label size and bold\n",
        "plt.ylabel(\"True Labels\", fontsize=20, fontweight='bold')      # Increase y-axis label size and bold\n",
        "plt.xticks(fontsize=14, fontweight='bold')  # Increase x-axis ticks size and bold\n",
        "plt.yticks(fontsize=14, fontweight='bold')  # Increase y-axis ticks size and bold\n",
        "\n",
        "\n",
        "plt.tight_layout()  # Adjust layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AiHWBKK3rcYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Normalized confusion matrix values (replace these with your own)\n",
        "cm_normalized = np.array([\n",
        "    [89.06, 7.81, 3.12],\n",
        "    [21.54, 70.77, 7.69],\n",
        "    [0.00, 1.54, 98.46]\n",
        "])\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    cm_normalized,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"Blues\",\n",
        "    cbar=False,\n",
        "    annot_kws={\"size\": 20, \"weight\": \"bold\"},  # Increase annotation size and bold\n",
        "    linewidths=1.5,  # Width of the borders around each cell\n",
        "    linecolor='black'  # Color of the borders\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Predicted Labels\", fontsize=20, fontweight='bold')  # Increase x-axis label size and bold\n",
        "plt.ylabel(\"True Labels\", fontsize=20, fontweight='bold')      # Increase y-axis label size and bold\n",
        "plt.xticks(fontsize=20, fontweight='bold')  # Set x-axis ticks size to 20 and bold\n",
        "plt.yticks(fontsize=20, fontweight='bold')  # Set y-axis ticks size to 20 and bold\n",
        "\n",
        "\n",
        "plt.tight_layout()  # Adjust layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X7vmQMB3uCpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Normalized confusion matrix values (replace these with your own)\n",
        "cm_normalized = np.array([\n",
        "    [89.06, 7.81, 3.12],\n",
        "    [21.54, 70.77, 7.69],\n",
        "    [0.00, 1.54, 98.46]\n",
        "])\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    cm_normalized,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"Blues\",\n",
        "    cbar=False,\n",
        "    annot_kws={\"size\": 20, \"weight\": \"bold\"},  # Increase annotation size and bold\n",
        "    linewidths=2.5,  # Width of the borders around each cell\n",
        "    linecolor='black',  # Color of the borders\n",
        "    square=True  # Makes cells square-shaped\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Predicted Labels\", fontsize=20, fontweight='bold')  # Increase x-axis label size and bold\n",
        "plt.ylabel(\"True Labels\", fontsize=20, fontweight='bold')      # Increase y-axis label size and bold\n",
        "plt.xticks(fontsize=20, fontweight='bold')  # Set x-axis ticks size to 20 and bold\n",
        "plt.yticks(fontsize=20, fontweight='bold')  # Set y-axis ticks size to 20 and bold\n",
        "\n",
        "# Make the plot more aesthetically pleasing\n",
        "plt.title(\"Normalized Confusion Matrix\", fontsize=20, fontweight='bold')  # Bold title with font size 20\n",
        "plt.tight_layout()  # Adjust layout\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PMQgyeOAuQ7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique labels and their corresponding encoded values\n",
        "unique_labels, label_encoding = np.unique(y_windowed, return_inverse=True)\n",
        "\n",
        "# Print the unique labels with their corresponding numbers\n",
        "for i, label in enumerate(unique_labels):\n",
        "    print(f\"Encoded label {i} corresponds to behavior: {label}\")\n"
      ],
      "metadata": {
        "id": "-Xhg5qTMWasG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "model_accuracies = [92.72, 93.41, 99.97, 90.17, 86.08]\n",
        "published_accuracies = [85.67, 94.43, \"NA\", 87.15, \"NA\"]\n",
        "\n",
        "# Filter out 'NA' values\n",
        "filtered_published_accuracies = [acc if acc != 'NA' else None for acc in published_accuracies]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Plot model accuracies with solid color\n",
        "bars_model = plt.bar(index, model_accuracies, bar_width, label='Model Accuracy', color='skyblue', edgecolor='black', hatch='')\n",
        "\n",
        "# Plot published accuracies with dashed color\n",
        "bars_published = plt.bar([i + bar_width for i in index if published_accuracies[i] != 'NA'],\n",
        "                         [acc for acc in filtered_published_accuracies if acc is not None],\n",
        "                         bar_width, label='Published Accuracy', color='lightgreen', edgecolor='black', hatch='//')\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Comparison of Model and Published Accuracies Across Datasets')\n",
        "\n",
        "# Align x-axis labels with bars\n",
        "plt.xticks([i + bar_width / 2 for i in index], datasets)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# Annotate bars with values\n",
        "for bar in bars_model:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5, f\"{yval:.2f}%\", ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "for bar in bars_published:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5, f\"{yval:.2f}%\", ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1GDBXhE9ioZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = [\n",
        "    '1',\n",
        "    '2',\n",
        "    '3',\n",
        "    '4',\n",
        "    '5'\n",
        "]\n",
        "f1_scores = [0.93, 0.93, 1, 0.90, 0.86]\n",
        "gini_scores = [0.98, 0.99, 1, 0.98, 0.92]\n",
        "precision_scores = [0.93, 0.93, 1, 0.90, 0.86]\n",
        "recall_scores = [0.93, 0.93, 1, 0.90, 0.86]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "bar_width = 0.2\n",
        "index = range(len(datasets))\n",
        "\n",
        "bars1 = plt.bar([i + 2 * bar_width for i in index], f1_scores, bar_width, label='F1 Score', color='orange')\n",
        "bars2 = plt.bar([i + 3 * bar_width for i in index], gini_scores, bar_width, label='Gini Score', color='lightblue')\n",
        "bars3 = plt.bar([i + 4 * bar_width for i in index], precision_scores, bar_width, label='Precision', color='pink')\n",
        "bars4 = plt.bar([i + 5 * bar_width for i in index], recall_scores, bar_width, label='Recall', color='lightcoral')\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks([i + 2.5 * bar_width for i in index], datasets, rotation=45, ha='right')\n",
        "\n",
        "# Annotate bars with values\n",
        "def autolabel(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.annotate(f'{height:.3f}',\n",
        "                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                     xytext=(0, 3),\n",
        "                     textcoords=\"offset points\",\n",
        "                     ha='center', va='bottom')\n",
        "\n",
        "autolabel(bars1)\n",
        "autolabel(bars2)\n",
        "autolabel(bars3)\n",
        "autolabel(bars4)\n",
        "\n",
        "\n",
        "# Set y-axis limits to focus on 85% to 100%\n",
        "plt.ylim(0.7, 1)\n",
        "\n",
        "# Move legend outside the plot\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), shadow=True, ncol=2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jzhoGd1ZijyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "f1_scores = [0.93, 0.93, 1, 0.90, 0.86]\n",
        "gini_scores = [0.98, 0.99, 1, 0.98, 0.92]\n",
        "precision_scores = [0.93, 0.93, 1, 0.90, 0.86]\n",
        "recall_scores = [0.93, 0.93, 1, 0.90, 0.86]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "bar_width = 0.15\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Adjusting bar positions\n",
        "bars1 = plt.bar([i - 1.5 * bar_width for i in index], f1_scores, bar_width, label='F1 Score', color='orange')\n",
        "bars2 = plt.bar([i - 0.5 * bar_width for i in index], gini_scores, bar_width, label='Gini Score', color='lightblue')\n",
        "bars3 = plt.bar([i + 0.5 * bar_width for i in index], precision_scores, bar_width, label='Precision', color='pink')\n",
        "bars4 = plt.bar([i + 1.5 * bar_width for i in index], recall_scores, bar_width, label='Recall', color='lightcoral')\n",
        "\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(index, datasets, rotation=45, ha='right')\n",
        "\n",
        "# Annotate bars with values\n",
        "def autolabel(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.annotate(f'{height:.3f}',\n",
        "                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                     xytext=(0, 3),\n",
        "                     textcoords=\"offset points\",\n",
        "                     ha='center', va='bottom')\n",
        "\n",
        "autolabel(bars1)\n",
        "autolabel(bars2)\n",
        "autolabel(bars3)\n",
        "autolabel(bars4)\n",
        "\n",
        "# Set y-axis limits to focus on 85% to 100%\n",
        "plt.ylim(0.7, 1)\n",
        "\n",
        "# Move legend outside the plot\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), shadow=True, ncol=2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DJtSwjdQkMhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '4', '5']\n",
        "grazing_acc = [91.64, 71.79, 89.06]\n",
        "walking_acc = [79.74, 74.87, 98.46]\n",
        "\n",
        "# Set up the bar width and figure size\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(datasets))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the bars for Grazing and Walking\n",
        "bars1 = plt.bar(index, grazing_acc, bar_width, label='Grazing Accuracy', color='skyblue')\n",
        "bars2 = plt.bar(index + bar_width, walking_acc, bar_width, label='Walking Accuracy', color='salmon')\n",
        "\n",
        "# Add labels and titles\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy of Grazing and Walking Behaviors for Datasets 1, 4, and 5')\n",
        "plt.xticks(index + bar_width / 2, datasets)\n",
        "\n",
        "# Annotate bars with values\n",
        "def autolabel(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.annotate(f'{height:.2f}%',\n",
        "                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                     xytext=(0, 3),  # Offset for label placement\n",
        "                     textcoords=\"offset points\",\n",
        "                     ha='center', va='bottom')\n",
        "\n",
        "autolabel(bars1)\n",
        "autolabel(bars2)\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-G79Uh7bkTRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '4', '5']\n",
        "grazing_acc = [91.64, 71.79, 89.06]\n",
        "walking_acc = [79.74, 74.87, 98.46]\n",
        "\n",
        "# Set up the bar width and figure size\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(datasets))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the bars for Grazing and Walking (with hatching for Walking)\n",
        "bars1 = plt.bar(index, grazing_acc, bar_width, label='Grazing Accuracy', color='skyblue')\n",
        "bars2 = plt.bar(index + bar_width, walking_acc, bar_width, label='Walking Accuracy', color='salmon', hatch='//')\n",
        "\n",
        "# Add labels and titles\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy of Grazing and Walking Behaviors for Datasets 1, 4, and 5')\n",
        "plt.xticks(index + bar_width / 2, datasets)\n",
        "\n",
        "# Annotate bars with values\n",
        "def autolabel(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.annotate(f'{height:.2f}%',\n",
        "                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                     xytext=(0, 3),  # Offset for label placement\n",
        "                     textcoords=\"offset points\",\n",
        "                     ha='center', va='bottom')\n",
        "\n",
        "autolabel(bars1)\n",
        "autolabel(bars2)\n",
        "\n",
        "# Move legend to upper middle\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=2)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1HWTg0b12YSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '4', '5']\n",
        "grazing_acc = [91.64, 71.79, 89.06]\n",
        "walking_acc = [79.74, 74.87, 98.46]\n",
        "\n",
        "# Set up the bar width and figure size\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(datasets))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the bars for Grazing and Walking (with hatching for Walking)\n",
        "bars1 = plt.bar(index, grazing_acc, bar_width, label='Grazing Accuracy', color='skyblue')\n",
        "bars2 = plt.bar(index + bar_width, walking_acc, bar_width, label='Walking Accuracy', color='salmon', hatch='//')\n",
        "\n",
        "# Add labels and titles\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy of Grazing and Walking Behaviors for Datasets 1, 4, and 5')\n",
        "plt.xticks(index + bar_width / 2, datasets)\n",
        "\n",
        "# Annotate bars with values\n",
        "def autolabel(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.annotate(f'{height:.2f}%',\n",
        "                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                     xytext=(0, 3),  # Offset for label placement\n",
        "                     textcoords=\"offset points\",\n",
        "                     ha='center', va='bottom')\n",
        "\n",
        "autolabel(bars1)\n",
        "autolabel(bars2)\n",
        "\n",
        "# Move legend slightly lower and keep it centered\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.95), ncol=2)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WEzctW373T3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '4', '5']\n",
        "grazing_acc = [91.64, 71.79, 89.06]\n",
        "walking_acc = [79.74, 74.87, 98.46]\n",
        "\n",
        "# Set up the bar width and figure size\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(datasets))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the bars for Grazing and Walking (with hatching for Walking)\n",
        "bars1 = plt.bar(index, grazing_acc, bar_width, label='Grazing Accuracy', color='skyblue')\n",
        "bars2 = plt.bar(index + bar_width, walking_acc, bar_width, label='Walking Accuracy', color='salmon', hatch='//')\n",
        "\n",
        "# Add labels and titles with increased font size\n",
        "plt.xlabel('Dataset', fontsize=14)\n",
        "plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "plt.xticks(index + bar_width / 2, datasets, fontsize=12)\n",
        "\n",
        "# Move legend slightly lower and keep it centered with increased font size\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.95), ncol=2, fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yvqNYvchh9Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '4', '5']\n",
        "grazing_acc = [91.64, 71.79, 89.06]\n",
        "walking_acc = [79.74, 74.87, 98.46]\n",
        "\n",
        "# Set up the bar width and figure size\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(datasets))\n",
        "\n",
        "# Define different colors for bars\n",
        "grazing_color = '#1f77b4'  # Grazing Accuracy\n",
        "walking_color = '#ff9999'  # Walking Accuracy\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create the bars for Grazing and Walking\n",
        "bars1 = plt.bar(index, grazing_acc, bar_width, label='Grazing Accuracy', color=grazing_color, edgecolor='black', linewidth=1.5)\n",
        "bars2 = plt.bar(index + bar_width, walking_acc, bar_width, label='Walking Accuracy', color=walking_color, edgecolor='black', linewidth=1.5, hatch='//')\n",
        "\n",
        "# Add labels and title with larger text and bold\n",
        "plt.xlabel('Dataset', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Accuracy (%)', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Adjust x-ticks and legend\n",
        "plt.xticks(index + bar_width / 2, datasets, fontsize=14)\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=2, fontsize=12)\n",
        "\n",
        "# Increase font size of y-ticks and make them bold\n",
        "plt.yticks(fontsize=14)\n",
        "\n",
        "# Remove grid lines\n",
        "plt.grid(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AvsXZX_uo2bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '4', '5']\n",
        "grazing_acc = [91.64, 71.79, 89.06]\n",
        "walking_acc = [79.74, 74.87, 98.46]\n",
        "\n",
        "# Set up the bar width and figure size\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(datasets))\n",
        "\n",
        "# Define lighter colors for bars\n",
        "grazing_color = '#a3c1e0'  # Light blue for Grazing Accuracy\n",
        "walking_color = '#ffcccc'   # Light pink for Walking Accuracy\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create the bars for Grazing and Walking\n",
        "bars1 = plt.bar(index, grazing_acc, bar_width, label='Grazing Accuracy', color=grazing_color, edgecolor='black', linewidth=1.5)\n",
        "bars2 = plt.bar(index + bar_width, walking_acc, bar_width, label='Walking Accuracy', color=walking_color, edgecolor='black', linewidth=1.5, hatch='//')\n",
        "\n",
        "# Add labels and title with larger text and bold\n",
        "plt.xlabel('Dataset', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Accuracy (%)', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Adjust x-ticks and legend\n",
        "plt.xticks(index + bar_width / 2, datasets, fontsize=14, fontweight='bold')\n",
        "plt.yticks(fontsize=14, fontweight='bold')\n",
        "\n",
        "# Move the legend down slightly\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.95), ncol=2, fontsize=12, frameon=True)\n",
        "\n",
        "# Remove grid lines\n",
        "plt.grid(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R0WHpEmspGwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '4', '5']\n",
        "grazing_acc = [91.64, 71.79, 89.06]\n",
        "walking_acc = [79.74, 74.87, 98.46]\n",
        "\n",
        "# Set up the bar width and figure size\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(datasets))\n",
        "\n",
        "# Define darker shades of blue and pink for bars\n",
        "grazing_color = '#87ceeb'  # Darker light blue for Grazing Accuracy\n",
        "walking_color = '#ff9999'   # Darker light pink for Walking Accuracy\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create the bars for Grazing and Walking\n",
        "bars1 = plt.bar(index, grazing_acc, bar_width, label='Grazing Accuracy', color=grazing_color, edgecolor='black', linewidth=1.5)\n",
        "bars2 = plt.bar(index + bar_width, walking_acc, bar_width, label='Walking Accuracy', color=walking_color, edgecolor='black', linewidth=1.5, hatch='//')\n",
        "\n",
        "# Add labels and title with larger text and bold\n",
        "plt.xlabel('Dataset', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Test Accuracy (%)', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Adjust x-ticks and legend\n",
        "plt.xticks(index + bar_width / 2, datasets, fontsize=14, fontweight='bold')\n",
        "plt.yticks(fontsize=14, fontweight='bold')\n",
        "\n",
        "# Move the legend down slightly\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.95), ncol=2, fontsize=12, frameon=True)\n",
        "\n",
        "# Remove grid lines\n",
        "plt.grid(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F4a8IAmmpQym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'CURC.csv' with your actual file)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Define the column that indicates grazing/feeding behavior (e.g., 'IteragreementFeeding' might label feeding)\n",
        "feeding_column = 'IteragreementFeeding'\n",
        "\n",
        "# Convert the 'IteragreementFeeding' column to numeric values (assuming 1 indicates grazing, 0 otherwise)\n",
        "data[feeding_column] = pd.to_numeric(data[feeding_column], errors='coerce')\n",
        "\n",
        "# Add a time column and convert it to datetime format (assuming 'Time' exists)\n",
        "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S')\n",
        "\n",
        "# Define daytime and nighttime hours (for example, day: 6 AM to 6 PM, night: 6 PM to 6 AM)\n",
        "day_start = pd.to_datetime(\"06:00:00\").time()\n",
        "day_end = pd.to_datetime(\"18:00:00\").time()\n",
        "\n",
        "# Create separate columns for day and night grazing\n",
        "data['is_daytime'] = data['Time'].apply(lambda x: day_start <= x.time() <= day_end)\n",
        "data['is_nighttime'] = ~data['is_daytime']\n",
        "\n",
        "# Calculate total daytime and nighttime grazing instances\n",
        "daytime_grazing_seconds = data[data['is_daytime']][feeding_column].sum()\n",
        "nighttime_grazing_seconds = data[data['is_nighttime']][feeding_column].sum()\n",
        "\n",
        "# Convert to hours\n",
        "daytime_grazing_hours = daytime_grazing_seconds / 3600\n",
        "nighttime_grazing_hours = nighttime_grazing_seconds / 3600\n",
        "\n",
        "# Assuming daytime and nighttime each last 12 hours\n",
        "day_duration_hours = 12\n",
        "night_duration_hours = 12\n",
        "\n",
        "# Calculate grazing percentages\n",
        "daytime_grazing_percentage = (daytime_grazing_hours / day_duration_hours) * 100\n",
        "nighttime_grazing_percentage = (nighttime_grazing_hours / night_duration_hours) * 100\n",
        "\n",
        "# Set thresholds based on the study\n",
        "daytime_threshold = 40  # 40% of the day\n",
        "nighttime_threshold = 16  # 16% of the night\n",
        "\n",
        "# Determine if overgrazing occurred during the day or night\n",
        "if daytime_grazing_percentage > daytime_threshold:\n",
        "    print(f\"Overgrazing detected during the day: Grazing {daytime_grazing_percentage:.2f}%, exceeding the {daytime_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"No overgrazing during the day: Grazing {daytime_grazing_percentage:.2f}%, within the {daytime_threshold}% threshold.\")\n",
        "\n",
        "if nighttime_grazing_percentage > nighttime_threshold:\n",
        "    print(f\"Overgrazing detected during the night: Grazing {nighttime_grazing_percentage:.2f}%, exceeding the {nighttime_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"No overgrazing during the night: Grazing {nighttime_grazing_percentage:.2f}%, within the {nighttime_threshold}% threshold.\")"
      ],
      "metadata": {
        "id": "imoSX_o1t17y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'CURC.csv' with your actual file)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Define the column that indicates grazing/feeding behavior (e.g., 'IteragreementFeeding' might label feeding)\n",
        "feeding_column = 'IteragreementFeeding'\n",
        "\n",
        "# Convert the 'IteragreementFeeding' column to numeric values (assuming 1 indicates grazing, 0 otherwise)\n",
        "# It seems the values in 'IteragreementFeeding' could contain categorical labels like \"EatingEating\" or \"otherother\".\n",
        "# We will convert \"EatingEating\" to 1 (indicating feeding), and others to 0 (non-feeding).\n",
        "data[feeding_column] = data[feeding_column].apply(lambda x: 1 if 'Eating' in x else 0)\n",
        "\n",
        "# Add a time column and convert it to datetime format (assuming 'Time' exists)\n",
        "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S')\n",
        "\n",
        "# Define daytime and nighttime hours (for example, day: 6 AM to 6 PM, night: 6 PM to 6 AM)\n",
        "day_start = pd.to_datetime(\"06:00:00\").time()\n",
        "day_end = pd.to_datetime(\"18:00:00\").time()\n",
        "\n",
        "# Create separate columns for day and night grazing\n",
        "data['is_daytime'] = data['Time'].apply(lambda x: day_start <= x.time() <= day_end)\n",
        "data['is_nighttime'] = ~data['is_daytime']\n",
        "\n",
        "# Calculate total daytime and nighttime grazing instances\n",
        "daytime_grazing_seconds = data[data['is_daytime']][feeding_column].sum()\n",
        "nighttime_grazing_seconds = data[data['is_nighttime']][feeding_column].sum()\n",
        "\n",
        "# Convert to hours\n",
        "daytime_grazing_hours = daytime_grazing_seconds / 3600\n",
        "nighttime_grazing_hours = nighttime_grazing_seconds / 3600\n",
        "\n",
        "# Assuming daytime and nighttime each last 12 hours\n",
        "day_duration_hours = 12\n",
        "night_duration_hours = 12\n",
        "\n",
        "# Calculate grazing percentages\n",
        "daytime_grazing_percentage = (daytime_grazing_hours / day_duration_hours) * 100\n",
        "nighttime_grazing_percentage = (nighttime_grazing_hours / night_duration_hours) * 100\n",
        "\n",
        "# Set thresholds based on the study\n",
        "daytime_threshold = 40  # 40% of the day\n",
        "nighttime_threshold = 16  # 16% of the night\n",
        "\n",
        "# Determine if overgrazing occurred during the day or night\n",
        "if daytime_grazing_percentage > daytime_threshold:\n",
        "    print(f\"Overgrazing detected during the day: Grazing {daytime_grazing_percentage:.2f}%, exceeding the {daytime_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"No overgrazing during the day: Grazing {daytime_grazing_percentage:.2f}%, within the {daytime_threshold}% threshold.\")\n",
        "\n",
        "if nighttime_grazing_percentage > nighttime_threshold:\n",
        "    print(f\"Overgrazing detected during the night: Grazing {nighttime_grazing_percentage:.2f}%, exceeding the {nighttime_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"No overgrazing during the night: Grazing {nighttime_grazing_percentage:.2f}%, within the {nighttime_threshold}% threshold.\")"
      ],
      "metadata": {
        "id": "izy6So4sjX5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'CURC.csv' with your actual file)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Define the column that indicates grazing/feeding behavior (e.g., 'IteragreementFeeding')\n",
        "feeding_column = 'IteragreementFeeding'\n",
        "\n",
        "# Map behavior strings to numeric values (assuming \"EatingEating\" means grazing)\n",
        "# Adjust this mapping if there are additional behaviors\n",
        "behavior_mapping = {\n",
        "    'EatingEating': 1,  # Grazing\n",
        "    'otherother': 0     # Not grazing\n",
        "}\n",
        "\n",
        "# Apply the mapping to the feeding column\n",
        "data[feeding_column] = data[feeding_column].map(behavior_mapping)\n",
        "\n",
        "# Convert 'Time' column to datetime if it's not already (assuming time in HH:MM:SS format)\n",
        "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S').dt.time\n",
        "\n",
        "# Define thresholds for grazing\n",
        "daytime_start = pd.to_datetime('06:00:00').time()  # 6 AM\n",
        "daytime_end = pd.to_datetime('18:00:00').time()    # 6 PM\n",
        "\n",
        "# Create boolean columns for daytime and nighttime grazing\n",
        "data['is_daytime'] = data['Time'].apply(lambda x: daytime_start <= x <= daytime_end)\n",
        "data['is_nighttime'] = ~data['is_daytime']\n",
        "\n",
        "# Check if 'IteragreementFeeding' has the correct 1's and 0's for grazing behavior\n",
        "print(\"Distribution of Grazing Behavior:\")\n",
        "print(data[feeding_column].value_counts())\n",
        "\n",
        "# Calculate daytime grazing (sum feeding during the day)\n",
        "daytime_grazing_seconds = data.loc[data['is_daytime'], feeding_column].sum()\n",
        "nighttime_grazing_seconds = data.loc[data['is_nighttime'], feeding_column].sum()\n",
        "\n",
        "# Convert to hours\n",
        "daytime_grazing_hours = daytime_grazing_seconds / 3600\n",
        "nighttime_grazing_hours = nighttime_grazing_seconds / 3600\n",
        "\n",
        "# Total day and night hours\n",
        "total_day_hours = 12  # 12 hours from 6 AM to 6 PM\n",
        "total_night_hours = 12\n",
        "\n",
        "# Thresholds (from the study)\n",
        "daytime_grazing_threshold = 0.40 * total_day_hours  # 40% of the daytime\n",
        "nighttime_grazing_threshold = 0.16 * total_night_hours  # 16% of the nighttime\n",
        "\n",
        "# Calculate percentages for grazing\n",
        "daytime_grazing_percentage = (daytime_grazing_seconds / (total_day_hours * 3600)) * 100\n",
        "nighttime_grazing_percentage = (nighttime_grazing_seconds / (total_night_hours * 3600)) * 100\n",
        "\n",
        "# Output grazing assessment\n",
        "if daytime_grazing_percentage > 40:\n",
        "    print(f\"Overgrazing during the day: Grazing {daytime_grazing_percentage:.2f}%, exceeding the 40% threshold.\")\n",
        "else:\n",
        "    print(f\"No overgrazing during the day: Grazing {daytime_grazing_percentage:.2f}%, within the 40% threshold.\")\n",
        "\n",
        "if nighttime_grazing_percentage > 16:\n",
        "    print(f\"Overgrazing during the night: Grazing {nighttime_grazing_percentage:.2f}%, exceeding the 16% threshold.\")\n",
        "else:\n",
        "    print(f\"No overgrazing during the night: Grazing {nighttime_grazing_percentage:.2f}%, within the 16% threshold.\")"
      ],
      "metadata": {
        "id": "zCyUqrJj2Q0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mu3B5X_Klyze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('dataset_6.csv')\n",
        "\n",
        "# Define thresholds based on the study\n",
        "daytime_grazing_threshold = 40  # 40% grazing during the day\n",
        "nighttime_grazing_threshold = 16  # 16% grazing during the night\n",
        "\n",
        "# Define behavior labels to be analyzed\n",
        "behavior_labels = ['Grazing', 'Walking']\n",
        "\n",
        "# Check if 'label' column exists\n",
        "if 'label' in data.columns:\n",
        "    # Count occurrences of each behavior\n",
        "    behavior_counts = data['label'].value_counts()\n",
        "\n",
        "    # Print the distribution of behaviors\n",
        "    print(\"Distribution of Behavior Labels:\")\n",
        "    print(behavior_counts)\n",
        "\n",
        "    # Calculate percentage of each behavior\n",
        "    total_records = data.shape[0]\n",
        "    behavior_percentages = (behavior_counts / total_records) * 100\n",
        "\n",
        "    # Print percentage of each behavior\n",
        "    print(\"\\nPercentage of Each Behavior:\")\n",
        "    for behavior in behavior_labels:\n",
        "        if behavior in behavior_percentages.index:\n",
        "            print(f\"{behavior}: {behavior_percentages[behavior]:.2f}%\")\n",
        "        else:\n",
        "            print(f\"{behavior}: 0.00%\")\n",
        "\n",
        "    # Check if behavior percentages meet the thresholds\n",
        "    if behavior_percentages.get('Grazing', 0) > daytime_grazing_threshold:\n",
        "        print(f\"Overgrazing detected: Grazing {behavior_percentages.get('Grazing', 0):.2f}%, exceeding the {daytime_grazing_threshold}% threshold.\")\n",
        "    else:\n",
        "        print(f\"No overgrazing detected: Grazing {behavior_percentages.get('Grazing', 0):.2f}%, within the {daytime_grazing_threshold}% threshold.\")\n",
        "\n",
        "    if behavior_percentages.get('Walking', 0) > nighttime_grazing_threshold:\n",
        "        print(f\"Excessive walking detected: Walking {behavior_percentages.get('Walking', 0):.2f}%, exceeding the {nighttime_grazing_threshold}% threshold.\")\n",
        "    else:\n",
        "        print(f\"No excessive walking detected: Walking {behavior_percentages.get('Walking', 0):.2f}%, within the {nighttime_grazing_threshold}% threshold.\")\n",
        "else:\n",
        "    raise KeyError(\"The column 'label' is missing in the dataset.\")"
      ],
      "metadata": {
        "id": "-t2euLWr401M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset (replace 'CURC.csv' with your actual file path)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Check available columns\n",
        "print(data.columns)\n",
        "\n",
        "# Combine relevant columns to create a behavior label\n",
        "# Assuming you want to combine locomotion and feeding behaviors\n",
        "data['Behavior'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Check the unique values in the 'Behavior' column\n",
        "print(data['Behavior'].value_counts())\n",
        "\n",
        "# Calculate the percentage of each behavior\n",
        "behavior_counts = data['Behavior'].value_counts()\n",
        "behavior_percentages = (behavior_counts / len(data)) * 100\n",
        "\n",
        "# Plot the distribution of behavior labels\n",
        "plt.figure(figsize=(10, 6))\n",
        "behavior_percentages.plot(kind='bar', color='skyblue')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Percentage (%)')\n",
        "plt.title('Distribution of Different Behaviors')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()  # Adjusts plot to fit labels and title\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JwJngFrs7Dq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset (replace 'CURC.csv' with your actual file path)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Combine relevant columns to create a behavior label\n",
        "# Assuming you want to combine locomotion and feeding behaviors\n",
        "data['Behavior'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Check the unique values in the 'Behavior' column\n",
        "print(data['Behavior'].value_counts())\n",
        "\n",
        "# Plot accelerometer data distributions for different behaviors\n",
        "\n",
        "# Set up the plotting area\n",
        "fig, axes = plt.subplots(3, 1, figsize=(12, 18))\n",
        "\n",
        "# Plot for X-axis (g)\n",
        "sns.boxplot(x='Behavior', y='X-axis (g)', data=data, ax=axes[0], palette='Set2')\n",
        "axes[0].set_title('Distribution of X-axis Acceleration by Behavior')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Plot for Y-axis (g)\n",
        "sns.boxplot(x='Behavior', y='Y-axis (g)', data=data, ax=axes[1], palette='Set2')\n",
        "axes[1].set_title('Distribution of Y-axis Acceleration by Behavior')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Plot for Z-axis (g)\n",
        "sns.boxplot(x='Behavior', y='Z-axis (g)', data=data, ax=axes[2], palette='Set2')\n",
        "axes[2].set_title('Distribution of Z-axis Acceleration by Behavior')\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7M2zxJUM7bhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Ensure columns are present in the data\n",
        "required_columns = ['X-axis (g)', 'Y-axis (g)', 'Z-axis (g)']\n",
        "for col in required_columns:\n",
        "    if col not in data.columns:\n",
        "        raise KeyError(f\"Column '{col}' is missing from the dataset.\")\n",
        "\n",
        "# Extract the relevant columns\n",
        "x = data['X-axis (g)']\n",
        "y = data['Y-axis (g)']\n",
        "z = data['Z-axis (g)']\n",
        "\n",
        "# Create a 3D scatter plot\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plotting the data points\n",
        "sc = ax.scatter(x, y, z, c='blue', marker='o', alpha=0.5)\n",
        "\n",
        "# Labeling the axes\n",
        "ax.set_xlabel('X-axis (g)')\n",
        "ax.set_ylabel('Y-axis (g)')\n",
        "ax.set_zlabel('Z-axis (g)')\n",
        "\n",
        "# Title and grid\n",
        "ax.set_title('3D Scatter Plot of Accelerometer Data')\n",
        "ax.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5i_6PTNy7l0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Create a 3D scatter plot for each behavior\n",
        "for behavior in behaviors:\n",
        "    # Filter data for the current behavior\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    # Check if there is data for this behavior\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    # Create a new figure for each behavior\n",
        "    fig = plt.figure(figsize=(12, 8))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Plotting the data points\n",
        "    sc = ax.scatter(x, y, z, marker='o', alpha=0.5)\n",
        "\n",
        "    # Labeling the axes\n",
        "    ax.set_xlabel('X-axis (g)')\n",
        "    ax.set_ylabel('Y-axis (g)')\n",
        "    ax.set_zlabel('Z-axis (g)')\n",
        "\n",
        "    # Title and grid\n",
        "    ax.set_title(f'3D Scatter Plot of Accelerometer Data for {behavior}')\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Wv-AEAWl8I0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Determine the number of subplots needed\n",
        "n_behaviors = len(behaviors)\n",
        "n_cols = 3  # Number of columns in the grid\n",
        "n_rows = (n_behaviors + n_cols - 1) // n_cols  # Number of rows needed\n",
        "\n",
        "# Create a figure with a grid of subplots\n",
        "fig = plt.figure(figsize=(5 * n_cols, 5 * n_rows))\n",
        "\n",
        "# Loop through each behavior and create a subplot for it\n",
        "for i, behavior in enumerate(behaviors):\n",
        "    # Filter data for the current behavior\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    # Check if there is data for this behavior\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    # Create a subplot\n",
        "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
        "\n",
        "    # Plotting the data points\n",
        "    sc = ax.scatter(x, y, z, marker='o', alpha=0.5)\n",
        "\n",
        "    # Labeling the axes\n",
        "    ax.set_xlabel('X-axis (g)')\n",
        "    ax.set_ylabel('Y-axis (g)')\n",
        "    ax.set_zlabel('Z-axis (g)')\n",
        "\n",
        "    # Title for each subplot\n",
        "    ax.set_title(f'Behavior: {behavior}')\n",
        "    ax.grid(True)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D85sJqgV84Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Determine the number of subplots needed\n",
        "n_behaviors = len(behaviors)\n",
        "n_cols = 3  # Number of columns in the grid\n",
        "n_rows = (n_behaviors + n_cols - 1) // n_cols  # Number of rows needed\n",
        "\n",
        "# Create a figure with a grid of subplots\n",
        "fig = plt.figure(figsize=(5 * n_cols, 5 * n_rows))\n",
        "\n",
        "# Loop through each behavior and create a subplot for it\n",
        "for i, behavior in enumerate(behaviors):\n",
        "    # Filter data for the current behavior\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    # Check if there is data for this behavior\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    # Create a subplot\n",
        "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
        "\n",
        "    # Plotting the data points\n",
        "    sc = ax.scatter(x, y, z, marker='o', alpha=0.5)\n",
        "\n",
        "    # Labeling the axes\n",
        "    ax.set_xlabel('X-axis (g)')\n",
        "    ax.set_ylabel('Y-axis (g)')\n",
        "    ax.set_zlabel('Z-axis (g)')\n",
        "\n",
        "    # Title for each subplot\n",
        "    ax.set_title(f'Behavior: {behavior}')\n",
        "    ax.grid(True)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sSJC8o6BvWWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Determine the number of subplots needed\n",
        "n_behaviors = len(behaviors)\n",
        "n_cols = 3  # Number of columns in the grid\n",
        "n_rows = (n_behaviors + n_cols - 1) // n_cols  # Number of rows needed\n",
        "\n",
        "# Create a figure with a grid of subplots\n",
        "fig = plt.figure(figsize=(7 * n_cols, 6 * n_rows))  # Increased figure size\n",
        "\n",
        "# Define a list of colors for each behavior\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(behaviors)))  # Using 'tab10' colormap for distinct colors\n",
        "\n",
        "# Loop through each behavior and create a subplot for it\n",
        "for i, behavior in enumerate(behaviors):\n",
        "    # Filter data for the current behavior\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    # Check if there is data for this behavior\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    # Create a subplot\n",
        "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
        "\n",
        "    # Plotting the data points with a unique color for each behavior\n",
        "    ax.scatter(x, y, z, marker='o', alpha=0.7, color=colors[i], s=50)  # Adjust size and color\n",
        "\n",
        "    # Labeling the axes\n",
        "    ax.set_xlabel('X-axis (g)', fontsize=12)\n",
        "    ax.set_ylabel('Y-axis (g)', fontsize=12)\n",
        "    ax.set_zlabel('Z-axis (g)', fontsize=12)\n",
        "\n",
        "    # Title for each subplot with a slight vertical offset\n",
        "    ax.set_title(f'Behavior: {behavior}', fontsize=14, pad=20)  # Adjust the pad for spacing\n",
        "    ax.grid(True, linestyle='--', alpha=0.5)  # Use dashed grid lines for better aesthetics\n",
        "\n",
        "    # Adjust view angle for better perspective\n",
        "    ax.view_init(elev=20, azim=30)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.subplots_adjust(hspace=0.4, wspace=0.4)  # Increase space between subplots\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "isniWRdzv9-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Determine the number of subplots needed\n",
        "n_behaviors = len(behaviors)\n",
        "n_cols = 3  # Number of columns in the grid\n",
        "n_rows = (n_behaviors + n_cols - 1) // n_cols  # Number of rows needed\n",
        "\n",
        "# Create a figure with a grid of subplots\n",
        "fig = plt.figure(figsize=(7 * n_cols, 6 * n_rows))  # Increased figure size\n",
        "\n",
        "# Define a colorblind-friendly color palette\n",
        "colors = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7', '#999999']\n",
        "\n",
        "# Loop through each behavior and create a subplot for it\n",
        "for i, behavior in enumerate(behaviors):\n",
        "    # Filter data for the current behavior\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    # Check if there is data for this behavior\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    # Create a subplot\n",
        "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
        "\n",
        "    # Plotting the data points with a unique color for each behavior\n",
        "    ax.scatter(x, y, z, marker='o', alpha=0.7, color=colors[i % len(colors)], s=50)  # Adjust size and color\n",
        "\n",
        "    # Labeling the axes\n",
        "    ax.set_xlabel('X-axis (g)', fontsize=12)\n",
        "    ax.set_ylabel('Y-axis (g)', fontsize=12)\n",
        "    ax.set_zlabel('Z-axis (g)', fontsize=12)\n",
        "\n",
        "    # Title for each subplot with a slight vertical offset\n",
        "    ax.set_title(f'Behavior: {behavior}', fontsize=14, pad=20)  # Adjust the pad for spacing\n",
        "    ax.grid(True, linestyle='--', alpha=0.5)  # Use dashed grid lines for better aesthetics\n",
        "\n",
        "    # Adjust view angle for better perspective\n",
        "    ax.view_init(elev=20, azim=30)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.subplots_adjust(hspace=0.4, wspace=0.4)  # Increase space between subplots\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Lm4PfMMjwKpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Determine the number of subplots needed\n",
        "n_behaviors = len(behaviors)\n",
        "n_cols = 3  # Number of columns in the grid\n",
        "n_rows = (n_behaviors + n_cols - 1) // n_cols  # Number of rows needed\n",
        "\n",
        "# Create a figure with a grid of subplots\n",
        "fig = plt.figure(figsize=(7 * n_cols, 6 * n_rows))  # Increased figure size\n",
        "\n",
        "# Define a colorblind-friendly color palette\n",
        "colors = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7', '#999999']\n",
        "\n",
        "# Loop through each behavior and create a subplot for it\n",
        "for i, behavior in enumerate(behaviors):\n",
        "    # Filter data for the current behavior\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    # Check if there is data for this behavior\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    # Create a subplot\n",
        "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
        "\n",
        "    # Plotting the data points with a unique color for each behavior\n",
        "    ax.scatter(x, y, z, marker='o', alpha=0.7, color=colors[i % len(colors)], s=50)  # Adjust size and color\n",
        "\n",
        "    # Labeling the axes with bold text\n",
        "    ax.set_xlabel('X-axis (g)', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Y-axis (g)', fontsize=12, fontweight='bold')\n",
        "    ax.set_zlabel('Z-axis (g)', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Title for each subplot with bold text and no padding\n",
        "    ax.set_title(f'Behavior: {behavior}', fontsize=14, fontweight='bold', pad=10)  # Adjust the pad for spacing\n",
        "    ax.grid(True, linestyle='--', alpha=0.5)  # Use dashed grid lines for better aesthetics\n",
        "\n",
        "    # Adjust view angle for better perspective\n",
        "    ax.view_init(elev=20, azim=30)\n",
        "\n",
        "# Adjust layout to minimize whitespace\n",
        "plt.subplots_adjust(hspace=0.3, wspace=0.3)  # Adjust space between subplots\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2SrQXfoEwf4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Determine the number of subplots needed\n",
        "n_behaviors = len(behaviors)\n",
        "n_cols = 3  # Number of columns in the grid\n",
        "n_rows = (n_behaviors + n_cols - 1) // n_cols  # Number of rows needed\n",
        "\n",
        "# Create a figure with a grid of subplots\n",
        "fig = plt.figure(figsize=(7 * n_cols, 5 * n_rows))  # Adjusted figure size for less height\n",
        "\n",
        "# Define a colorblind-friendly color palette\n",
        "colors = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7', '#999999']\n",
        "\n",
        "# Loop through each behavior and create a subplot for it\n",
        "for i, behavior in enumerate(behaviors):\n",
        "    # Filter data for the current behavior\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    # Check if there is data for this behavior\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    # Create a subplot\n",
        "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
        "\n",
        "    # Plotting the data points with a unique color for each behavior\n",
        "    ax.scatter(x, y, z, marker='o', alpha=0.7, color=colors[i % len(colors)], s=50)  # Adjust size and color\n",
        "\n",
        "    # Labeling the axes with bold text\n",
        "    ax.set_xlabel('X-axis (g)', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Y-axis (g)', fontsize=12, fontweight='bold')\n",
        "    ax.set_zlabel('Z-axis (g)', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Title for each subplot with bold text\n",
        "    ax.set_title(f'Behavior: {behavior}', fontsize=14, fontweight='bold')  # Removed padding\n",
        "\n",
        "    # Add grid for better visibility\n",
        "    ax.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Adjust view angle for better perspective\n",
        "    ax.view_init(elev=20, azim=30)\n",
        "\n",
        "# Adjust layout to minimize whitespace\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.25)  # Decreased space between subplots\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MpxPw-wRw2kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/AX3_RAW_DATA06272024_ok.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Determine the number of subplots needed\n",
        "n_behaviors = len(behaviors)\n",
        "n_cols = 3  # Number of columns in the grid\n",
        "n_rows = (n_behaviors + n_cols - 1) // n_cols  # Number of rows needed\n",
        "\n",
        "# Create a figure with a grid of subplots\n",
        "fig = plt.figure(figsize=(7 * n_cols, 5 * n_rows))  # Adjusted figure size for less height\n",
        "\n",
        "# Define a colorblind-friendly color palette\n",
        "colors = ['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7', '#999999']\n",
        "\n",
        "# Compute global min and max for all axes\n",
        "x_min, x_max = data['X-axis (g)'].min(), data['X-axis (g)'].max()\n",
        "y_min, y_max = data['Y-axis (g)'].min(), data['Y-axis (g)'].max()\n",
        "z_min, z_max = data['Z-axis (g)'].min(), data['Z-axis (g)'].max()\n",
        "\n",
        "\n",
        "for i, behavior in enumerate(behaviors):\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
        "    ax.scatter(x, y, z, marker='o', alpha=0.7, color=colors[i % len(colors)], s=50)\n",
        "\n",
        "    ax.set_xlabel('X-axis (g)', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Y-axis (g)', fontsize=12, fontweight='bold')\n",
        "    ax.set_zlabel('Z-axis (g)', fontsize=12, fontweight='bold')\n",
        "    ax.set_title(f'Behavior: {behavior}', fontsize=14, fontweight='bold')\n",
        "\n",
        "    ax.grid(True, linestyle='--', alpha=0.5)\n",
        "    ax.view_init(elev=20, azim=30)\n",
        "\n",
        "    # 🔹 Apply global axis limits here:\n",
        "    ax.set_xlim([x_min, x_max])\n",
        "    ax.set_ylim([y_min, y_max])\n",
        "    ax.set_zlim([z_min, z_max])\n",
        "\n",
        "\n",
        "    # Title for each subplot with bold text\n",
        "    ax.set_title(f'Behavior: {behavior}', fontsize=14, fontweight='bold')  # Removed padding\n",
        "\n",
        "    # Add grid for better visibility\n",
        "    ax.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Adjust view angle for better perspective\n",
        "    ax.view_init(elev=20, azim=30)\n",
        "\n",
        "# Adjust layout to minimize whitespace\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.25)  # Decreased space between subplots\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yNYWzyNIALtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Determine the number of subplots needed\n",
        "n_behaviors = len(behaviors)\n",
        "n_cols = 3  # Number of columns in the grid\n",
        "n_rows = (n_behaviors + n_cols - 1) // n_cols  # Number of rows needed\n",
        "\n",
        "# Create a figure with a grid of subplots\n",
        "fig = plt.figure(figsize=(5 * n_cols, 5 * n_rows))\n",
        "fig.patch.set_facecolor('lightgray')  # Set figure background color\n",
        "\n",
        "# Define a colormap\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, n_behaviors))\n",
        "\n",
        "# Loop through each behavior and create a subplot for it\n",
        "for i, behavior in enumerate(behaviors):\n",
        "    # Filter data for the current behavior\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    # Check if there is data for this behavior\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    # Create a subplot\n",
        "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
        "\n",
        "    # Plotting the data points with color and size adjustments\n",
        "    sc = ax.scatter(x, y, z, marker='o', alpha=0.7, color=colors[i % len(colors)], s=50)  # Adjust size and color\n",
        "\n",
        "    # Labeling the axes\n",
        "    ax.set_xlabel('X-axis (g)', fontsize=20, fontweight='bold')\n",
        "    ax.set_ylabel('Y-axis (g)', fontsize=20, fontweight='bold')\n",
        "    ax.set_zlabel('Z-axis (g)', fontsize=20, fontweight='bold')\n",
        "\n",
        "    # Title for each subplot\n",
        "    ax.set_title(f'Behavior: {behavior}', fontsize=20, fontweight='bold')\n",
        "    ax.grid(True, linestyle='--', alpha=0.5)  # Use dashed grid lines for better aesthetics\n",
        "\n",
        "    # Adjust view angle for better perspective\n",
        "    ax.view_init(elev=20, azim=30)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CuaUlNoEvmnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Determine the number of subplots needed\n",
        "n_behaviors = len(behaviors)\n",
        "n_cols = 3  # Number of columns in the grid\n",
        "n_rows = (n_behaviors + n_cols - 1) // n_cols  # Number of rows needed\n",
        "\n",
        "# Create a figure with a grid of subplots\n",
        "fig = plt.figure(figsize=(7 * n_cols, 6 * n_rows))  # Increased figure size\n",
        "fig.patch.set_facecolor('lightgray')  # Set figure background color\n",
        "\n",
        "# Define a colormap\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, n_behaviors))\n",
        "\n",
        "# Loop through each behavior and create a subplot for it\n",
        "for i, behavior in enumerate(behaviors):\n",
        "    # Filter data for the current behavior\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    # Check if there is data for this behavior\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    # Create a subplot\n",
        "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
        "\n",
        "    # Plotting the data points with color and size adjustments\n",
        "    sc = ax.scatter(x, y, z, marker='o', alpha=0.7, color=colors[i % len(colors)], s=50)  # Adjust size and color\n",
        "\n",
        "    # Labeling the axes\n",
        "    ax.set_xlabel('X-axis (g)', fontsize=20, fontweight='bold')\n",
        "    ax.set_ylabel('Y-axis (g)', fontsize=20, fontweight='bold')\n",
        "    ax.set_zlabel('Z-axis (g)', fontsize=20, fontweight='bold')\n",
        "\n",
        "    # Title for each subplot with a slight vertical offset\n",
        "    ax.set_title(f'Behavior: {behavior}', fontsize=20, fontweight='bold', pad=20)  # Adjust the pad for spacing\n",
        "    ax.grid(True, linestyle='--', alpha=0.5)  # Use dashed grid lines for better aesthetics\n",
        "\n",
        "    # Adjust view angle for better perspective\n",
        "    ax.view_init(elev=20, azim=30)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.subplots_adjust(hspace=0.4, wspace=0.4)  # Increase space between subplots\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VlAzhanGvvos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Create a combined label for behavior\n",
        "data['CombinedLabel'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Define unique behaviors based on combined labels\n",
        "behaviors = data['CombinedLabel'].unique()\n",
        "\n",
        "# Determine the number of subplots needed\n",
        "n_behaviors = len(behaviors)\n",
        "n_cols = 3  # Number of columns in the grid\n",
        "n_rows = (n_behaviors + n_cols - 1) // n_cols  # Number of rows needed\n",
        "\n",
        "# Create a figure with a grid of subplots\n",
        "fig = plt.figure(figsize=(5 * n_cols, 5 * n_rows))\n",
        "fig.patch.set_facecolor('lightgray')  # Set figure background color\n",
        "\n",
        "# Define a colormap\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, n_behaviors))\n",
        "\n",
        "# Loop through each behavior and create a subplot for it\n",
        "for i, behavior in enumerate(behaviors):\n",
        "    # Filter data for the current behavior\n",
        "    behavior_data = data[data['CombinedLabel'] == behavior]\n",
        "\n",
        "    # Check if there is data for this behavior\n",
        "    if behavior_data.empty:\n",
        "        print(f\"No data available for behavior: {behavior}\")\n",
        "        continue\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    x = behavior_data['X-axis (g)']\n",
        "    y = behavior_data['Y-axis (g)']\n",
        "    z = behavior_data['Z-axis (g)']\n",
        "\n",
        "    # Create a subplot\n",
        "    ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
        "\n",
        "    # Plotting the data points with color\n",
        "    sc = ax.scatter(x, y, z, marker='o', alpha=0.7, color=colors[i % len(colors)], s=50)  # Adjust size and color\n",
        "\n",
        "    # Labeling the axes\n",
        "    ax.set_xlabel('X-axis (g)', fontsize=20, fontweight='bold')\n",
        "    ax.set_ylabel('Y-axis (g)', fontsize=20, fontweight='bold')\n",
        "    ax.set_zlabel('Z-axis (g)', fontsize=20, fontweight='bold')\n",
        "\n",
        "    # Title for each subplot\n",
        "    ax.set_title(f'Behavior: {behavior}', fontsize=20, fontweight='bold')\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Adjust view angle for better perspective\n",
        "    ax.view_init(elev=20, azim=30)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yu48B3TlvO25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "# Define thresholds based on the study\n",
        "daytime_grazing_threshold = 40  # 40% grazing during the day\n",
        "nighttime_grazing_threshold = 16  # 16% grazing during the night\n",
        "\n",
        "# Define behavior labels to be analyzed\n",
        "behavior_labels = {0: 'Feeding', 1: 'Rumination', 2: 'Standing', 3: 'Lying', 4: 'Walking'}\n",
        "\n",
        "# Check if 'behavior' column exists\n",
        "if 'behavior' in data.columns:\n",
        "    # Count occurrences of each behavior\n",
        "    behavior_counts = data['behavior'].value_counts()\n",
        "\n",
        "    # Print the distribution of behaviors\n",
        "    print(\"Distribution of Behavior Labels:\")\n",
        "    for behavior_code, count in behavior_counts.items():\n",
        "        print(f\"{behavior_labels[behavior_code]}: {count}\")\n",
        "\n",
        "    # Calculate percentage of each behavior\n",
        "    total_records = data.shape[0]\n",
        "    behavior_percentages = (behavior_counts / total_records) * 100\n",
        "\n",
        "    # Print percentage of each behavior\n",
        "    print(\"\\nPercentage of Each Behavior:\")\n",
        "    for behavior_code, percentage in behavior_percentages.items():\n",
        "        print(f\"{behavior_labels[behavior_code]}: {percentage:.2f}%\")\n",
        "\n",
        "    # Check if grazing and walking percentages meet the thresholds\n",
        "    grazing_percentage = behavior_percentages.get(0, 0)  # Feeding is labeled as 0\n",
        "    walking_percentage = behavior_percentages.get(4, 0)  # Walking is labeled as 4\n",
        "\n",
        "    if grazing_percentage > daytime_grazing_threshold:\n",
        "        print(f\"Overgrazing detected: Grazing {grazing_percentage:.2f}%, exceeding the {daytime_grazing_threshold}% threshold.\")\n",
        "    else:\n",
        "        print(f\"No overgrazing detected: Grazing {grazing_percentage:.2f}%, within the {daytime_grazing_threshold}% threshold.\")\n",
        "\n",
        "    if walking_percentage > nighttime_grazing_threshold:\n",
        "        print(f\"Excessive walking detected: Walking {walking_percentage:.2f}%, exceeding the {nighttime_grazing_threshold}% threshold.\")\n",
        "    else:\n",
        "        print(f\"No excessive walking detected: Walking {walking_percentage:.2f}%, within the {nighttime_grazing_threshold}% threshold.\")\n",
        "else:\n",
        "    raise KeyError(\"The column 'behavior' is missing in the dataset.\")"
      ],
      "metadata": {
        "id": "hXnyffqq9H8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'CURC.csv' with your actual file)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Define the column that indicates grazing/feeding behavior\n",
        "feeding_column = 'IteragreementFeeding'\n",
        "\n",
        "# Convert the 'IteragreementFeeding' column to numeric values\n",
        "# \"EatingEating\" is converted to 1 (feeding), others to 0 (non-feeding).\n",
        "data[feeding_column] = data[feeding_column].apply(lambda x: 1 if 'Eating' in x else 0)\n",
        "\n",
        "# Convert 'Time' to datetime format\n",
        "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S')\n",
        "\n",
        "# Define daytime and nighttime hours\n",
        "day_start = pd.to_datetime(\"06:00:00\").time()\n",
        "day_end = pd.to_datetime(\"18:00:00\").time()\n",
        "\n",
        "# Create separate columns for daytime and nighttime\n",
        "data['is_daytime'] = data['Time'].apply(lambda x: day_start <= x.time() <= day_end)\n",
        "data['is_nighttime'] = ~data['is_daytime']\n",
        "\n",
        "# Calculate total daytime and nighttime grazing instances\n",
        "daytime_grazing_seconds = data[data['is_daytime']][feeding_column].sum()\n",
        "nighttime_grazing_seconds = data[data['is_nighttime']][feeding_column].sum()\n",
        "\n",
        "# Convert seconds to hours\n",
        "daytime_grazing_hours = daytime_grazing_seconds / 3600\n",
        "nighttime_grazing_hours = nighttime_grazing_seconds / 3600\n",
        "\n",
        "# Set durations for day and night\n",
        "day_duration_hours = 12\n",
        "night_duration_hours = 12\n",
        "\n",
        "# Calculate percentages for grazing\n",
        "daytime_grazing_percentage = (daytime_grazing_hours / day_duration_hours) * 100\n",
        "nighttime_grazing_percentage = (nighttime_grazing_hours / night_duration_hours) * 100\n",
        "\n",
        "# Set thresholds based on the study\n",
        "daytime_threshold = 40  # 40% for daytime\n",
        "nighttime_threshold = 16  # 16% for nighttime\n",
        "\n",
        "# Check for overgrazing\n",
        "if daytime_grazing_percentage > daytime_threshold:\n",
        "    print(f\"Overgrazing detected during the day: Grazing {daytime_grazing_percentage:.2f}%, exceeding the {daytime_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"No overgrazing during the day: Grazing {daytime_grazing_percentage:.2f}%, within the {daytime_threshold}% threshold.\")\n",
        "\n",
        "if nighttime_grazing_percentage > nighttime_threshold:\n",
        "    print(f\"Overgrazing detected during the night: Grazing {nighttime_grazing_percentage:.2f}%, exceeding the {nighttime_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"No overgrazing during the night: Grazing {nighttime_grazing_percentage:.2f}%, within the {nighttime_threshold}% threshold.\")\n"
      ],
      "metadata": {
        "id": "8Bua4_zYlR0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'CURC.csv' with your actual file)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Define the behavior columns\n",
        "locomotion_column = 'IteragreementLocom'\n",
        "feeding_column = 'IteragreementFeeding'\n",
        "\n",
        "# Convert columns to binary indicators (1 for behavior present, 0 otherwise)\n",
        "data[locomotion_column] = data[locomotion_column].apply(lambda x: 1 if 'Locomotion' in x else 0)\n",
        "data[feeding_column] = data[feeding_column].apply(lambda x: 1 if 'Eating' in x else 0)\n",
        "\n",
        "# Calculate the total number of data points (to calculate percentages)\n",
        "total_points = len(data)\n",
        "\n",
        "# Count the number of instances for each behavior\n",
        "locomotion_count = data[locomotion_column].sum()\n",
        "feeding_count = data[feeding_column].sum()\n",
        "\n",
        "# Calculate percentages\n",
        "locomotion_percentage = (locomotion_count / total_points) * 100\n",
        "feeding_percentage = (feeding_count / total_points) * 100\n",
        "\n",
        "# Print out the percentage breakdown of each behavior\n",
        "print(\"Percentage breakdown of each behavior:\")\n",
        "print(f\"Locomotion: {locomotion_percentage:.2f}%\")\n",
        "print(f\"Feeding: {feeding_percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "5g9etWIqmp-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'CURC.csv' with your actual file)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Define mapping for the labels\n",
        "label_mapping = {\n",
        "    'WalkingWalking': 'Walking',\n",
        "    'StandingStanding': 'Standing',\n",
        "    'EatingEating': 'Feeding'\n",
        "}\n",
        "\n",
        "# Apply the mapping to the column\n",
        "data['behavior'] = data['IteragreementLocom'].map(label_mapping).fillna('Other')\n",
        "\n",
        "# Count occurrences of each behavior\n",
        "behavior_counts = data['behavior'].value_counts()\n",
        "\n",
        "# Calculate the total number of data points\n",
        "total_points = len(data)\n",
        "\n",
        "# Create a percentage breakdown for each behavior\n",
        "behavior_percentages = (behavior_counts / total_points) * 100\n",
        "\n",
        "# Print out the distribution of behavior labels\n",
        "print(\"Distribution of Behavior Labels:\")\n",
        "for behavior, count in behavior_counts.items():\n",
        "    print(f\"{behavior}: {count}\")\n",
        "\n",
        "# Print out the percentage of each behavior\n",
        "print(\"\\nPercentage of Each Behavior:\")\n",
        "for behavior, percentage in behavior_percentages.items():\n",
        "    print(f\"{behavior}: {percentage:.2f}%\")\n",
        "\n",
        "# Define thresholds\n",
        "daytime_threshold = 40  # % for daytime\n",
        "walking_threshold = 16  # % for walking\n",
        "\n",
        "# Extract percentages\n",
        "feeding_percentage = behavior_percentages.get('Feeding', 0)\n",
        "walking_percentage = behavior_percentages.get('Walking', 0)\n",
        "\n",
        "# Print messages about overgrazing and excessive walking\n",
        "if feeding_percentage > daytime_threshold:\n",
        "    print(f\"\\nOvergrazing detected: Grazing {feeding_percentage:.2f}%, exceeding the {daytime_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"\\nNo overgrazing detected: Grazing {feeding_percentage:.2f}%, within the {daytime_threshold}% threshold.\")\n",
        "\n",
        "if walking_percentage > walking_threshold:\n",
        "    print(f\"Excessive walking detected: Walking {walking_percentage:.2f}%, exceeding the {walking_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"No excessive walking detected: Walking {walking_percentage:.2f}%, within the {walking_threshold}% threshold.\")"
      ],
      "metadata": {
        "id": "2Lfpz9o0nRpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'CURC.csv' with your actual file)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Define mapping for the labels\n",
        "label_mapping = {\n",
        "    'WalkingWalking': 'Walking',\n",
        "    'StandingStanding': 'Standing',\n",
        "    'EatingEating': 'Feeding',\n",
        "    'otherother': 'Other'  # Add this to catch any other labels\n",
        "}\n",
        "\n",
        "# Apply the mapping to the relevant column\n",
        "data['behavior'] = data['IteragreementLocom'].map(label_mapping).fillna('Other')\n",
        "\n",
        "# Count occurrences of each behavior\n",
        "behavior_counts = data['behavior'].value_counts()\n",
        "\n",
        "# Calculate the total number of data points\n",
        "total_points = len(data)\n",
        "\n",
        "# Create a percentage breakdown for each behavior\n",
        "behavior_percentages = (behavior_counts / total_points) * 100\n",
        "\n",
        "# Print out the distribution of behavior labels\n",
        "print(\"Distribution of Behavior Labels:\")\n",
        "for behavior, count in behavior_counts.items():\n",
        "    print(f\"{behavior}: {count}\")\n",
        "\n",
        "# Print out the percentage of each behavior\n",
        "print(\"\\nPercentage of Each Behavior:\")\n",
        "for behavior, percentage in behavior_percentages.items():\n",
        "    print(f\"{behavior}: {percentage:.2f}%\")\n",
        "\n",
        "# Define thresholds\n",
        "daytime_threshold = 40  # % for daytime grazing\n",
        "walking_threshold = 16  # % for walking\n",
        "\n",
        "# Extract percentages\n",
        "feeding_percentage = behavior_percentages.get('Feeding', 0)\n",
        "walking_percentage = behavior_percentages.get('Walking', 0)\n",
        "\n",
        "# Print messages about overgrazing and excessive walking\n",
        "if feeding_percentage > daytime_threshold:\n",
        "    print(f\"\\nOvergrazing detected: Grazing {feeding_percentage:.2f}%, exceeding the {daytime_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"\\nNo overgrazing detected: Grazing {feeding_percentage:.2f}%, within the {daytime_threshold}% threshold.\")\n",
        "\n",
        "if walking_percentage > walking_threshold:\n",
        "    print(f\"Excessive walking detected: Walking {walking_percentage:.2f}%, exceeding the {walking_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"No excessive walking detected: Walking {walking_percentage:.2f}%, within the {walking_threshold}% threshold.\")"
      ],
      "metadata": {
        "id": "Vi-gRfjPnpQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define data for the plots\n",
        "data1_labels = ['Standing', 'Walking']\n",
        "data1_counts = [2987, 268]\n",
        "data1_percentages = [91.77, 8.23]\n",
        "\n",
        "data2_labels = ['Grazing', 'Lying-Ruminating', 'Lying-Resting', 'Standing-Resting', 'Walking', 'Standing-Ruminating']\n",
        "data2_counts = [5732, 2034, 1702, 1559, 1229, 832]\n",
        "data2_percentages = [43.80, 14.92, 12.58, 11.33, 9.39, 6.29]\n",
        "\n",
        "data3_labels = ['Walking', 'Feeding', 'Rumination', 'Lying', 'Standing']\n",
        "data3_counts = [592645, 359711, 294985, 3368, 1827]\n",
        "data3_percentages = [47.32, 28.72, 23.55, 0.27, 0.15]\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(3, 2, figsize=(14, 18))\n",
        "\n",
        "# Plot 1: Distribution of Behavior Labels (Data 1)\n",
        "axs[0, 0].bar(data1_labels, data1_counts, color=['blue', 'orange'])\n",
        "axs[0, 0].set_title('Distribution of Behavior Labels (Data 1)')\n",
        "axs[0, 0].set_ylabel('Count')\n",
        "\n",
        "# Plot 2: Percentage of Each Behavior (Data 1)\n",
        "axs[0, 1].bar(data1_labels, data1_percentages, color=['blue', 'orange'])\n",
        "axs[0, 1].set_title('Percentage of Each Behavior (Data 1)')\n",
        "axs[0, 1].set_ylabel('Percentage (%)')\n",
        "\n",
        "# Plot 3: Distribution of Behavior Labels (Data 2)\n",
        "axs[1, 0].bar(data2_labels, data2_counts, color='green')\n",
        "axs[1, 0].set_title('Distribution of Behavior Labels (Data 2)')\n",
        "axs[1, 0].set_ylabel('Count')\n",
        "axs[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Plot 4: Percentage of Each Behavior (Data 2)\n",
        "axs[1, 1].bar(data2_labels, data2_percentages, color='green')\n",
        "axs[1, 1].set_title('Percentage of Each Behavior (Data 2)')\n",
        "axs[1, 1].set_ylabel('Percentage (%)')\n",
        "axs[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Plot 5: Distribution of Behavior Labels (Data 3)\n",
        "axs[2, 0].bar(data3_labels, data3_counts, color='red')\n",
        "axs[2, 0].set_title('Distribution of Behavior Labels (Data 3)')\n",
        "axs[2, 0].set_ylabel('Count')\n",
        "axs[2, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Plot 6: Percentage of Each Behavior (Data 3)\n",
        "axs[2, 1].bar(data3_labels, data3_percentages, color='red')\n",
        "axs[2, 1].set_title('Percentage of Each Behavior (Data 3)')\n",
        "axs[2, 1].set_ylabel('Percentage (%)')\n",
        "axs[2, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plots\n",
        "plt.show()\n",
        "\n",
        "# Print threshold messages\n",
        "print(\"No overgrazing detected: Grazing 0.00%, within the 40% threshold.\")\n",
        "print(\"No excessive walking detected: Walking 8.23%, within the 16% threshold.\")\n",
        "print(\"Overgrazing detected: Grazing 43.80%, exceeding the 40% threshold.\")\n",
        "print(\"No excessive walking detected: Walking 9.39%, within the 16% threshold.\")\n",
        "print(\"No overgrazing detected: Grazing 28.72%, within the 40% threshold.\")\n",
        "print(\"Excessive walking detected: Walking 47.32%, exceeding the 16% threshold.\")"
      ],
      "metadata": {
        "id": "Jbze3b3RnzYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define data for Dataset 1\n",
        "labels1 = ['Walking', 'Feeding', 'Rumination', 'Lying', 'Standing']\n",
        "sizes1 = [592645, 359711, 294985, 3368, 1827]\n",
        "percentages1 = [47.32, 28.72, 23.55, 0.27, 0.15]\n",
        "\n",
        "# Define data for Dataset 4\n",
        "labels4 = ['Grazing', 'Lying-Ruminating', 'Lying-Resting', 'Standing-Resting', 'Walking', 'Standing-Ruminating']\n",
        "sizes4 = [5732, 2034, 1702, 1559, 1229, 832]\n",
        "percentages4 = [43.80, 14.92, 12.58, 11.33, 9.39, 6.29]\n",
        "\n",
        "# Define data for Dataset 5\n",
        "labels5 = ['Standing', 'Walking']\n",
        "sizes5 = [2987, 268]\n",
        "percentages5 = [91.77, 8.23]\n",
        "\n",
        "# Create subplots for the pie charts\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot for Dataset 1\n",
        "axs[0].pie(sizes1, labels=labels1, autopct='%1.2f%%', colors=['blue', 'orange', 'green', 'red', 'purple'])\n",
        "axs[0].set_title('Dataset 1: Percentage of Each Behavior')\n",
        "\n",
        "# Plot for Dataset 4\n",
        "axs[1].pie(sizes4, labels=labels4, autopct='%1.2f%%', colors=['blue', 'orange', 'green', 'red', 'purple', 'cyan'])\n",
        "axs[1].set_title('Dataset 4: Percentage of Each Behavior')\n",
        "\n",
        "# Plot for Dataset 5\n",
        "axs[2].pie(sizes5, labels=labels5, autopct='%1.2f%%', colors=['blue', 'orange'])\n",
        "axs[2].set_title('Dataset 5: Percentage of Each Behavior')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plots\n",
        "plt.show()\n",
        "\n",
        "# Print threshold messages\n",
        "print(\"Dataset 1:\")\n",
        "print(\"No overgrazing detected: Grazing 28.72%, within the 40% threshold.\")\n",
        "print(\"Excessive walking detected: Walking 47.32%, exceeding the 16% threshold.\")\n",
        "\n",
        "print(\"\\nDataset 4:\")\n",
        "print(\"Overgrazing detected: Grazing 43.80%, exceeding the 40% threshold.\")\n",
        "print(\"No excessive walking detected: Walking 9.39%, within the 16% threshold.\")\n",
        "\n",
        "print(\"\\nDataset 5:\")\n",
        "print(\"No overgrazing detected: Grazing 0.00%, within the 40% threshold.\")\n",
        "print(\"No excessive walking detected: Walking 8.23%, within the 16% threshold.\")"
      ],
      "metadata": {
        "id": "57BDgaT0oP3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the data\n",
        "data = {\n",
        "    'Dataset': ['Dataset 1', 'Dataset 4', 'Dataset 5'],\n",
        "    'Overgrazing Status': [\n",
        "        'No overgrazing detected: Grazing 28.72%, within the 40% threshold.',\n",
        "        'Overgrazing detected: Grazing 43.80%, exceeding the 40% threshold.',\n",
        "        'No overgrazing detected: Grazing 0.00%, within the 40% threshold.'\n",
        "    ],\n",
        "    'Walking Status': [\n",
        "        'Excessive walking detected: Walking 47.32%, exceeding the 16% threshold.',\n",
        "        'No excessive walking detected: Walking 9.39%, within the 16% threshold.',\n",
        "        'No excessive walking detected: Walking 8.23%, within the 16% threshold.'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "id": "OKo6CP85o290"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'CURC.csv' with your actual file path)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Define mapping for the labels\n",
        "label_mapping = {\n",
        "    'WalkingWalking': 'Walking',\n",
        "    'StandingStanding': 'Standing',\n",
        "    'EatingEating': 'Feeding',  # Updated 'EatingEating' to 'Feeding'\n",
        "    'otherother': 'Other'  # Add this to catch any other labels\n",
        "}\n",
        "\n",
        "# Apply the mapping to the relevant column\n",
        "data['behavior'] = data['IteragreementLocom'].map(label_mapping).fillna('Other')\n",
        "\n",
        "# Count occurrences of each behavior\n",
        "behavior_counts = data['behavior'].value_counts()\n",
        "\n",
        "# Calculate the total number of data points\n",
        "total_points = len(data)\n",
        "\n",
        "# Create a percentage breakdown for each behavior\n",
        "behavior_percentages = (behavior_counts / total_points) * 100\n",
        "\n",
        "# Print out the distribution of behavior labels\n",
        "print(\"Distribution of Behavior Labels:\")\n",
        "for behavior, count in behavior_counts.items():\n",
        "    print(f\"{behavior}: {count}\")\n",
        "\n",
        "# Print out the percentage of each behavior\n",
        "print(\"\\nPercentage of Each Behavior:\")\n",
        "for behavior, percentage in behavior_percentages.items():\n",
        "    print(f\"{behavior}: {percentage:.2f}%\")\n",
        "\n",
        "# Define thresholds\n",
        "daytime_threshold = 40  # % for daytime grazing\n",
        "walking_threshold = 16  # % for walking\n",
        "\n",
        "# Extract percentages\n",
        "feeding_percentage = behavior_percentages.get('Feeding', 0)\n",
        "walking_percentage = behavior_percentages.get('Walking', 0)\n",
        "\n",
        "# Print messages about overgrazing and excessive walking\n",
        "if feeding_percentage > daytime_threshold:\n",
        "    print(f\"\\nOvergrazing detected: Feeding {feeding_percentage:.2f}%, exceeding the {daytime_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"\\nNo overgrazing detected: Feeding {feeding_percentage:.2f}%, within the {daytime_threshold}% threshold.\")\n",
        "\n",
        "if walking_percentage > walking_threshold:\n",
        "    print(f\"Excessive walking detected: Walking {walking_percentage:.2f}%, exceeding the {walking_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"No excessive walking detected: Walking {walking_percentage:.2f}%, within the {walking_threshold}% threshold.\")"
      ],
      "metadata": {
        "id": "lQ80eIMRpFmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'CURC.csv' with your actual file)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Define mapping for the labels\n",
        "label_mapping = {\n",
        "    'WalkingWalking': 'Walking',\n",
        "    'StandingStanding': 'Standing',\n",
        "    'EatingEating': 'Feeding',\n",
        "    'otherother': 'Other'  # Add this to catch any other labels\n",
        "}\n",
        "\n",
        "# Apply the mapping to the relevant column for locomotion\n",
        "data['behavior'] = data['IteragreementLocom'].map(label_mapping).fillna('Other')\n",
        "\n",
        "# Count occurrences of each behavior\n",
        "behavior_counts = data['behavior'].value_counts()\n",
        "\n",
        "# Calculate the total number of data points\n",
        "total_points = len(data)\n",
        "\n",
        "# Create a percentage breakdown for each behavior\n",
        "behavior_percentages = (behavior_counts / total_points) * 100\n",
        "\n",
        "# Print out the distribution of behavior labels\n",
        "print(\"Distribution of Behavior Labels:\")\n",
        "for behavior, count in behavior_counts.items():\n",
        "    print(f\"{behavior}: {count}\")\n",
        "\n",
        "# Print out the percentage of each behavior\n",
        "print(\"\\nPercentage of Each Behavior:\")\n",
        "for behavior, percentage in behavior_percentages.items():\n",
        "    print(f\"{behavior}: {percentage:.2f}%\")\n",
        "\n",
        "# Extract percentages for feeding and walking\n",
        "feeding_percentage = behavior_percentages.get('Feeding', 0)\n",
        "walking_percentage = behavior_percentages.get('Walking', 0)\n",
        "\n",
        "# Calculate grazing percentage from IteragreementFeeding column\n",
        "feeding_data = data['IteragreementFeeding'].map({'EatingEating': 1, 'otherother': 0}).fillna(0)\n",
        "feeding_count = feeding_data.sum()\n",
        "feeding_percentage_total = (feeding_count / total_points) * 100\n",
        "\n",
        "# Define thresholds\n",
        "daytime_threshold = 40  # % for daytime grazing\n",
        "walking_threshold = 16  # % for walking\n",
        "\n",
        "# Print messages about overgrazing and excessive walking\n",
        "if feeding_percentage_total > daytime_threshold:\n",
        "    print(f\"\\nOvergrazing detected: Grazing {feeding_percentage_total:.2f}%, exceeding the {daytime_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"\\nNo overgrazing detected: Grazing {feeding_percentage_total:.2f}%, within the {daytime_threshold}% threshold.\")\n",
        "\n",
        "if walking_percentage > walking_threshold:\n",
        "    print(f\"Excessive walking detected: Walking {walking_percentage:.2f}%, exceeding the {walking_threshold}% threshold.\")\n",
        "else:\n",
        "    print(f\"No excessive walking detected: Walking {walking_percentage:.2f}%, within the {walking_threshold}% threshold.\")"
      ],
      "metadata": {
        "id": "q80marUwtZze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # Optional: for heatmap styling\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Define window size\n",
        "window_size = 15  # Approximately 15 data points for 0.5 seconds\n",
        "\n",
        "# Initialize lists to store windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "# Segment the time-series data into windows\n",
        "for i in range(0, len(data) - window_size + 1, window_size):\n",
        "    window = data.iloc[i:i + window_size]\n",
        "    if len(window) == window_size:  # Ensure the window is complete\n",
        "        # Extract features from the window\n",
        "        window_features = {\n",
        "            'mean_acc_x': window['acc_x'].mean(),\n",
        "            'mean_acc_y': window['acc_y'].mean(),\n",
        "            'mean_acc_z': window['acc_z'].mean(),\n",
        "            'std_acc_x': window['acc_x'].std(),\n",
        "            'std_acc_y': window['acc_y'].std(),\n",
        "            'std_acc_z': window['acc_z'].std(),\n",
        "            'skew_acc_x': window['acc_x'].skew(),\n",
        "            'skew_acc_y': window['acc_y'].skew(),\n",
        "            'skew_acc_z': window['acc_z'].skew(),\n",
        "            'kurt_acc_x': window['acc_x'].kurt(),\n",
        "            'kurt_acc_y': window['acc_y'].kurt(),\n",
        "            'kurt_acc_z': window['acc_z'].kurt()\n",
        "        }\n",
        "        windowed_features.append(window_features)\n",
        "\n",
        "        # Assign label to the window (assuming it's the same for all samples within the window)\n",
        "        window_label = window['behavior'].iloc[0]  # Adjust based on your specific label\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X_windowed = pd.DataFrame(windowed_features)\n",
        "y_windowed = np.array(windowed_labels)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_windowed)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_windowed)\n",
        "\n",
        "# Split the data into train and test using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Instantiate Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "# Train the Random Forest classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_rf * 100:.2f}%\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Sensitivity and Specificity calculation\n",
        "sensitivity_specificity = {}\n",
        "overall_sensitivity = 0\n",
        "overall_specificity = 0\n",
        "\n",
        "for i, label in enumerate(np.unique(y_test)):\n",
        "    tp = conf_matrix[i, i]\n",
        "    fn = conf_matrix[i, :].sum() - tp\n",
        "    fp = conf_matrix[:, i].sum() - tp\n",
        "    tn = conf_matrix.sum() - (tp + fn + fp)\n",
        "\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    sensitivity_specificity[label] = {\n",
        "        'Sensitivity (Recall)': sensitivity,\n",
        "        'Specificity': specificity\n",
        "    }\n",
        "\n",
        "    overall_sensitivity += sensitivity\n",
        "    overall_specificity += specificity\n",
        "\n",
        "# Calculate overall sensitivity and specificity\n",
        "num_classes = len(np.unique(y_test))\n",
        "overall_sensitivity /= num_classes\n",
        "overall_specificity /= num_classes\n",
        "\n",
        "# Print sensitivity and specificity for each label\n",
        "for label, metrics in sensitivity_specificity.items():\n",
        "    print(f\"\\nLabel: {label}\")\n",
        "    print(f\"Sensitivity: {metrics['Sensitivity (Recall)']:.2f}\")\n",
        "    print(f\"Specificity: {metrics['Specificity']:.2f}\")\n",
        "\n",
        "# Print overall sensitivity and specificity\n",
        "print(f\"\\nOverall Sensitivity: {overall_sensitivity:.2f}\")\n",
        "print(f\"Overall Specificity: {overall_specificity:.2f}\")\n"
      ],
      "metadata": {
        "id": "MO2dyQ8Ka2il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # Optional: for heatmap styling\n",
        "\n",
        "# Define file names\n",
        "file_names = [\"cow1.csv\", \"cow2.csv\", \"cow3.csv\", \"cow4.csv\", \"cow5.csv\", \"cow6.csv\"]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "all_data = []\n",
        "\n",
        "# Iterate over each file and read them\n",
        "for file_name in file_names:\n",
        "    data = pd.read_csv(file_name)\n",
        "    all_data.append(data)\n",
        "\n",
        "# Concatenate all the data into one DataFrame\n",
        "combined_data = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# Define window size\n",
        "window_size = 15  # Approximately 15 data points for 0.5 seconds\n",
        "\n",
        "# Initialize lists to store windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "# Segment the time-series data into windows\n",
        "for i in range(0, len(combined_data) - window_size + 1, window_size):\n",
        "    window = combined_data.iloc[i:i + window_size]\n",
        "    if len(window) == window_size:  # Ensure the window is complete\n",
        "        # Extract features from the window\n",
        "        window_features = {\n",
        "            'mean_acc_x': window['AccX'].mean(),\n",
        "            'mean_acc_y': window['AccY'].mean(),\n",
        "            'mean_acc_z': window['AccZ'].mean(),\n",
        "            'std_acc_x': window['AccX'].std(),\n",
        "            'std_acc_y': window['AccY'].std(),\n",
        "            'std_acc_z': window['AccZ'].std(),\n",
        "            'skew_acc_x': window['AccX'].skew(),\n",
        "            'skew_acc_y': window['AccY'].skew(),\n",
        "            'skew_acc_z': window['AccZ'].skew(),\n",
        "            'kurt_acc_x': window['AccX'].kurt(),\n",
        "            'kurt_acc_y': window['AccY'].kurt(),\n",
        "            'kurt_acc_z': window['AccZ'].kurt()\n",
        "        }\n",
        "        windowed_features.append(window_features)\n",
        "\n",
        "        # Assign label to the window (assuming it's the same for all samples within the window)\n",
        "        window_label = window['Label'].iloc[0]\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X_windowed = pd.DataFrame(windowed_features)\n",
        "y_windowed = np.array(windowed_labels)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_windowed)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE with a reduced number of neighbors\n",
        "smote = SMOTE(random_state=42, k_neighbors=2)  # Reduce k_neighbors to 2\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_windowed)\n",
        "\n",
        "# Split the data into train and test using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize a list to store accuracy results\n",
        "accuracies = []\n",
        "\n",
        "# Gini score calculation using AUC-ROC\n",
        "def gini_score(y_true, y_pred_proba):\n",
        "    # Calculate AUC-ROC score\n",
        "    auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n",
        "    # Gini coefficient is derived from AUC\n",
        "    return 2 * auc - 1\n",
        "\n",
        "# Perform 1 iteration\n",
        "for i in range(1):\n",
        "    # Instantiate Random Forest classifier with random subspace\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "    # Train the Random Forest classifier\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_rf = rf_classifier.predict(X_test)\n",
        "    y_pred_proba_rf = rf_classifier.predict_proba(X_test)  # Get predicted probabilities\n",
        "\n",
        "    # Evaluate the Random Forest model's performance\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "    # Calculate Gini score using predicted probabilities\n",
        "    gini = gini_score(y_test, y_pred_proba_rf)\n",
        "\n",
        "    accuracies.append(accuracy_rf)\n",
        "    print(f\"Accuracy on test data (Random Forest with 0.5-second window size) for iteration {i + 1}: {accuracy_rf * 100:.2f}%\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"Gini Score: {gini:.2f}\")\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "    # Calculate Sensitivity and Specificity\n",
        "    sensitivity_specificity = {}\n",
        "    for label in np.unique(y_test):\n",
        "        tp = conf_matrix[label, label]  # True Positives\n",
        "        fn = conf_matrix[label, :].sum() - tp  # False Negatives\n",
        "        fp = conf_matrix[:, label].sum() - tp  # False Positives\n",
        "        tn = conf_matrix.sum() - (tp + fn + fp)  # True Negatives\n",
        "\n",
        "        # Calculate Sensitivity and Specificity\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        sensitivity_specificity[label] = {\n",
        "            'Sensitivity (Recall)': sensitivity,\n",
        "            'Specificity': specificity\n",
        "        }\n",
        "\n",
        "    # Print Sensitivity and Specificity for each label\n",
        "    for label, metrics in sensitivity_specificity.items():\n",
        "        print(f\"\\nLabel: {label}\")\n",
        "        print(f\"Sensitivity: {metrics['Sensitivity (Recall)']:.2f}\")\n",
        "        print(f\"Specificity: {metrics['Specificity']:.2f}\")"
      ],
      "metadata": {
        "id": "zpNMhVpYcbTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sensitivity_specificity = {}\n",
        "for i, label in enumerate(np.unique(y_test)):  # Enumerate to get numerical index 'i'\n",
        "    tp = conf_matrix[i, i]  # Use 'i' for indexing\n",
        "    fn = conf_matrix[i, :].sum() - tp\n",
        "    fp = conf_matrix[:, i].sum() - tp\n",
        "    tn = conf_matrix.sum() - (tp + fn + fp)\n",
        "\n",
        "    # Calculate Sensitivity and Specificity (Corrected Indentation)\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    sensitivity_specificity[label] = {\n",
        "        'Sensitivity (Recall)': sensitivity,\n",
        "        'Specificity': specificity\n",
        "    }\n",
        "\n",
        "# Print Sensitivity and Specificity for each label\n",
        "for label, metrics in sensitivity_specificity.items():\n",
        "    print(f\"\\nLabel: {label}\")\n",
        "    print(f\"Sensitivity: {metrics['Sensitivity (Recall)']:.2f}\")\n",
        "    print(f\"Specificity: {metrics['Specificity']:.2f}\")"
      ],
      "metadata": {
        "id": "vnYSMuJ0gSRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dictionary to store sensitivity and specificity for each label\n",
        "sensitivity_specificity = {}\n",
        "\n",
        "# Iterate over unique labels in the test set\n",
        "for i, label in enumerate(np.unique(y_test)):  # Enumerate to get numerical index 'i'\n",
        "    tp = conf_matrix[i, i]  # True Positive: correctly predicted instances of the current class\n",
        "    fn = conf_matrix[i, :].sum() - tp  # False Negative: instances of the current class not predicted as such\n",
        "    fp = conf_matrix[:, i].sum() - tp  # False Positive: instances predicted as the current class that aren't\n",
        "    tn = conf_matrix.sum() - (tp + fn + fp)  # True Negative: correctly predicted instances of other classes\n",
        "\n",
        "    # Calculate Sensitivity and Specificity\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # Sensitivity (Recall)\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Specificity\n",
        "\n",
        "    # Store the calculated metrics in the dictionary\n",
        "    sensitivity_specificity[label] = {\n",
        "        'Sensitivity (Recall)': sensitivity,\n",
        "        'Specificity': specificity\n",
        "    }\n",
        "\n",
        "# Print Sensitivity and Specificity for each label\n",
        "for label, metrics in sensitivity_specificity.items():\n",
        "    print(f\"\\nLabel: {label}\")\n",
        "    print(f\"Sensitivity: {metrics['Sensitivity (Recall)']:.2f}\")\n",
        "    print(f\"Specificity: {metrics['Specificity']:.2f}\")"
      ],
      "metadata": {
        "id": "GvRLS7Pig0MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize overall metrics\n",
        "total_tp = 0  # Total True Positives\n",
        "total_fn = 0  # Total False Negatives\n",
        "total_fp = 0  # Total False Positives\n",
        "total_tn = 0  # Total True Negatives\n",
        "\n",
        "# Calculate total TP, FN, FP, and TN across all labels\n",
        "for i in range(len(np.unique(y_test))):\n",
        "    tp = conf_matrix[i, i]  # True Positive\n",
        "    fn = conf_matrix[i, :].sum() - tp  # False Negative\n",
        "    fp = conf_matrix[:, i].sum() - tp  # False Positive\n",
        "    tn = conf_matrix.sum() - (tp + fn + fp)  # True Negative\n",
        "\n",
        "    total_tp += tp\n",
        "    total_fn += fn\n",
        "    total_fp += fp\n",
        "    total_tn += tn\n",
        "\n",
        "# Calculate overall Sensitivity and Specificity\n",
        "overall_sensitivity = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "overall_specificity = total_tn / (total_tn + total_fp) if (total_tn + total_fp) > 0 else 0\n",
        "\n",
        "# Print overall Sensitivity and Specificity\n",
        "print(f\"\\nOverall Sensitivity (Recall): {overall_sensitivity:.2f}\")\n",
        "print(f\"Overall Specificity: {overall_specificity:.2f}\")\n"
      ],
      "metadata": {
        "id": "d7XXMbfghX8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Calculate time difference\n",
        "time_diff = data['date'].diff().dropna()  # Drop NA values and calculate time difference\n",
        "\n",
        "# Calculate frequency (assuming uniform sampling)\n",
        "mean_time_diff = time_diff.mean()\n",
        "frequency = 1 / mean_time_diff.total_seconds()  # Convert to Hz\n",
        "\n",
        "print(\"Sampling frequency for combined data:\", frequency, \"Hz\")\n",
        "\n",
        "# Calculate window size based on frequency\n",
        "window_duration = 0.5  # Seconds\n",
        "window_size = int(frequency * window_duration)\n",
        "\n",
        "if window_size == 0:\n",
        "    print(\"Window size is zero, adjusting to 1\")\n",
        "    window_size = 1\n",
        "\n",
        "# Extract windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "for i in range(0, len(data), window_size):\n",
        "    window = data.iloc[i:i+window_size]\n",
        "    if len(window) == window_size:\n",
        "        # Compute mean values as features for this window\n",
        "        window_features = window.mean()\n",
        "        window_label = window['label'].iloc[0]\n",
        "        windowed_features.append(window_features)\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X = pd.DataFrame(windowed_features).drop(columns=['date'])  # Drop 'date' column for features\n",
        "y = np.array(windowed_labels)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test accuracy for combined data:\", accuracy * 100, \"%\")\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate overall sensitivity and specificity\n",
        "total_tp = 0  # Total True Positives\n",
        "total_fn = 0  # Total False Negatives\n",
        "total_fp = 0  # Total False Positives\n",
        "total_tn = 0  # Total True Negatives\n",
        "\n",
        "# Loop through the confusion matrix to aggregate TP, FN, FP, TN\n",
        "num_classes = conf_matrix.shape[0]  # Get number of classes\n",
        "\n",
        "for i in range(num_classes):\n",
        "    TP = conf_matrix[i, i]  # True Positive for class i\n",
        "    FN = conf_matrix[i, :].sum() - TP  # False Negative for class i\n",
        "    FP = conf_matrix[:, i].sum() - TP  # False Positive for class i\n",
        "    TN = conf_matrix.sum() - (TP + FN + FP)  # True Negative for class i\n",
        "\n",
        "    total_tp += TP\n",
        "    total_fn += FN\n",
        "    total_fp += FP\n",
        "    total_tn += TN\n",
        "\n",
        "# Calculate overall sensitivity and specificity\n",
        "overall_sensitivity = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "overall_specificity = total_tn / (total_tn + total_fp) if (total_tn + total_fp) > 0 else 0\n",
        "\n",
        "# Print overall sensitivity and specificity\n",
        "print(f\"\\nOverall Sensitivity (Recall): {overall_sensitivity:.2f}\")\n",
        "print(f\"Overall Specificity: {overall_specificity:.2f}\")"
      ],
      "metadata": {
        "id": "Gy3_GzQjekjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"dataset_6.csv\")\n",
        "\n",
        "# Define window size\n",
        "window_size = 15  # Approximately 15 data points for 0.5 seconds\n",
        "\n",
        "# Initialize lists to store windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "# Segment the time-series data into windows\n",
        "for i in range(0, len(data) - window_size + 1, window_size):\n",
        "    window = data.iloc[i:i + window_size]\n",
        "    if len(window) == window_size:  # Ensure the window is complete\n",
        "        # Extract features from the window\n",
        "        window_features = {\n",
        "            'mean_acc_x': window['acc_x'].mean(),\n",
        "            'mean_acc_y': window['acc_y'].mean(),\n",
        "            'mean_acc_z': window['acc_z'].mean(),\n",
        "            'std_acc_x': window['acc_x'].std(),\n",
        "            'std_acc_y': window['acc_y'].std(),\n",
        "            'std_acc_z': window['acc_z'].std(),\n",
        "            'skew_acc_x': window['acc_x'].skew(),\n",
        "            'skew_acc_y': window['acc_y'].skew(),\n",
        "            'skew_acc_z': window['acc_z'].skew(),\n",
        "            'kurt_acc_x': window['acc_x'].kurt(),\n",
        "            'kurt_acc_y': window['acc_y'].kurt(),\n",
        "            'kurt_acc_z': window['acc_z'].kurt()\n",
        "        }\n",
        "        windowed_features.append(window_features)\n",
        "\n",
        "        # Assign label to the window (assuming it's the same for all samples within the window)\n",
        "        window_label = window['label'].iloc[0]\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X_windowed = pd.DataFrame(windowed_features)\n",
        "y_windowed = np.array(windowed_labels)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_windowed)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_windowed)\n",
        "\n",
        "# Split the data into train and test using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "# Train the Random Forest classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest model's performance\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "# Print metrics for this single iteration\n",
        "print(\"Single Iteration Performance:\")\n",
        "print(f\"  Accuracy: {accuracy_rf * 100:.2f}%\")\n",
        "print(f\"  F1 Score: {f1:.2f}\")\n",
        "print(f\"  Precision: {precision:.2f}\")\n",
        "print(f\"  Recall: {recall:.2f}\")\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Calculate overall sensitivity and specificity\n",
        "total_tp = conf_matrix.diagonal().sum()  # Total True Positives\n",
        "total_fn = conf_matrix.sum(axis=1).sum() - total_tp  # Total False Negatives\n",
        "total_fp = conf_matrix.sum(axis=0).sum() - total_tp  # Total False Positives\n",
        "total_tn = conf_matrix.sum() - (total_tp + total_fn + total_fp)  # Total True Negatives\n",
        "\n",
        "overall_sensitivity = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "overall_specificity = total_tn / (total_tn + total_fp) if (total_tn + total_fp) > 0 else 0\n",
        "\n",
        "# Print overall sensitivity and specificity\n",
        "print(f\"Overall Sensitivity (Recall): {overall_sensitivity:.2f}\")\n",
        "print(f\"Overall Specificity: {overall_specificity:.2f}\")\n",
        "\n",
        "# Plot confusion matrix for the single iteration\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VBsUSQb8f7qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the dataset (replace 'CURC.csv' with your actual file path)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Convert the 'Time' column to datetime format (assuming Time is in HH:MM:SS format)\n",
        "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S').dt.time\n",
        "\n",
        "# Define a larger window size in seconds\n",
        "window_size_seconds = 6  # Adjust this value as needed\n",
        "window_size_samples = window_size_seconds  # 6 seconds = 6 data points\n",
        "\n",
        "# Initialize lists to store windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "# Segment the time-series data into windows\n",
        "for i in range(0, len(data) - window_size_samples + 1, window_size_samples):\n",
        "    window = data.iloc[i:i + window_size_samples]\n",
        "    if len(window) == window_size_samples:  # Ensure the window is complete\n",
        "        # Extract features from the window\n",
        "        window_features = {\n",
        "            'mean_x': window['X-axis (g)'].mean(),\n",
        "            'mean_y': window['Y-axis (g)'].mean(),\n",
        "            'mean_z': window['Z-axis (g)'].mean(),\n",
        "            'std_x': window['X-axis (g)'].std(),\n",
        "            'std_y': window['Y-axis (g)'].std(),\n",
        "            'std_z': window['Z-axis (g)'].std(),\n",
        "            'skew_x': window['X-axis (g)'].skew(),\n",
        "            'skew_y': window['Y-axis (g)'].skew(),\n",
        "            'skew_z': window['Z-axis (g)'].skew(),\n",
        "            'kurt_x': window['X-axis (g)'].kurt(),\n",
        "            'kurt_y': window['Y-axis (g)'].kurt(),\n",
        "            'kurt_z': window['Z-axis (g)'].kurt()\n",
        "        }\n",
        "        windowed_features.append(window_features)\n",
        "\n",
        "        # Assign labels to the window based on 'IteragreementLocom' and 'IteragreementFeeding'\n",
        "        locomotion_label = window['IteragreementLocom'].mode().iloc[0]\n",
        "        feeding_label = window['IteragreementFeeding'].mode().iloc[0]\n",
        "        combined_label = f\"{locomotion_label}{feeding_label}\"\n",
        "        windowed_labels.append(combined_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X_windowed = pd.DataFrame(windowed_features)\n",
        "y_windowed = np.array(windowed_labels)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_windowed)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_windowed)\n",
        "\n",
        "# Split the data into train and test using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "# Perform 10 iterations\n",
        "for i in range(1):\n",
        "    # Instantiate Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "    # Train the Random Forest classifier\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the Random Forest model's performance\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "    # Append metrics to lists\n",
        "    accuracies.append(accuracy_rf)\n",
        "    f1_scores.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "    print(f\"Iteration {i + 1}:\")\n",
        "    print(f\"  Accuracy: {accuracy_rf * 100:.2f}%\")\n",
        "    print(f\"  F1 Score: {f1:.2f}\")\n",
        "    print(f\"  Precision: {precision:.2f}\")\n",
        "    print(f\"  Recall: {recall:.2f}\")\n",
        "\n",
        "# Print average metrics\n",
        "print(\"\\nAverage Metrics over 10 iterations:\")\n",
        "print(f\"  Average Accuracy: {np.mean(accuracies) * 100:.2f}%\")\n",
        "print(f\"  Average F1 Score: {np.mean(f1_scores):.2f}\")\n",
        "print(f\"  Average Precision: {np.mean(precisions):.2f}\")\n",
        "print(f\"  Average Recall: {np.mean(recalls):.2f}\")\n",
        "\n",
        "# Calculate confusion matrix and derive specificity\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()  # Assuming binary classification\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "print(f\"\\nOverall Sensitivity (Recall): {sensitivity:.2f}\")\n",
        "print(f\"Overall Specificity: {specificity:.2f}\")"
      ],
      "metadata": {
        "id": "JY2EkRrIf7s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "model_accuracies = [92.72, 93.41, 99.97, 90.17, 86.08]\n",
        "published_accuracies = [85.67, 94.43, \"NA\", 87.15, \"NA\"]\n",
        "f1_scores = [0.93, 0.93, 1.00, 0.90, 0.86]\n",
        "\n",
        "# Filter out 'NA' values\n",
        "filtered_published_accuracies = [acc if acc != 'NA' else None for acc in published_accuracies]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "bar_width = 0.25\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Plot model accuracies with solid color\n",
        "bars_model = plt.bar(index, model_accuracies, bar_width, label='Model Accuracy', color='skyblue', edgecolor='black', hatch='')\n",
        "\n",
        "# Plot published accuracies with dashed color\n",
        "bars_published = plt.bar([i + bar_width for i in index if published_accuracies[i] != 'NA'],\n",
        "                         [acc for acc in filtered_published_accuracies if acc is not None],\n",
        "                         bar_width, label='Published Accuracy', color='lightgreen', edgecolor='black', hatch='//')\n",
        "\n",
        "# Plot F1 scores with dotted color\n",
        "bars_f1 = plt.bar([i + 2 * bar_width for i in index], f1_scores, bar_width, label='F1 Score', color='salmon', edgecolor='black', hatch='..')\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Dataset', fontsize=14)\n",
        "plt.ylabel('Scores', fontsize=14)\n",
        "\n",
        "# Align x-axis labels with bars\n",
        "plt.xticks([i + bar_width for i in index], datasets, fontsize=12)\n",
        "\n",
        "plt.legend(fontsize=12)\n",
        "\n",
        "# Annotate bars with values\n",
        "for bar in bars_model:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5, f\"{yval:.1f}%\", ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "for bar in bars_published:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5, f\"{yval:.1f}%\", ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "for bar in bars_f1:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.05, f\"{yval:.2f}\", ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IP1RckUXf7wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "model_accuracies = [92.72, 93.41, 99.97, 90.17, 86.08]\n",
        "published_accuracies = [85.67, 94.43, \"NA\", 87.15, \"NA\"]\n",
        "f1_scores = [0.93, 0.93, 1.00, 0.90, 0.86]\n",
        "\n",
        "# Filter out 'NA' values\n",
        "filtered_published_accuracies = [acc if acc != 'NA' else None for acc in published_accuracies]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "bar_width = 0.25\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Plot model accuracies with solid color\n",
        "bars_model = plt.bar(index, model_accuracies, bar_width, label='Model Accuracy', color='skyblue', edgecolor='black', hatch='')\n",
        "\n",
        "# Plot published accuracies with dashed color\n",
        "bars_published = plt.bar([i + bar_width for i in index if published_accuracies[i] != 'NA'],\n",
        "                         [acc for acc in filtered_published_accuracies if acc is not None],\n",
        "                         bar_width, label='Published Accuracy', color='lightgreen', edgecolor='black', hatch='//')\n",
        "\n",
        "# Plot F1 scores with dotted color\n",
        "bars_f1 = plt.bar([i + 2 * bar_width for i in index], [score * 100 for score in f1_scores],\n",
        "                   bar_width, label='F1 Score (%)', color='salmon', edgecolor='black', hatch='..')\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Dataset', fontsize=14)\n",
        "plt.ylabel('Scores', fontsize=14)\n",
        "\n",
        "# Align x-axis labels with bars\n",
        "plt.xticks([i + bar_width for i in index], datasets, fontsize=12)\n",
        "\n",
        "plt.legend(fontsize=12)\n",
        "\n",
        "# Annotate bars with values\n",
        "for bar in bars_model:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5, f\"{yval:.1f}%\", ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "for bar in bars_published:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5, f\"{yval:.1f}%\", ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "for bar in bars_f1:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5, f\"{yval:.1f}%\", ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O7hbsY54m2y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "model_accuracies = [92.72, 93.41, 99.97, 90.17, 86.08]\n",
        "published_accuracies = [85.67, 94.43, \"NA\", 87.15, \"NA\"]\n",
        "f1_scores = [0.93, 0.93, 1.00, 0.90, 0.86]\n",
        "\n",
        "# Filter out 'NA' values\n",
        "filtered_published_accuracies = [acc if acc != 'NA' else None for acc in published_accuracies]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "bar_width = 0.25\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Plot model accuracies with solid color\n",
        "bars_model = plt.bar(index, model_accuracies, bar_width, label='Model Accuracy', color='skyblue', edgecolor='black', hatch='')\n",
        "\n",
        "# Plot published accuracies with dashed color\n",
        "bars_published = plt.bar([i + bar_width for i in index if published_accuracies[i] != 'NA'],\n",
        "                         [acc for acc in filtered_published_accuracies if acc is not None],\n",
        "                         bar_width, label='Published Accuracy', color='lightgreen', edgecolor='black', hatch='//')\n",
        "\n",
        "# Plot F1 scores with dotted color\n",
        "bars_f1 = plt.bar([i + 2 * bar_width for i in index], [score * 100 for score in f1_scores],\n",
        "                   bar_width, label='F1 Score (%)', color='salmon', edgecolor='black', hatch='..')\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Dataset', fontsize=14)\n",
        "plt.ylabel('Scores', fontsize=14)\n",
        "\n",
        "# Align x-axis labels with bars\n",
        "plt.xticks([i + bar_width for i in index], datasets, fontsize=12)\n",
        "\n",
        "plt.legend(fontsize=12)\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid for better readability\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6UV-O1wdnAxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "model_accuracies = [92.72, 93.41, 99.97, 90.17, 86.08]\n",
        "published_accuracies = [85.67, 94.43, \"NA\", 87.15, \"NA\"]\n",
        "f1_scores = [0.93, 0.93, 1.00, 0.90, 0.86]\n",
        "\n",
        "# Filter out 'NA' values\n",
        "filtered_published_accuracies = [acc if acc != 'NA' else None for acc in published_accuracies]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "bar_width = 0.25\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Plot model accuracies with solid color\n",
        "bars_model = plt.bar(index, model_accuracies, bar_width, label='Model Accuracy', color='skyblue', edgecolor='black', hatch='')\n",
        "\n",
        "# Plot published accuracies with dashed color\n",
        "bars_published = plt.bar([i + bar_width for i in index if published_accuracies[i] != 'NA'],\n",
        "                         [acc for acc in filtered_published_accuracies if acc is not None],\n",
        "                         bar_width, label='Published Accuracy', color='lightgreen', edgecolor='black', hatch='//')\n",
        "\n",
        "# Plot F1 scores with dotted color\n",
        "bars_f1 = plt.bar([i + 2 * bar_width for i in index], [score * 100 for score in f1_scores],\n",
        "                   bar_width, label='F1 Score (%)', color='salmon', edgecolor='black', hatch='..')\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Dataset', fontsize=18)  # Increased font size\n",
        "plt.ylabel('Scores', fontsize=18)    # Increased font size\n",
        "\n",
        "# Align x-axis labels with bars\n",
        "plt.xticks([i + bar_width for i in index], datasets, fontsize=16)  # Increased font size\n",
        "\n",
        "plt.legend(fontsize=16)  # Increased font size\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GKGqFMqVnKYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "model_accuracies = [92.72, 93.41, 99.97, 90.17, 86.08]\n",
        "published_accuracies = [85.67, 94.43, \"NA\", 87.15, \"NA\"]\n",
        "f1_scores = [0.93, 0.93, 1.00, 0.90, 0.86]\n",
        "\n",
        "# Filter out 'NA' values\n",
        "filtered_published_accuracies = [acc if acc != 'NA' else None for acc in published_accuracies]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "bar_width = 0.25\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Plot model accuracies with solid color\n",
        "bars_model = plt.bar(index, model_accuracies, bar_width, label='Model Accuracy', color='skyblue', edgecolor='black', hatch='')\n",
        "\n",
        "# Plot published accuracies with dashed color\n",
        "bars_published = plt.bar([i + bar_width for i in index if published_accuracies[i] != 'NA'],\n",
        "                         [acc for acc in filtered_published_accuracies if acc is not None],\n",
        "                         bar_width, label='Published Accuracy', color='lightgreen', edgecolor='black', hatch='//')\n",
        "\n",
        "# Plot F1 scores with dotted color\n",
        "bars_f1 = plt.bar([i + 2 * bar_width for i in index], [score * 100 for score in f1_scores],\n",
        "                   bar_width, label='F1 Score (%)', color='salmon', edgecolor='black', hatch='..')\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Dataset', fontsize=18)  # Increased font size\n",
        "plt.ylabel('Scores', fontsize=18)    # Increased font size\n",
        "\n",
        "# Align x-axis labels with bars\n",
        "plt.xticks([i + bar_width for i in index], datasets, fontsize=16)  # Increased font size\n",
        "plt.yticks(fontsize=16)  # Increased font size for Y-axis tick labels\n",
        "\n",
        "plt.legend(fontsize=16)  # Increased font size\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N903WH7qnj8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "model_accuracies = [92.72, 93.41, 99.97, 90.17, 86.08]\n",
        "published_accuracies = [85.67, 94.43, \"NA\", 87.15, \"NA\"]\n",
        "f1_scores = [0.93, 0.93, 1.00, 0.90, 0.86]\n",
        "\n",
        "# Filter out 'NA' values\n",
        "filtered_published_accuracies = [acc if acc != 'NA' else None for acc in published_accuracies]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "bar_width = 0.25\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Plot model accuracies with solid color\n",
        "bars_model = plt.bar(index, model_accuracies, bar_width, label='Model Accuracy', color='skyblue', edgecolor='black', hatch='')\n",
        "\n",
        "# Plot published accuracies with dashed color\n",
        "bars_published = plt.bar([i + bar_width for i in index if published_accuracies[i] != 'NA'],\n",
        "                         [acc for acc in filtered_published_accuracies if acc is not None],\n",
        "                         bar_width, label='Published Accuracy', color='lightgreen', edgecolor='black', hatch='//')\n",
        "\n",
        "# Plot F1 scores with dotted color\n",
        "bars_f1 = plt.bar([i + 2 * bar_width for i in index], [score * 100 for score in f1_scores],\n",
        "                   bar_width, label='F1 Score', color='salmon', edgecolor='black', hatch='..')\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Dataset', fontsize=18)  # Increased font size\n",
        "plt.ylabel('Scores', fontsize=18)    # Increased font size\n",
        "\n",
        "# Align x-axis labels with bars\n",
        "plt.xticks([i + bar_width for i in index], datasets, fontsize=16)  # Increased font size\n",
        "plt.yticks(fontsize=16)  # Increased font size for Y-axis tick labels\n",
        "\n",
        "# Move the legend below the plot\n",
        "plt.legend(fontsize=16, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)  # Adjust ncol for layout\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fi36mlFhnz-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "model_accuracies = [92.72, 93.41, 99.97, 90.17, 86.08]\n",
        "published_accuracies = [85.67, 94.43, \"NA\", 87.15, \"NA\"]\n",
        "f1_scores = [0.93, 0.93, 1.00, 0.90, 0.86]\n",
        "\n",
        "# Filter out 'NA' values\n",
        "filtered_published_accuracies = [acc if acc != 'NA' else None for acc in published_accuracies]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "bar_width = 0.25\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Define darker shades for bars\n",
        "model_color = '#87ceeb'          # Darker light blue for Model Accuracy\n",
        "published_color = '#ffcc99'      # Darker light green for Published Accuracy\n",
        "f1_color = '#ff9999'             # Darker light pink for F1 Score\n",
        "\n",
        "# Plot model accuracies with solid color\n",
        "bars_model = plt.bar(index, model_accuracies, bar_width, label='Model Accuracy', color=model_color, edgecolor='black')\n",
        "\n",
        "# Plot published accuracies with dashed color\n",
        "bars_published = plt.bar([i + bar_width for i in index if published_accuracies[i] != 'NA'],\n",
        "                         [acc for acc in filtered_published_accuracies if acc is not None],\n",
        "                         bar_width, label='Published Accuracy', color=published_color, edgecolor='black', hatch='//')\n",
        "\n",
        "# Plot F1 scores with dotted color\n",
        "bars_f1 = plt.bar([i + 2 * bar_width for i in index], [score * 100 for score in f1_scores],\n",
        "                   bar_width, label='F1 Score', color=f1_color, edgecolor='black', hatch='..')\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Dataset', fontsize=18, fontweight='bold')  # Increased font size and bold\n",
        "plt.ylabel('Scores', fontsize=18, fontweight='bold')    # Increased font size and bold\n",
        "\n",
        "# Align x-axis labels with bars\n",
        "plt.xticks([i + bar_width for i in index], datasets, fontsize=16, fontweight='bold')  # Increased font size and bold\n",
        "plt.yticks(fontsize=16, fontweight='bold')  # Increased font size and bold for Y-axis tick labels\n",
        "\n",
        "# Move the legend below the plot\n",
        "plt.legend(fontsize=16, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)  # Adjust ncol for layout\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IZk0-uOuqNpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "model_accuracies = [92.72, 93.41, 99.97, 90.17, 86.08]\n",
        "published_accuracies = [85.67, 94.43, \"NA\", 87.15, \"NA\"]\n",
        "f1_scores = [0.93, 0.93, 1.00, 0.90, 0.86]\n",
        "\n",
        "# Filter out 'NA' values\n",
        "filtered_published_accuracies = [acc if acc != 'NA' else None for acc in published_accuracies]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "bar_width = 0.25\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Define original colors for bars\n",
        "model_color = 'skyblue'          # Original color for Model Accuracy\n",
        "published_color = 'lightgreen'   # Original color for Published Accuracy\n",
        "f1_color = 'salmon'              # Original color for F1 Score\n",
        "\n",
        "# Plot model accuracies with solid color\n",
        "bars_model = plt.bar(index, model_accuracies, bar_width, label='Model Accuracy', color=model_color, edgecolor='black')\n",
        "\n",
        "# Plot published accuracies with dashed color\n",
        "bars_published = plt.bar([i + bar_width for i in index if published_accuracies[i] != 'NA'],\n",
        "                         [acc for acc in filtered_published_accuracies if acc is not None],\n",
        "                         bar_width, label='Published Accuracy', color=published_color, edgecolor='black', hatch='//')\n",
        "\n",
        "# Plot F1 scores with dotted color\n",
        "bars_f1 = plt.bar([i + 2 * bar_width for i in index], [score * 100 for score in f1_scores],\n",
        "                   bar_width, label='F1 Score', color=f1_color, edgecolor='black', hatch='..')\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Dataset', fontsize=18, fontweight='bold')  # Increased font size and bold\n",
        "plt.ylabel('Scores', fontsize=18, fontweight='bold')    # Increased font size and bold\n",
        "\n",
        "# Align x-axis labels with bars\n",
        "plt.xticks([i + bar_width for i in index], datasets, fontsize=16, fontweight='bold')  # Increased font size and bold\n",
        "plt.yticks(fontsize=16, fontweight='bold')  # Increased font size and bold for Y-axis tick labels\n",
        "\n",
        "# Move the legend below the plot\n",
        "plt.legend(fontsize=16, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)  # Adjust ncol for layout\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F6_t3XUmqZ18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "datasets = ['1', '2', '3', '4', '5']\n",
        "model_accuracies = [92.72, 93.41, 99.97, 90.17, 86.08]\n",
        "published_accuracies = [85.67, 94.43, \"NA\", 87.15, \"NA\"]\n",
        "f1_scores = [0.93, 0.93, 1.00, 0.90, 0.86]\n",
        "\n",
        "# Filter out 'NA' values\n",
        "filtered_published_accuracies = [acc if acc != 'NA' else None for acc in published_accuracies]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "bar_width = 0.25\n",
        "index = range(len(datasets))\n",
        "\n",
        "# Define original colors for bars\n",
        "model_color = 'skyblue'          # Original color for Model Accuracy\n",
        "published_color = 'lightgreen'   # Original color for Published Accuracy\n",
        "f1_color = 'salmon'              # Original color for F1 Score\n",
        "\n",
        "# Plot model accuracies with solid color\n",
        "bars_model = plt.bar(index, model_accuracies, bar_width, label='Model Accuracy', color=model_color, edgecolor='black')\n",
        "\n",
        "# Plot published accuracies with dashed color\n",
        "bars_published = plt.bar([i + bar_width for i in index if published_accuracies[i] != 'NA'],\n",
        "                         [acc for acc in filtered_published_accuracies if acc is not None],\n",
        "                         bar_width, label='Published Accuracy', color=published_color, edgecolor='black', hatch='//')\n",
        "\n",
        "# Plot F1 scores with dotted color\n",
        "bars_f1 = plt.bar([i + 2 * bar_width for i in index], [score * 100 for score in f1_scores],\n",
        "                   bar_width, label='F1 Score', color=f1_color, edgecolor='black', hatch='..')\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Dataset', fontsize=18, fontweight='bold')  # Increased font size and bold\n",
        "plt.ylabel('Test Accuracy %', fontsize=18, fontweight='bold')    # Increased font size and bold\n",
        "\n",
        "# Align x-axis labels with bars\n",
        "plt.xticks([i + bar_width for i in index], datasets, fontsize=16, fontweight='bold')  # Increased font size and bold\n",
        "plt.yticks(fontsize=16, fontweight='bold')  # Increased font size and bold for Y-axis tick labels\n",
        "\n",
        "# Move the legend below the plot\n",
        "plt.legend(fontsize=16, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)  # Adjust ncol for layout\n",
        "\n",
        "# Improve layout and show plot\n",
        "plt.tight_layout()\n",
        "plt.grid(False)  # Remove grid\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W1b14mNUq7hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the dataset (replace 'CURC.csv' with your actual file path)\n",
        "data = pd.read_csv('CURC.csv')\n",
        "\n",
        "# Convert the 'Time' column to datetime format (assuming Time is in HH:MM:SS format)\n",
        "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S').dt.time\n",
        "\n",
        "# Define a larger window size in seconds\n",
        "window_size_seconds = 6  # Adjust this value as needed\n",
        "window_size_samples = window_size_seconds  # 6 seconds = 6 data points\n",
        "\n",
        "# Initialize lists to store windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "# Segment the time-series data into windows\n",
        "for i in range(0, len(data) - window_size_samples + 1, window_size_samples):\n",
        "    window = data.iloc[i:i + window_size_samples]\n",
        "    if len(window) == window_size_samples:  # Ensure the window is complete\n",
        "        # Extract features from the window\n",
        "        window_features = {\n",
        "            'mean_x': window['X-axis (g)'].mean(),\n",
        "            'mean_y': window['Y-axis (g)'].mean(),\n",
        "            'mean_z': window['Z-axis (g)'].mean(),\n",
        "            'std_x': window['X-axis (g)'].std(),\n",
        "            'std_y': window['Y-axis (g)'].std(),\n",
        "            'std_z': window['Z-axis (g)'].std(),\n",
        "            'skew_x': window['X-axis (g)'].skew(),\n",
        "            'skew_y': window['Y-axis (g)'].skew(),\n",
        "            'skew_z': window['Z-axis (g)'].skew(),\n",
        "            'kurt_x': window['X-axis (g)'].kurt(),\n",
        "            'kurt_y': window['Y-axis (g)'].kurt(),\n",
        "            'kurt_z': window['Z-axis (g)'].kurt()\n",
        "        }\n",
        "        windowed_features.append(window_features)\n",
        "\n",
        "        # Assign labels to the window based on 'IteragreementLocom' and 'IteragreementFeeding'\n",
        "        locomotion_label = window['IteragreementLocom'].mode().iloc[0]\n",
        "        feeding_label = window['IteragreementFeeding'].mode().iloc[0]\n",
        "        combined_label = f\"{locomotion_label}{feeding_label}\"\n",
        "        windowed_labels.append(combined_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X_windowed = pd.DataFrame(windowed_features)\n",
        "y_windowed = np.array(windowed_labels)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_windowed)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_windowed)\n",
        "\n",
        "# Split the data into train and test using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "# Perform 10 iterations\n",
        "for i in range(1):\n",
        "    # Instantiate Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
        "\n",
        "    # Train the Random Forest classifier\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the Random Forest model's performance\n",
        "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "    # Append metrics to lists\n",
        "    accuracies.append(accuracy_rf)\n",
        "    f1_scores.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "    print(f\"Iteration {i + 1}:\")\n",
        "    print(f\"  Accuracy: {accuracy_rf * 100:.2f}%\")\n",
        "    print(f\"  F1 Score: {f1:.2f}\")\n",
        "    print(f\"  Precision: {precision:.2f}\")\n",
        "    print(f\"  Recall: {recall:.2f}\")\n",
        "\n",
        "# Print average metrics\n",
        "print(\"\\nAverage Metrics over 10 iterations:\")\n",
        "print(f\"  Average Accuracy: {np.mean(accuracies) * 100:.2f}%\")\n",
        "print(f\"  Average F1 Score: {np.mean(f1_scores):.2f}\")\n",
        "print(f\"  Average Precision: {np.mean(precisions):.2f}\")\n",
        "print(f\"  Average Recall: {np.mean(recalls):.2f}\")\n",
        "\n",
        "# Calculate confusion matrix and display it\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Compute specificity and sensitivity for each class\n",
        "sensitivity_per_class = []\n",
        "specificity_per_class = []\n",
        "total_true_negatives = 0\n",
        "total_false_positives = 0\n",
        "\n",
        "for i in range(len(conf_matrix)):\n",
        "    # Sensitivity for class i (True Positive Rate)\n",
        "    true_positive = conf_matrix[i, i]\n",
        "    false_negative = conf_matrix[i, :].sum() - true_positive\n",
        "    sensitivity = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
        "    sensitivity_per_class.append(sensitivity)\n",
        "\n",
        "    # Specificity for class i (True Negative Rate)\n",
        "    false_positive = conf_matrix[:, i].sum() - true_positive\n",
        "    true_negative = conf_matrix.sum() - (false_positive + false_negative + true_positive)\n",
        "    specificity = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
        "    specificity_per_class.append(specificity)\n",
        "\n",
        "    # Sum overall true negatives and false positives for global specificity\n",
        "    total_true_negatives += true_negative\n",
        "    total_false_positives += false_positive\n",
        "\n",
        "# Overall Sensitivity (weighted average of sensitivities)\n",
        "overall_sensitivity = np.mean(sensitivity_per_class)\n",
        "# Overall Specificity (based on global confusion matrix)\n",
        "overall_specificity = total_true_negatives / (total_true_negatives + total_false_positives)\n",
        "\n",
        "print(f\"\\nOverall Sensitivity (Recall): {overall_sensitivity:.2f}\")\n",
        "print(f\"Overall Specificity: {overall_specificity:.2f}\")\n",
        "\n",
        "# Display classification report (includes precision, recall, and F1-score for each class)\n",
        "class_report = classification_report(y_test, y_pred_rf)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "c9WI6hLsn9jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lazypredict"
      ],
      "metadata": {
        "id": "VXnoz2m-Paok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn pandas numpy"
      ],
      "metadata": {
        "id": "Mu6yYJ3fPgk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "# Replace 'CURC.csv' with the correct path to your file\n",
        "data = pd.read_csv('/content/AX3_RAW_DATA06272024_ok.csv')\n",
        "\n",
        "# Convert the 'Time' column to datetime (if applicable)\n",
        "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M:%S').dt.time\n",
        "\n",
        "# Preview the dataset\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "\n",
        "# Step 2: Define Features and Target\n",
        "# Replace 'acc_x', 'acc_y', 'acc_z' with your feature columns\n",
        "# Replace 'behavior' with your target column\n",
        "X = data[['acc_x', 'acc_y', 'acc_z']]\n",
        "y = data['behavior']\n",
        "\n",
        "# Check for missing values\n",
        "print(X.isnull().sum())\n",
        "print(y.isnull().sum())\n",
        "\n",
        "# Handle missing values if necessary\n",
        "X = X.fillna(0)  # Replace missing values with 0 (adjust if needed)\n",
        "\n",
        "# Step 3: Split Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 4: Use Lazy Predict for Classification\n",
        "# Initialize LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "\n",
        "# Fit models and evaluate\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display results\n",
        "print(models)\n",
        "\n",
        "# Step 5: Save Results to CSV (Optional)\n",
        "models.to_csv('model_comparison.csv', index=False)"
      ],
      "metadata": {
        "id": "P1Md6nT6OdPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libraries\n",
        "#DATASET 5\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset (replace 'CURC.csv' with your actual file path)\n",
        "data = pd.read_csv('/content/AX3_RAW_DATA06272024_ok.csv')\n",
        "\n",
        "# Step 1: Combine relevant columns to create a behavior label\n",
        "# Combine 'IteragreementLocom' and 'IteragreementFeeding' into a single 'Behavior' column\n",
        "data['Behavior'] = data['IteragreementLocom'].astype(str) + '-' + data['IteragreementFeeding'].astype(str)\n",
        "\n",
        "# Step 2: Encode the 'Behavior' column to numeric labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['Behavior_Label'] = label_encoder.fit_transform(data['Behavior'])\n",
        "\n",
        "# Print the mapping of behaviors to numeric labels\n",
        "print(\"Behavior Mapping:\")\n",
        "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
        "\n",
        "# Step 3: Define features (accelerometer data) and target (behavior labels)\n",
        "X = data[['X-axis (g)', 'Y-axis (g)', 'Z-axis (g)']]  # Feature columns\n",
        "y = data['Behavior_Label']                           # Target column\n",
        "\n",
        "# Step 4: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 5: Initialize LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "\n",
        "# Step 6: Fit LazyClassifier on the training data and evaluate on the test data\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nLazyClassifier Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the LazyClassifier results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Step 7: Visualize behavior labels (optional)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "data['Behavior'].value_counts().plot(kind='bar')\n",
        "plt.title('Behavior Label Distribution')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HXiABCfhParv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example LazyClassifier results as a DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# Replace this with your LazyClassifier results DataFrame\n",
        "data = {\n",
        "    \"Model\": [\n",
        "        \"XGBClassifier\", \"LGBMClassifier\", \"KNeighborsClassifier\", \"RandomForestClassifier\",\n",
        "        \"BaggingClassifier\", \"LabelSpreading\", \"PassiveAggressiveClassifier\",\n",
        "        \"DecisionTreeClassifier\", \"LabelPropagation\", \"NearestCentroid\",\n",
        "        \"ExtraTreesClassifier\", \"GaussianNB\", \"ExtraTreeClassifier\", \"AdaBoostClassifier\",\n",
        "        \"QuadraticDiscriminantAnalysis\", \"SVC\", \"SGDClassifier\", \"BernoulliNB\",\n",
        "        \"Perceptron\", \"LogisticRegression\", \"LinearDiscriminantAnalysis\",\n",
        "        \"LinearSVC\", \"CalibratedClassifierCV\", \"RidgeClassifierCV\", \"RidgeClassifier\",\n",
        "        \"DummyClassifier\"\n",
        "    ],\n",
        "    \"Accuracy\": [\n",
        "        0.64, 0.65, 0.63, 0.63, 0.61, 0.62, 0.55, 0.57, 0.61, 0.49, 0.61, 0.59,\n",
        "        0.55, 0.58, 0.60, 0.63, 0.58, 0.58, 0.45, 0.58, 0.58, 0.58, 0.58, 0.58,\n",
        "        0.58, 0.57\n",
        "    ],\n",
        "    \"Balanced Accuracy\": [\n",
        "        0.49, 0.48, 0.47, 0.47, 0.47, 0.46, 0.46, 0.46, 0.46, 0.46, 0.44, 0.44,\n",
        "        0.43, 0.43, 0.41, 0.41, 0.41, 0.40, 0.39, 0.37, 0.37, 0.37, 0.37, 0.36,\n",
        "        0.36, 0.33\n",
        "    ],\n",
        "    \"F1 Score\": [\n",
        "        0.63, 0.63, 0.61, 0.61, 0.60, 0.60, 0.52, 0.57, 0.59, 0.51, 0.59, 0.57,\n",
        "        0.54, 0.55, 0.56, 0.58, 0.44, 0.55, 0.46, 0.51, 0.51, 0.51, 0.51, 0.51,\n",
        "        0.51, 0.42\n",
        "    ],\n",
        "    \"Time Taken\": [\n",
        "        1.26, 0.20, 0.06, 0.35, 0.08, 0.27, 0.02, 0.02, 0.26, 0.02, 0.29, 0.01,\n",
        "        0.01, 0.15, 0.03, 0.21, 0.03, 0.02, 0.02, 0.05, 0.03, 0.02, 0.08, 0.01,\n",
        "        0.01, 0.01\n",
        "    ]\n",
        "}\n",
        "\n",
        "results = pd.DataFrame(data).set_index(\"Model\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "results['Accuracy'].sort_values().plot(kind='barh', color='skyblue')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Model')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Balanced Accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "results['Balanced Accuracy'].sort_values().plot(kind='barh', color='lightgreen')\n",
        "plt.title('Model Balanced Accuracy')\n",
        "plt.xlabel('Balanced Accuracy')\n",
        "plt.ylabel('Model')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot F1 Score\n",
        "plt.figure(figsize=(10, 6))\n",
        "results['F1 Score'].sort_values().plot(kind='barh', color='salmon')\n",
        "plt.title('Model F1 Score')\n",
        "plt.xlabel('F1 Score')\n",
        "plt.ylabel('Model')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Time Taken\n",
        "plt.figure(figsize=(10, 6))\n",
        "results['Time Taken'].sort_values().plot(kind='barh', color='orange')\n",
        "plt.title('Model Time Taken')\n",
        "plt.xlabel('Time Taken (seconds)')\n",
        "plt.ylabel('Model')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tdzAvoOXRlJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Example LazyClassifier results as a DataFrame\n",
        "data = {\n",
        "    \"Model\": [\n",
        "        \"XGBClassifier\", \"LGBMClassifier\", \"KNeighborsClassifier\", \"RandomForestClassifier\",\n",
        "        \"BaggingClassifier\", \"LabelSpreading\", \"PassiveAggressiveClassifier\",\n",
        "        \"DecisionTreeClassifier\", \"LabelPropagation\", \"NearestCentroid\",\n",
        "        \"ExtraTreesClassifier\", \"GaussianNB\", \"ExtraTreeClassifier\", \"AdaBoostClassifier\",\n",
        "        \"QuadraticDiscriminantAnalysis\", \"SVC\", \"SGDClassifier\", \"BernoulliNB\",\n",
        "        \"Perceptron\", \"LogisticRegression\", \"LinearDiscriminantAnalysis\",\n",
        "        \"LinearSVC\", \"CalibratedClassifierCV\", \"RidgeClassifierCV\", \"RidgeClassifier\",\n",
        "        \"DummyClassifier\"\n",
        "    ],\n",
        "    \"Accuracy\": [\n",
        "        0.64, 0.65, 0.63, 0.63, 0.61, 0.62, 0.55, 0.57, 0.61, 0.49, 0.61, 0.59,\n",
        "        0.55, 0.58, 0.60, 0.63, 0.58, 0.58, 0.45, 0.58, 0.58, 0.58, 0.58, 0.58,\n",
        "        0.58, 0.57\n",
        "    ],\n",
        "    \"Time Taken\": [\n",
        "        1.26, 0.20, 0.06, 0.35, 0.08, 0.27, 0.02, 0.02, 0.26, 0.02, 0.29, 0.01,\n",
        "        0.01, 0.15, 0.03, 0.21, 0.03, 0.02, 0.02, 0.05, 0.03, 0.02, 0.08, 0.01,\n",
        "        0.01, 0.01\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "results = pd.DataFrame(data).set_index(\"Model\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "results['Accuracy'].sort_values().plot(kind='barh', color='skyblue')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Model')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Time Taken\n",
        "plt.figure(figsize=(10, 6))\n",
        "results['Time Taken'].sort_values().plot(kind='barh', color='orange')\n",
        "plt.title('Model Time Taken')\n",
        "plt.xlabel('Time Taken (seconds)')\n",
        "plt.ylabel('Model')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tUzMm5AaSdRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lazypredict\n"
      ],
      "metadata": {
        "id": "bQYiOUv8PNeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset 2\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define file names\n",
        "file_names = [\"cow1.csv\", \"cow2.csv\", \"cow3.csv\", \"cow4.csv\", \"cow5.csv\", \"cow6.csv\"]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "all_data = []\n",
        "\n",
        "# Iterate over each file and read them\n",
        "for file_name in file_names:\n",
        "    data = pd.read_csv(file_name)\n",
        "    all_data.append(data)\n",
        "\n",
        "# Concatenate all the data into one DataFrame\n",
        "combined_data = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# Define window size\n",
        "window_size = 15  # Approximately 15 data points for 0.5 seconds\n",
        "\n",
        "# Initialize lists to store windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "# Segment the time-series data into windows\n",
        "for i in range(0, len(combined_data) - window_size + 1, window_size):\n",
        "    window = combined_data.iloc[i:i + window_size]\n",
        "    if len(window) == window_size:  # Ensure the window is complete\n",
        "        # Extract features from the window\n",
        "        window_features = {\n",
        "            'mean_acc_x': window['AccX'].mean(),\n",
        "            'mean_acc_y': window['AccY'].mean(),\n",
        "            'mean_acc_z': window['AccZ'].mean(),\n",
        "            'std_acc_x': window['AccX'].std(),\n",
        "            'std_acc_y': window['AccY'].std(),\n",
        "            'std_acc_z': window['AccZ'].std(),\n",
        "            'skew_acc_x': window['AccX'].skew(),\n",
        "            'skew_acc_y': window['AccY'].skew(),\n",
        "            'skew_acc_z': window['AccZ'].skew(),\n",
        "            'kurt_acc_x': window['AccX'].kurt(),\n",
        "            'kurt_acc_y': window['AccY'].kurt(),\n",
        "            'kurt_acc_z': window['AccZ'].kurt()\n",
        "        }\n",
        "        windowed_features.append(window_features)\n",
        "\n",
        "        # Assign label to the window (assuming it's the same for all samples within the window)\n",
        "        window_label = window['Label'].iloc[0]\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X_windowed = pd.DataFrame(windowed_features)\n",
        "y_windowed = np.array(windowed_labels)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_windowed)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE with a reduced number of neighbors\n",
        "smote = SMOTE(random_state=42, k_neighbors=2)  # Reduce k_neighbors to 2\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_windowed)\n",
        "\n",
        "# Split the data into train and test using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Apply LazyPredict for model benchmarking\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "\n",
        "# Fit and evaluate the models\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nLazyPredict Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Plot the top models' performance\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=models.index[:10], y=models['Accuracy'][:10], palette='viridis')\n",
        "plt.title(\"Top 10 Model Accuracies\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hJSHRU28P0am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define file names\n",
        "file_names = [\"cow1.csv\", \"cow2.csv\", \"cow3.csv\", \"cow4.csv\", \"cow5.csv\", \"cow6.csv\"]\n",
        "\n",
        "# Label mapping provided for behaviors\n",
        "behavior_mapping = {\n",
        "    \"RES\": \"Resting in standing position\",\n",
        "    \"RUS\": \"Ruminating in standing position\",\n",
        "    \"MOV\": \"Moving\",\n",
        "    \"GRZ\": \"Grazing\",\n",
        "    \"SLT\": \"Salt licking\",\n",
        "    \"FES\": \"Feeding in stanchion\",\n",
        "    \"DRN\": \"Drinking\",\n",
        "    \"LCK\": \"Licking\",\n",
        "    \"REL\": \"Resting in lying position\",\n",
        "    \"URI\": \"Urinating\",\n",
        "    \"ATT\": \"Attacking\",\n",
        "    \"ESC\": \"Escaping\",\n",
        "    \"BMN\": \"Being mounted\",\n",
        "    \"ETC\": \"Other behaviors\",\n",
        "    \"BLN\": \"Data without video, no label\",\n",
        "}\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "all_data = []\n",
        "\n",
        "# Iterate over each file and read them\n",
        "for file_name in file_names:\n",
        "    data = pd.read_csv(file_name)\n",
        "    all_data.append(data)\n",
        "\n",
        "# Concatenate all datasets into a single DataFrame\n",
        "data = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# Step 1: Remove rows with labels like 'ETC' (Other behaviors) and 'BLN' (No label)\n",
        "unwanted_labels = ['ETC', 'BLN']\n",
        "data = data[~data['Label'].isin(unwanted_labels)]\n",
        "\n",
        "# Step 2: Map numeric label values to descriptions using the provided mapping\n",
        "data['Behavior_Description'] = data['Label'].map(behavior_mapping)\n",
        "\n",
        "# Step 3: Encode the 'Behavior_Description' column to numeric labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['Behavior_Label'] = label_encoder.fit_transform(data['Behavior_Description'])\n",
        "\n",
        "# Print the mapping of labels to numeric values\n",
        "print(\"Label Mapping to Numeric Labels:\")\n",
        "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
        "\n",
        "# Step 4: Clean column names (strip any leading/trailing spaces)\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "# Step 5: Check available columns to ensure the accelerometer data columns are present\n",
        "print(\"Available Columns in Data:\")\n",
        "print(data.columns)\n",
        "\n",
        "# Step 6: Define features (accelerometer data) and target (behavior labels)\n",
        "# Update feature columns to match actual names in your data\n",
        "if 'AccX' in data.columns and 'AccY' in data.columns and 'AccZ' in data.columns:\n",
        "    X = data[['AccX', 'AccY', 'AccZ']]  # Feature columns\n",
        "else:\n",
        "    print(\"One or more accelerometer data columns are missing.\")\n",
        "\n",
        "y = data['Behavior_Label']  # Target column\n",
        "\n",
        "# Step 7: Ensure that there are no missing or NaN values in the features and target columns\n",
        "data_cleaned = data.dropna(subset=['AccX', 'AccY', 'AccZ', 'Behavior_Label'])\n",
        "\n",
        "# Step 8: Split the cleaned dataset into training and testing sets\n",
        "X_cleaned = data_cleaned[['AccX', 'AccY', 'AccZ']]\n",
        "y_cleaned = data_cleaned['Behavior_Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 9: Initialize LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "\n",
        "# Fit LazyClassifier on the training data and evaluate on the test data\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nLazyClassifier Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the LazyClassifier results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Step 10: Visualize label distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "data['Behavior_Description'].value_counts().plot(kind='bar')\n",
        "plt.title('Behavior Label Distribution')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZV7cAWWsSgeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define file names\n",
        "file_names = [\"cow1.csv\", \"cow2.csv\", \"cow3.csv\", \"cow4.csv\", \"cow5.csv\", \"cow6.csv\"]\n",
        "\n",
        "# Label mapping provided for behaviors\n",
        "behavior_mapping = {\n",
        "    \"RES\": \"Resting in standing position\",\n",
        "    \"RUS\": \"Ruminating in standing position\",\n",
        "    \"MOV\": \"Moving\",\n",
        "    \"GRZ\": \"Grazing\",\n",
        "    \"SLT\": \"Salt licking\",\n",
        "    \"FES\": \"Feeding in stanchion\",\n",
        "    \"DRN\": \"Drinking\",\n",
        "    \"LCK\": \"Licking\",\n",
        "    \"REL\": \"Resting in lying position\",\n",
        "    \"URI\": \"Urinating\",\n",
        "    \"ATT\": \"Attacking\",\n",
        "    \"ESC\": \"Escaping\",\n",
        "    \"BMN\": \"Being mounted\",\n",
        "    \"ETC\": \"Other behaviors\",\n",
        "    \"BLN\": \"Data without video, no label\",\n",
        "}\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "all_data = []\n",
        "\n",
        "# Iterate over each file and read them\n",
        "for file_name in file_names:\n",
        "    data = pd.read_csv(file_name)\n",
        "    all_data.append(data)\n",
        "\n",
        "# Concatenate all datasets into a single DataFrame\n",
        "data = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# Step 1: Remove rows with labels like 'ETC' (Other behaviors) and 'BLN' (No label)\n",
        "unwanted_labels = ['ETC', 'BLN']\n",
        "data = data[~data['Label'].isin(unwanted_labels)]\n",
        "\n",
        "# Step 2: Map numeric label values to descriptions using the provided mapping\n",
        "data['Behavior_Description'] = data['Label'].map(behavior_mapping)\n",
        "\n",
        "# Step 3: Encode the 'Behavior_Description' column to numeric labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['Behavior_Label'] = label_encoder.fit_transform(data['Behavior_Description'])\n",
        "\n",
        "# Print the mapping of labels to numeric values\n",
        "print(\"Label Mapping to Numeric Labels:\")\n",
        "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
        "\n",
        "# Step 4: Clean column names (strip any leading/trailing spaces)\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "# Step 5: Check available columns to ensure the accelerometer data columns are present\n",
        "print(\"Available Columns in Data:\")\n",
        "print(data.columns)\n",
        "\n",
        "# Step 6: Limit the dataset size to 1% of the original data\n",
        "data = data.sample(frac=0.01, random_state=42)\n",
        "\n",
        "# Step 7: Define features (accelerometer data) and target (behavior labels)\n",
        "if 'AccX' in data.columns and 'AccY' in data.columns and 'AccZ' in data.columns:\n",
        "    X = data[['AccX', 'AccY', 'AccZ']]  # Feature columns\n",
        "else:\n",
        "    print(\"One or more accelerometer data columns are missing.\")\n",
        "\n",
        "y = data['Behavior_Label']  # Target column\n",
        "\n",
        "# Step 8: Ensure that there are no missing or NaN values in the features and target columns\n",
        "data_cleaned = data.dropna(subset=['AccX', 'AccY', 'AccZ', 'Behavior_Label'])\n",
        "\n",
        "# Step 9: Split the cleaned dataset into training and testing sets\n",
        "X_cleaned = data_cleaned[['AccX', 'AccY', 'AccZ']]\n",
        "y_cleaned = data_cleaned['Behavior_Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 10: Initialize LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "\n",
        "# Fit LazyClassifier on the training data and evaluate on the test data\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nLazyClassifier Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the LazyClassifier results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Step 11: Visualize label distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "data['Behavior_Description'].value_counts().plot(kind='bar')\n",
        "plt.title('Behavior Label Distribution')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iMrnitJ_alLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 3\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Column labels provided for accelerometer data and statistics\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "data_frames = []\n",
        "\n",
        "# Step 1: Load all data files into a single DataFrame\n",
        "for file_name in data_files:\n",
        "    data = pd.read_csv(file_name, names=column_labels, header=None)\n",
        "    data_frames.append(data)\n",
        "\n",
        "# Combine all data into a single DataFrame\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Step 2: Map numeric labels to meaningful behavior descriptions\n",
        "# Here we assume the labels 1.0-6.0 map to specific behaviors (adjust this as necessary)\n",
        "behavior_mapping = {\n",
        "    1.0: 'Behavior 1',\n",
        "    2.0: 'Behavior 2',\n",
        "    3.0: 'Behavior 3',\n",
        "    4.0: 'Behavior 4',\n",
        "    5.0: 'Behavior 5',\n",
        "    6.0: 'Behavior 6'\n",
        "}\n",
        "\n",
        "data['Behavior_Description'] = data['label'].map(behavior_mapping)\n",
        "\n",
        "# Step 3: Encode the 'Behavior_Description' to numeric labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['Behavior_Label'] = label_encoder.fit_transform(data['Behavior_Description'])\n",
        "\n",
        "# Step 4: Define feature columns and target column\n",
        "# We use all the columns except 'date' and 'label' as features\n",
        "X = data.drop(columns=['date', 'label', 'Behavior_Description', 'Behavior_Label'])\n",
        "y = data['Behavior_Label']\n",
        "\n",
        "# Step 5: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 6: Initialize LazyClassifier and fit the model\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the model results\n",
        "print(\"\\nLazyClassifier Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Step 7: Visualize the label distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "data['Behavior_Description'].value_counts().plot(kind='bar')\n",
        "plt.title('Behavior Label Distribution')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iNmmHciUR3c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 3\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Column labels provided for accelerometer data and statistics\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "data_frames = []\n",
        "\n",
        "# Step 1: Load all data files into a single DataFrame\n",
        "for file_name in data_files:\n",
        "    data = pd.read_csv(file_name, names=column_labels, header=None)\n",
        "    data_frames.append(data)\n",
        "\n",
        "# Combine all data into a single DataFrame\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Step 2: Map numeric labels to meaningful behavior descriptions\n",
        "# Here we assume the labels 1-6 map to specific behaviors (adjust this as necessary)\n",
        "behavior_mapping = {\n",
        "    1: 'Behavior 1',\n",
        "    2: 'Behavior 2',\n",
        "    3: 'Behavior 3',\n",
        "    4: 'Behavior 4',\n",
        "    5: 'Behavior 5',\n",
        "    6: 'Behavior 6'\n",
        "}\n",
        "\n",
        "data['Behavior_Description'] = data['label'].map(behavior_mapping)\n",
        "\n",
        "# Step 3: Encode the 'Behavior_Description' to numeric labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['Behavior_Label'] = label_encoder.fit_transform(data['Behavior_Description'])\n",
        "\n",
        "# Step 4: Define feature columns and target column\n",
        "# We use all the columns except 'date' and 'label' as features\n",
        "X = data.drop(columns=['date', 'label', 'Behavior_Description', 'Behavior_Label'])\n",
        "y = data['Behavior_Label']\n",
        "\n",
        "# Step 5: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 6: Initialize LazyClassifier and fit the model\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the model results\n",
        "print(\"\\nLazyClassifier Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Step 7: Visualize the label distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "data['Behavior_Description'].value_counts().plot(kind='bar')\n",
        "plt.title('Behavior Label Distribution')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "550DO1ePdQmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "data_frames = []\n",
        "\n",
        "# Step 1: Load all data files into a single DataFrame\n",
        "column_labels = ['timestamp', 'X-axis (g)', 'Y-axis (g)', 'Z-axis (g)', 'label']  # Define the column names for your dataset\n",
        "for file_name in data_files:\n",
        "    data = pd.read_csv(file_name, names=column_labels, header=None)\n",
        "    data_frames.append(data)\n",
        "\n",
        "# Combine all data into a single DataFrame\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Step 2: Map numeric labels to meaningful behavior descriptions\n",
        "behavior_mapping = {\n",
        "    1: 'Behavior 1',\n",
        "    2: 'Behavior 2',\n",
        "    3: 'Behavior 3',\n",
        "    4: 'Behavior 4',\n",
        "    5: 'Behavior 5',\n",
        "    6: 'Behavior 6'\n",
        "}\n",
        "\n",
        "data['Behavior_Description'] = data['label'].map(behavior_mapping)\n",
        "\n",
        "# Step 3: Encode the 'Behavior_Description' column to numeric labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['Behavior_Label'] = label_encoder.fit_transform(data['Behavior_Description'])\n",
        "\n",
        "# Print the mapping of behaviors to numeric labels\n",
        "print(\"Behavior Mapping:\")\n",
        "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
        "\n",
        "# Step 4: Define features (accelerometer data) and target (behavior labels)\n",
        "X = data[['X-axis (g)', 'Y-axis (g)', 'Z-axis (g)']]  # Feature columns\n",
        "y = data['Behavior_Label']                           # Target column\n",
        "\n",
        "# Step 5: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 6: Initialize LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "\n",
        "# Step 7: Fit LazyClassifier on the training data and evaluate on the test data\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nLazyClassifier Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the LazyClassifier results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Step 8: Visualize behavior label distribution (optional)\n",
        "plt.figure(figsize=(10, 6))\n",
        "data['Behavior_Description'].value_counts().plot(kind='bar')\n",
        "plt.title('Behavior Label Distribution')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "T0ai2fF-eUPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lazypredict\n"
      ],
      "metadata": {
        "id": "medP0udde193"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name, names=column_labels, header=None)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Extract features (drop 'date' and use the rest)\n",
        "X = data.drop(columns=['date', 'label'])\n",
        "y = data['label']\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize LazyClassifier and perform lazy prediction\n",
        "lazy_clf = LazyClassifier()\n",
        "models, predictions = lazy_clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Print the results\n",
        "print(models)"
      ],
      "metadata": {
        "id": "I7QsSujEfMI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "# Define column labels (as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name, names=column_labels, header=None)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Convert 'date' column to datetime format\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "\n",
        "# Extract features (drop 'date' and 'label')\n",
        "X = data.drop(columns=['date', 'label'])\n",
        "y = data['label']\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize LazyClassifier and perform lazy prediction\n",
        "lazy_clf = LazyClassifier()\n",
        "models, predictions = lazy_clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Print the results\n",
        "print(models)"
      ],
      "metadata": {
        "id": "otLDuUOmfgtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "# Define column labels (as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name, names=column_labels, header=0)  # Set header=0 to skip first row\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Check the first few rows to confirm if the 'date' column is correctly loaded\n",
        "print(data.head())\n",
        "\n",
        "# Convert 'date' column to datetime format, handling errors\n",
        "data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
        "\n",
        "# Check for any rows where the 'date' column could not be parsed\n",
        "print(data[data['date'].isna()])\n",
        "\n",
        "# Extract features (drop 'date' and 'label')\n",
        "X = data.drop(columns=['date', 'label'])\n",
        "y = data['label']\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize LazyClassifier and perform lazy prediction\n",
        "lazy_clf = LazyClassifier()\n",
        "models, predictions = lazy_clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Print the results\n",
        "print(models)"
      ],
      "metadata": {
        "id": "2ItB4oCjfqBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "# Define column labels (as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name, names=column_labels, header=0)  # Set header=0 to skip first row\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Convert 'date' column to datetime format, handling errors\n",
        "data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
        "\n",
        "# Check for any rows where the 'date' column could not be parsed\n",
        "print(data[data['date'].isna()])\n",
        "\n",
        "# Convert 'label' column to categorical if it is not already\n",
        "data['label'] = data['label'].astype(int)  # Ensure 'label' is of integer type\n",
        "\n",
        "# Check if the labels are categorical\n",
        "print(data['label'].unique())\n",
        "\n",
        "# Extract features (drop 'date' and 'label')\n",
        "X = data.drop(columns=['date', 'label'])\n",
        "y = data['label']\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Initialize LazyClassifier and perform lazy prediction\n",
        "lazy_clf = LazyClassifier()\n",
        "models, predictions = lazy_clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Print the results\n",
        "print(models)"
      ],
      "metadata": {
        "id": "1XuQ9vjDf10r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name, names=column_labels, header=0)  # Adjusted header=0 to skip the first row\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'], errors='coerce')  # Handle errors during conversion\n",
        "\n",
        "# Check if there are any invalid date values\n",
        "if data['date'].isna().any():\n",
        "    print(f\"Warning: There are invalid date values in the dataset.\")\n",
        "    print(data[data['date'].isna()])\n",
        "\n",
        "# Calculate time difference\n",
        "time_diff = data['date'].diff().dropna()  # Drop NA values and calculate time difference\n",
        "\n",
        "# Calculate frequency (assuming uniform sampling)\n",
        "mean_time_diff = time_diff.mean()\n",
        "frequency = 1 / mean_time_diff.total_seconds()  # Convert to Hz\n",
        "print(f\"Sampling frequency for combined data: {frequency:.2f} Hz\")\n",
        "\n",
        "# Calculate window size based on frequency\n",
        "window_duration = 0.5  # Seconds\n",
        "window_size = int(frequency * window_duration)\n",
        "\n",
        "# Ensure window size is at least 1\n",
        "if window_size == 0:\n",
        "    print(\"Window size is zero, adjusting to 1\")\n",
        "    window_size = 1\n",
        "\n",
        "# Extract windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "for i in range(0, len(data), window_size):\n",
        "    window = data.iloc[i:i + window_size]\n",
        "    if len(window) == window_size:  # Compute mean values as features for this window\n",
        "        window_features = window.mean()\n",
        "        window_label = window['label'].iloc[0]  # Assuming the label is the same for the entire window\n",
        "        windowed_features.append(window_features)\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X = pd.DataFrame(windowed_features).drop(columns=['date'])  # Drop 'date' column for features\n",
        "y = np.array(windowed_labels)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Use LazyPredict to compare models\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Print the model performance summary\n",
        "print(models)\n"
      ],
      "metadata": {
        "id": "5Evv11bltvf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name, names=column_labels, header=0)  # Adjusted header=0 to skip the first row\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'], errors='coerce')  # Handle errors during conversion\n",
        "\n",
        "# Check if there are any invalid date values\n",
        "if data['date'].isna().any():\n",
        "    print(f\"Warning: There are invalid date values in the dataset.\")\n",
        "    print(data[data['date'].isna()])\n",
        "\n",
        "# Calculate time difference\n",
        "time_diff = data['date'].diff().dropna()  # Drop NA values and calculate time difference\n",
        "\n",
        "# Calculate frequency (assuming uniform sampling)\n",
        "mean_time_diff = time_diff.mean()\n",
        "frequency = 1 / mean_time_diff.total_seconds()  # Convert to Hz\n",
        "print(f\"Sampling frequency for combined data: {frequency:.2f} Hz\")\n",
        "\n",
        "# Calculate window size based on frequency\n",
        "window_duration = 0.5  # Seconds\n",
        "window_size = int(frequency * window_duration)\n",
        "\n",
        "# Ensure window size is at least 1\n",
        "if window_size == 0:\n",
        "    print(\"Window size is zero, adjusting to 1\")\n",
        "    window_size = 1\n",
        "\n",
        "# Extract windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "for i in range(0, len(data), window_size):\n",
        "    window = data.iloc[i:i + window_size]\n",
        "    if len(window) == window_size:  # Compute mean values as features for this window\n",
        "        window_features = window.mean()\n",
        "        window_label = window['label'].iloc[0]  # Assuming the label is the same for the entire window\n",
        "        windowed_features.append(window_features)\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X = pd.DataFrame(windowed_features).drop(columns=['date'])  # Drop 'date' column for features\n",
        "y = np.array(windowed_labels)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Check if the labels are continuous (for regression) or discrete (for classification)\n",
        "print(np.unique(y))\n",
        "\n",
        "# If the labels are continuous, convert them to discrete classes\n",
        "if np.issubdtype(y.dtype, np.floating):  # Check if the labels are continuous (floats)\n",
        "    # Example: Bin continuous labels into 3 classes\n",
        "    y_discrete = pd.cut(y, bins=3, labels=[0, 1, 2])  # Adjust as needed for your dataset\n",
        "    print(\"Labels have been binned into discrete classes.\")\n",
        "else:\n",
        "    y_discrete = y  # No change if labels are already discrete\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_discrete)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Use LazyPredict to compare models\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Print the model performance summary\n",
        "print(models)"
      ],
      "metadata": {
        "id": "tBQN7grXwgRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Calculate time difference\n",
        "time_diff = data['date'].diff().dropna()  # Drop NA values and calculate time difference\n",
        "\n",
        "# Calculate frequency (assuming uniform sampling)\n",
        "mean_time_diff = time_diff.mean()\n",
        "frequency = 1 / mean_time_diff.total_seconds()  # Convert to Hz\n",
        "\n",
        "print(\"Sampling frequency for combined data:\", frequency, \"Hz\")\n",
        "\n",
        "# Calculate window size based on frequency\n",
        "window_duration = 0.5  # Seconds\n",
        "window_size = int(frequency * window_duration)\n",
        "\n",
        "if window_size == 0:\n",
        "    print(\"Window size is zero, adjusting to 1\")\n",
        "    window_size = 1\n",
        "\n",
        "# Extract windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "for i in range(0, len(data), window_size):\n",
        "    window = data.iloc[i:i+window_size]\n",
        "    if len(window) == window_size:\n",
        "        # Compute mean values as features for this window\n",
        "        window_features = window.mean()\n",
        "        window_label = window['label'].iloc[0]\n",
        "        windowed_features.append(window_features)\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X = pd.DataFrame(windowed_features).drop(columns=['date'])  # Drop 'date' column for features\n",
        "y = np.array(windowed_labels)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Use LazyPredict to evaluate models\n",
        "lazy_classifier = LazyClassifier()\n",
        "models = lazy_classifier.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Show model performance comparison\n",
        "print(models[0])  # This prints out performance metrics of all models"
      ],
      "metadata": {
        "id": "JQV44o36xAzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Calculate time difference\n",
        "time_diff = data['date'].diff().dropna()  # Drop NA values and calculate time difference\n",
        "\n",
        "# Calculate frequency (assuming uniform sampling)\n",
        "mean_time_diff = time_diff.mean()\n",
        "frequency = 1 / mean_time_diff.total_seconds()  # Convert to Hz\n",
        "\n",
        "print(\"Sampling frequency for combined data:\", frequency, \"Hz\")\n",
        "\n",
        "# Calculate window size based on frequency\n",
        "window_duration = 0.5  # Seconds\n",
        "window_size = int(frequency * window_duration)\n",
        "\n",
        "if window_size == 0:\n",
        "    print(\"Window size is zero, adjusting to 1\")\n",
        "    window_size = 1\n",
        "\n",
        "# Extract windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "for i in range(0, len(data), window_size):\n",
        "    window = data.iloc[i:i+window_size]\n",
        "    if len(window) == window_size:\n",
        "        # Compute mean values as features for this window\n",
        "        window_features = window.mean()\n",
        "        window_label = window['label'].iloc[0]\n",
        "        windowed_features.append(window_features)\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X = pd.DataFrame(windowed_features).drop(columns=['date'])  # Drop 'date' column for features\n",
        "y = np.array(windowed_labels)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Use LazyPredict to evaluate models\n",
        "lazy_classifier = LazyClassifier()\n",
        "models = lazy_classifier.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Show model performance comparison\n",
        "print(models[0])  # This prints out performance metrics of all models"
      ],
      "metadata": {
        "id": "fmWYNbahyf4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import warnings\n",
        "\n",
        "# Suppress Dask warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"dask\")\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Calculate time difference\n",
        "time_diff = data['date'].diff().dropna()  # Drop NA values and calculate time difference\n",
        "\n",
        "# Calculate frequency (assuming uniform sampling)\n",
        "mean_time_diff = time_diff.mean()\n",
        "frequency = 1 / mean_time_diff.total_seconds()  # Convert to Hz\n",
        "\n",
        "print(\"Sampling frequency for combined data:\", frequency, \"Hz\")\n",
        "\n",
        "# Calculate window size based on frequency\n",
        "window_duration = 0.5  # Seconds\n",
        "window_size = max(1, int(frequency * window_duration))  # Ensure window size is at least 1\n",
        "\n",
        "# Extract windowed features and labels\n",
        "windowed_features = []\n",
        "windowed_labels = []\n",
        "\n",
        "for i in range(0, len(data), window_size):\n",
        "    window = data.iloc[i:i+window_size]\n",
        "    if len(window) == window_size:\n",
        "        # Compute mean values as features for this window\n",
        "        window_features = window.mean()\n",
        "        window_label = window['label'].iloc[0]\n",
        "        windowed_features.append(window_features)\n",
        "        windowed_labels.append(window_label)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "X = pd.DataFrame(windowed_features).drop(columns=['date'])  # Drop 'date' column for features\n",
        "y = np.array(windowed_labels)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Deal with class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
        "\n",
        "# Use LazyPredict to evaluate models\n",
        "lazy_classifier = LazyClassifier()\n",
        "models = lazy_classifier.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Show model performance comparison\n",
        "print(models[0])  # This prints out performance metrics of all models"
      ],
      "metadata": {
        "id": "KEYK_YzbyqLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import warnings\n",
        "\n",
        "# Suppress Dask warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"dask\")\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Feature columns (excluding 'date' and 'label')\n",
        "X = data[column_labels[:-1]]\n",
        "\n",
        "# Target variable\n",
        "y = data['label']\n",
        "\n",
        "# Handle missing values (if any)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Apply SMOTE for class balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply LazyPredict classifier\n",
        "clf = LazyClassifier()\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# View results\n",
        "print(models)\n"
      ],
      "metadata": {
        "id": "8Bi9aizo0Lof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import warnings\n",
        "\n",
        "# Suppress Dask warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"dask\")\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Remove the 'date' column from features (or convert it to numeric if needed)\n",
        "X = data[column_labels[:-1]]  # Exclude the 'date' column\n",
        "\n",
        "# Alternatively, if you want to use date features (like year, month, day, etc.):\n",
        "# X['year'] = X['date'].dt.year\n",
        "# X['month'] = X['date'].dt.month\n",
        "# X['day'] = X['date'].dt.day\n",
        "# X = X.drop(columns=['date'])  # Drop original date column\n",
        "\n",
        "# Target variable\n",
        "y = data['label']\n",
        "\n",
        "# Handle missing values (if any)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Apply SMOTE for class balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply LazyPredict classifier\n",
        "clf = LazyClassifier()\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# View results\n",
        "print(models)"
      ],
      "metadata": {
        "id": "GX5CJMEz0Ytb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import warnings\n",
        "\n",
        "# Suppress Dask warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"dask\")\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Drop the 'date' column completely from features\n",
        "X = data[column_labels[:-1]]  # Exclude the 'label' and 'date' columns\n",
        "\n",
        "# Ensure 'date' is fully excluded\n",
        "X = X.loc[:, X.columns != 'date']\n",
        "\n",
        "# Target variable\n",
        "y = data['label']\n",
        "\n",
        "# Handle missing values (if any)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Apply SMOTE for class balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply LazyPredict classifier\n",
        "clf = LazyClassifier()\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# View results\n",
        "print(models)"
      ],
      "metadata": {
        "id": "YW6Oe-O-0jJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import warnings\n",
        "\n",
        "# Suppress Dask warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"dask\")\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Drop the 'date' column completely from features\n",
        "X = data[column_labels[:-1]]  # Exclude the 'label' and 'date' columns\n",
        "\n",
        "# Ensure 'date' is fully excluded\n",
        "X = X.loc[:, X.columns != 'date']\n",
        "\n",
        "# Target variable\n",
        "y = data['label']\n",
        "\n",
        "# Downsample to 10% of the data to reduce memory usage\n",
        "data_downsampled = data.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Extract features and target from downsampled data\n",
        "X_downsampled = data_downsampled[column_labels[:-1]].loc[:, data_downsampled.columns != 'date']\n",
        "y_downsampled = data_downsampled['label']\n",
        "\n",
        "# Handle missing values (if any) on the downsampled data\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_downsampled)\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Apply SMOTE for class balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_downsampled)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply LazyPredict classifier\n",
        "clf = LazyClassifier()\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# View results\n",
        "print(models)\n"
      ],
      "metadata": {
        "id": "ymPIjUsN3GtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import warnings\n",
        "\n",
        "# Suppress Dask warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"dask\")\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Downsampling (example step, adjust as necessary)\n",
        "# Let's assume we downsample to 30% of the data for quicker testing\n",
        "data_downsampled = data.sample(frac=0.3, random_state=42)\n",
        "\n",
        "# Extract features and target from downsampled data\n",
        "X_downsampled = data_downsampled.drop(columns=['date', 'label'])  # Drop 'date' and 'label' columns\n",
        "y_downsampled = data_downsampled['label']  # 'label' is the target variable\n",
        "\n",
        "# Handle missing values (if any) on the downsampled data\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_downsampled)\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Apply SMOTE for class balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_downsampled)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply LazyPredict classifier\n",
        "clf = LazyClassifier()\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# View results\n",
        "print(models)\n"
      ],
      "metadata": {
        "id": "rwmS6Se43ubA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "id": "i6Rp1G-6KoUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset 4 (datset_6)\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data from CSV file\n",
        "data = pd.read_csv(\"dataset_6.csv\")\n",
        "\n",
        "# Display the first few rows to understand the data structure\n",
        "print(data.head())\n",
        "\n",
        "# Step 1: Clean the data - check for missing values and remove rows with missing data\n",
        "data_cleaned = data.dropna()  # Drop rows with NaNs (if necessary)\n",
        "\n",
        "# Step 2: Map behavior labels to numeric values (if necessary)\n",
        "# Assuming behavior labels are in a column named 'label' or 'Behavior_Label'\n",
        "behavior_mapping = {\n",
        "    'Grazing': 0,\n",
        "    'Lying-Resting': 1,\n",
        "    'Lying-Ruminating': 2,\n",
        "    'Standing-Resting': 3,\n",
        "    'Standing-Ruminating': 4,\n",
        "    'Walking': 5\n",
        "}\n",
        "\n",
        "# Map the behavior labels\n",
        "data_cleaned['Behavior_Label'] = data_cleaned['label'].map(behavior_mapping)\n",
        "\n",
        "# Step 3: Encode labels (optional, since mapping already gives numeric values)\n",
        "# label_encoder = LabelEncoder()\n",
        "# data_cleaned['Behavior_Label'] = label_encoder.fit_transform(data_cleaned['label'])\n",
        "\n",
        "# Step 4: Define feature columns (exclude 'label' and 'Behavior_Label' columns)\n",
        "# Assuming the dataset has relevant feature columns for classification\n",
        "X = data_cleaned.drop(columns=['label', 'Behavior_Label'])\n",
        "\n",
        "# Define the target variable (Behavior labels)\n",
        "y = data_cleaned['Behavior_Label']\n",
        "\n",
        "# Step 5: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 6: Initialize LazyClassifier and fit the model\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the model results\n",
        "print(\"\\nLazyClassifier Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Step 7: Visualize the label distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "data_cleaned['label'].value_counts().plot(kind='bar')\n",
        "plt.title('Behavior Label Distribution')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2lybxzPzWFrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn lazypredict matplotlib"
      ],
      "metadata": {
        "id": "OATKvC3l5dy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "\n",
        "# Suppress Dask warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"dask\")\n",
        "\n",
        "# Define column labels (adjust as per your dataset)\n",
        "column_labels = ['date', 'x_mean', 'x_max', 'x_min', 'x_std', 'x_var', 'x_skew', 'x_kurtosis',\n",
        "                 'y_mean', 'y_max', 'y_min', 'y_std', 'y_var', 'y_skew', 'y_kurtosis',\n",
        "                 'z_mean', 'z_max', 'z_min', 'z_std', 'z_var', 'z_skew', 'z_kurtosis',\n",
        "                 'n', 'x_range', 'y_range', 'z_range', 'svm', 'vmm', 'sma', 'ai', 'label']\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Downsampling (example step, adjust as necessary)\n",
        "# Let's assume we downsample to 30% of the data for quicker testing\n",
        "data_downsampled = data.sample(frac=0.3, random_state=42)\n",
        "\n",
        "# Extract features and target from downsampled data\n",
        "X_downsampled = data_downsampled.drop(columns=['date', 'label'])  # Drop 'date' and 'label' columns\n",
        "y_downsampled = data_downsampled['label']  # 'label' is the target variable\n",
        "\n",
        "# Handle missing values (if any) on the downsampled data\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_downsampled)\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Apply SMOTE for class balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_downsampled)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply LazyPredict classifier\n",
        "clf = LazyClassifier()\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# View results from LazyPredict\n",
        "print(models)\n",
        "\n",
        "# Now, let's add XGBClassifier for comparison\n",
        "xgb_clf = xgb.XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict with XGBClassifier\n",
        "y_pred_xgb = xgb_clf.predict(X_test)\n",
        "\n",
        "# Display classification report for XGBClassifier\n",
        "print(\"\\nXGBoost Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "id": "UuBrz262KzMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "# Suppress Dask warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"dask\")\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Downsampling (example step, adjust as necessary)\n",
        "data_downsampled = data.sample(frac=0.3, random_state=42)\n",
        "\n",
        "# Extract features and target from downsampled data\n",
        "X_downsampled = data_downsampled.drop(columns=['date', 'label'])  # Drop 'date' and 'label' columns\n",
        "y_downsampled = data_downsampled['label']  # 'label' is the target variable\n",
        "\n",
        "# Handle missing values (if any) on the downsampled data\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_downsampled)\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Apply SMOTE for class balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_downsampled)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the XGBClassifier\n",
        "xgb_clf = xgb.XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
        "\n",
        "# Record the start time for training\n",
        "start_time = time.time()\n",
        "\n",
        "# Fit the model\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Record the end time for training\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "train_time = end_time - start_time\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_xgb = xgb_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Print results\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
        "print(f\"XGBoost Training Time: {train_time:.4f} seconds\")"
      ],
      "metadata": {
        "id": "WM8_PUdFLR25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "# Suppress Dask warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"dask\")\n",
        "\n",
        "# Data files\n",
        "data_files = [\"resampled_2_1S.csv\", \"resampled_2_3S.csv\", \"resampled_2_5S.csv\"]\n",
        "\n",
        "# Initialize lists to store all data\n",
        "data_frames = []\n",
        "\n",
        "# Load all data files and append to data_frames list\n",
        "for file_name in data_files:\n",
        "    df = pd.read_csv(file_name)\n",
        "    data_frames.append(df)\n",
        "\n",
        "# Concatenate all data frames into a single dataframe\n",
        "data = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Assuming 'date' is the column containing timestamps\n",
        "data['date'] = pd.to_datetime(data['date'])  # Convert to datetime format\n",
        "\n",
        "# Downsampling (example step, adjust as necessary)\n",
        "data_downsampled = data.sample(frac=0.3, random_state=42)\n",
        "\n",
        "# Extract features and target from downsampled data\n",
        "X_downsampled = data_downsampled.drop(columns=['date', 'label'])  # Drop 'date' and 'label' columns\n",
        "y_downsampled = data_downsampled['label']  # 'label' is the target variable\n",
        "\n",
        "# Shift the class labels to start from 0\n",
        "y_downsampled -= 1  # Subtract 1 from all labels to ensure they start from 0\n",
        "\n",
        "# Handle missing values (if any) on the downsampled data\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_downsampled)\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Apply SMOTE for class balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_downsampled)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the XGBClassifier\n",
        "xgb_clf = xgb.XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
        "\n",
        "# Record the start time for training\n",
        "start_time = time.time()\n",
        "\n",
        "# Fit the model\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Record the end time for training\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "train_time = end_time - start_time\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_xgb = xgb_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Print results\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
        "print(f\"XGBoost Training Time: {train_time:.4f} seconds\")"
      ],
      "metadata": {
        "id": "ufHZEO_7LpRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset 1 (data)\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data from CSV file\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Display the first few rows to understand the data structure\n",
        "print(data.head())\n",
        "\n",
        "# Step 1: Clean the data - check for missing values and remove rows with missing data\n",
        "data_cleaned = data.dropna()  # Drop rows with NaNs (if necessary)\n",
        "\n",
        "# Step 2: Map behavior labels to numeric values (already numeric in the provided dataset)\n",
        "# Assuming the behavior labels are in a column named 'behavior' with:\n",
        "# Feeding: 0, Rumination: 1, Standing: 2, Lying: 3, Walking: 4\n",
        "\n",
        "# Step 3: Define feature columns (exclude 'date', 'time', 'cow_num', 'behavior')\n",
        "X = data_cleaned.drop(columns=['date', 'time', 'cow_num', 'behavior'])\n",
        "\n",
        "# Define the target variable (Behavior labels)\n",
        "y = data_cleaned['behavior']  # This column contains the behavior labels (already numeric)\n",
        "\n",
        "# Step 4: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 5: Initialize LazyClassifier and fit the model\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the model results\n",
        "print(\"\\nLazyClassifier Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Step 6: Visualize the behavior label distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "data_cleaned['behavior'].value_counts().plot(kind='bar')\n",
        "plt.title('Behavior Label Distribution')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, labels=[\"Feeding\", \"Rumination\", \"Standing\", \"Lying\", \"Walking\"])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P8cjoCllWR89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data from CSV file\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Display the first few rows to understand the data structure\n",
        "print(data.head())\n",
        "\n",
        "# Step 1: Clean the data - check for missing values and remove rows with missing data\n",
        "data_cleaned = data.dropna()  # Drop rows with NaNs (if necessary)\n",
        "\n",
        "# Step 2: Randomly sample a smaller subset of the data (e.g., 10% of the original data)\n",
        "sampled_data = data_cleaned.sample(frac=0.1, random_state=42)  # Adjust frac for different sizes\n",
        "\n",
        "# Step 3: Define feature columns (exclude 'date', 'time', 'cow_num', 'behavior')\n",
        "X = sampled_data.drop(columns=['date', 'time', 'cow_num', 'behavior'])\n",
        "\n",
        "# Define the target variable (Behavior labels)\n",
        "y = sampled_data['behavior']  # This column contains the behavior labels (already numeric)\n",
        "\n",
        "# Step 4: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 5: Initialize LazyClassifier and fit the model\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the model results\n",
        "print(\"\\nLazyClassifier Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Step 6: Visualize the behavior label distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sampled_data['behavior'].value_counts().plot(kind='bar')\n",
        "plt.title('Behavior Label Distribution')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, labels=[\"Feeding\", \"Rumination\", \"Standing\", \"Lying\", \"Walking\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rEpIOebR5jKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load only the necessary columns to save memory\n",
        "cols_to_use = ['acc_x', 'acc_y', 'acc_z', 'behavior']  # Essential columns\n",
        "\n",
        "# Load a smaller subset of the data (e.g., 1% of the original dataset)\n",
        "data = pd.read_csv(\"data.csv\", usecols=cols_to_use)  # Load only the columns that are needed\n",
        "\n",
        "# Display the first few rows to understand the data structure\n",
        "print(data.head())\n",
        "\n",
        "# Step 1: Clean the data - check for missing values and remove rows with missing data\n",
        "data_cleaned = data.dropna()  # Drop rows with NaNs\n",
        "\n",
        "# Step 2: Randomly sample a smaller subset of the data (e.g., 1% of the original data)\n",
        "sampled_data = data_cleaned.sample(frac=0.01, random_state=42)  # Adjust frac for different sizes\n",
        "\n",
        "# Step 3: Define feature columns (exclude 'behavior' column)\n",
        "X = sampled_data.drop(columns=['behavior'])\n",
        "\n",
        "# Define the target variable (Behavior labels)\n",
        "y = sampled_data['behavior']  # This column contains the behavior labels (already numeric)\n",
        "\n",
        "# Step 4: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 5: Initialize LazyClassifier and fit the model\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the model results\n",
        "print(\"\\nLazyClassifier Results:\")\n",
        "print(models)\n",
        "\n",
        "# Optional: Save the results to a CSV file\n",
        "models.to_csv('lazy_classifier_results.csv', index=False)\n",
        "\n",
        "# Step 6: Visualize the behavior label distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sampled_data['behavior'].value_counts().plot(kind='bar')\n",
        "plt.title('Behavior Label Distribution')\n",
        "plt.xlabel('Behavior')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, labels=[\"Feeding\", \"Rumination\", \"Standing\", \"Lying\", \"Walking\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "drKgwQxM6h_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.61, 0.62, 0.55, 0.57, 0.61, 0.49, 0.61, 0.59, 0.55, 0.58, 0.60, 0.63, 0.58,\n",
        "                       0.58, 0.58, 0.45, 0.58, 0.58, 0.58, 0.58, 0.57],\n",
        "        'time': [1.26, 0.20, 0.06, 0.35, 0.08, 0.27, 0.02, 0.02, 0.26, 0.02, 0.29, 0.01, 0.01, 0.15, 0.03, 0.21, 0.03,\n",
        "                 0.02, 0.02, 0.03, 0.03, 0.05, 0.02, 0.04, 0.01],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Creating plots for accuracy and time\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
        "\n",
        "# Accuracy Plot\n",
        "for idx, (dataset, data) in enumerate(datasets.items()):\n",
        "    axes[0].bar(data['models'], data['accuracies'], label=dataset, alpha=0.7)\n",
        "axes[0].set_title('Model Accuracy Comparison')\n",
        "axes[0].set_xlabel('Models')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].tick_params(axis='x', rotation=90)\n",
        "axes[0].legend(title=\"Datasets\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Time Plot\n",
        "for idx, (dataset, data) in enumerate(datasets.items()):\n",
        "    axes[1].bar(data['models'], data['time'], label=dataset, alpha=0.7)\n",
        "axes[1].set_title('Model Time Comparison')\n",
        "axes[1].set_xlabel('Models')\n",
        "axes[1].set_ylabel('Time (seconds)')\n",
        "axes[1].tick_params(axis='x', rotation=90)\n",
        "axes[1].legend(title=\"Datasets\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Displaying the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LtZiDnl27Dxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.61, 0.62, 0.55, 0.57, 0.61, 0.49, 0.61, 0.59, 0.55, 0.58, 0.60, 0.63, 0.58,\n",
        "                       0.58, 0.58, 0.45, 0.58, 0.58, 0.58, 0.57],\n",
        "        'time': [1.26, 0.20, 0.06, 0.35, 0.08, 0.27, 0.02, 0.13, 0.41, 0.32, 0.02, 0.31, 0.36, 0.03, 0.07, 0.06, 0.09, 0.19,\n",
        "                 0.08, 0.11, 0.07, 0.01, 0.03, 0.07, 0.02],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Ensuring that the number of models and accuracies match\n",
        "for dataset, data in datasets.items():\n",
        "    if len(data['models']) != len(data['accuracies']):\n",
        "        print(f\"Mismatch in dataset {dataset}: Models count = {len(data['models'])}, Accuracies count = {len(data['accuracies'])}\")\n",
        "\n",
        "# Creating plots for accuracy and time\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
        "\n",
        "# Accuracy Plot\n",
        "for idx, (dataset, data) in enumerate(datasets.items()):\n",
        "    axes[0].bar(data['models'], data['accuracies'], label=dataset, alpha=0.7)\n",
        "axes[0].set_title('Model Accuracy Comparison')\n",
        "axes[0].set_xlabel('Models')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].tick_params(axis='x', rotation=90)\n",
        "axes[0].legend(title=\"Datasets\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Time Plot\n",
        "for idx, (dataset, data) in enumerate(datasets.items()):\n",
        "    axes[1].bar(data['models'], data['time'], label=dataset, alpha=0.7)\n",
        "axes[1].set_title('Model Time Comparison')\n",
        "axes[1].set_xlabel('Models')\n",
        "axes[1].set_ylabel('Time (seconds)')\n",
        "axes[1].tick_params(axis='x', rotation=90)\n",
        "axes[1].legend(title=\"Datasets\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Displaying the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hM1trcx2_LM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.61, 0.62, 0.55, 0.57, 0.61, 0.49, 0.61, 0.59, 0.55, 0.58, 0.60, 0.63, 0.58,\n",
        "                       0.58, 0.58, 0.45, 0.58, 0.58, 0.58, 0.58, 0.58, 0.57],\n",
        "        'time': [1.26, 0.20, 0.06, 0.35, 0.08, 0.27, 0.02, 0.02, 0.26, 0.02, 0.29, 0.06, 0.06, 0.29, 0.16, 0.29, 0.02,\n",
        "                 0.09, 0.16, 0.16, 0.30, 0.16, 0.29, 0.27, 0.13],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Sorting models based on the selected models\n",
        "def filter_selected_models(datasets, selected_models):\n",
        "    filtered_data = {}\n",
        "    for dataset, data in datasets.items():\n",
        "        selected_indices = [i for i, model in enumerate(data['models']) if model in selected_models]\n",
        "        filtered_data[dataset] = {\n",
        "            'models': np.array(data['models'])[selected_indices],\n",
        "            'accuracies': np.array(data['accuracies'])[selected_indices],\n",
        "            'time': np.array(data['time'])[selected_indices]\n",
        "        }\n",
        "    return filtered_data\n",
        "\n",
        "# Get the filtered data for the selected models\n",
        "filtered_data = filter_selected_models(datasets, selected_models)\n",
        "\n",
        "# Plotting accuracy and time performance for selected models\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# Plot for Accuracy\n",
        "for dataset, data in filtered_data.items():\n",
        "    ax1.barh(data['models'], data['accuracies'], label=dataset, alpha=0.7)\n",
        "\n",
        "ax1.set_xlabel('Accuracy')\n",
        "ax1.set_title('Top Models by Accuracy (Selected Models)')\n",
        "ax1.legend()\n",
        "\n",
        "# Plot for Time Performance\n",
        "for dataset, data in filtered_data.items():\n",
        "    ax2.barh(data['models'], data['time'], label=dataset, alpha=0.7)\n",
        "\n",
        "ax2.set_xlabel('Time (s)')\n",
        "ax2.set_title('Top Models by Time Performance (Selected Models)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nEZ6pxHO_rIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.61, 0.62, 0.55, 0.57, 0.61, 0.49, 0.61, 0.59, 0.55, 0.58, 0.60, 0.63, 0.58,\n",
        "                       0.58, 0.58, 0.45, 0.58, 0.58, 0.58, 0.58, 0.57],\n",
        "        'time': [1.26, 0.20, 0.06, 0.35, 0.08, 1.10, 0.21, 0.02, 0.31, 0.31, 0.49, 0.07, 0.03, 0.21, 0.23, 0.40, 0.50,\n",
        "                 0.06, 0.05, 0.14, 0.05, 0.16, 0.30, 0.03, 0.08, 0.08],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to filter selected models\n",
        "def filter_selected_models(datasets, selected_models):\n",
        "    filtered_data = {}\n",
        "    for dataset, data in datasets.items():\n",
        "        selected_indices = [i for i, model in enumerate(data['models']) if model in selected_models]\n",
        "        filtered_data[dataset] = {\n",
        "            'models': np.array(data['models'])[selected_indices],\n",
        "            'accuracies': np.array(data['accuracies'])[selected_indices],\n",
        "            'time': np.array(data['time'])[selected_indices]\n",
        "        }\n",
        "    return filtered_data\n",
        "\n",
        "# Get the filtered data for the selected models\n",
        "filtered_data = filter_selected_models(datasets, selected_models)\n",
        "\n",
        "# Plotting accuracy and time performance for selected models\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "# Plot for Accuracy\n",
        "for dataset, data in filtered_data.items():\n",
        "    ax1.barh(data['models'], data['accuracies'], label=dataset, alpha=0.7)\n",
        "\n",
        "ax1.set_xlabel('Accuracy')\n",
        "ax1.set_title('Top Models by Accuracy (Selected Models)')\n",
        "ax1.legend()\n",
        "\n",
        "# Plot for Time Performance\n",
        "for dataset, data in filtered_data.items():\n",
        "    ax2.barh(data['models'], data['time'], label=dataset, alpha=0.7)\n",
        "\n",
        "ax2.set_xlabel('Time (s)')\n",
        "ax2.set_title('Top Models by Time Performance (Selected Models)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IyDQNh88Av8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.61, 0.62, 0.55, 0.57, 0.61, 0.49, 0.61, 0.59, 0.55, 0.58, 0.60, 0.63, 0.58,\n",
        "                       0.58, 0.58, 0.45, 0.58, 0.58, 0.58, 0.58, 0.57],\n",
        "        'time': [3.10, 1.97, 2.44, 2.50, 0.33, 4.44, 2.44, 2.44, 2.10, 0.09, 0.05, 0.04, 1.12, 0.03, 0.05, 0.06, 0.07, 0.12,\n",
        "                 0.03, 0.19, 0.17, 0.10, 0.07, 0.10, 0.15],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to filter selected models\n",
        "def filter_selected_models(datasets, selected_models):\n",
        "    filtered_data = {}\n",
        "    for dataset, data in datasets.items():\n",
        "        selected_indices = [i for i, model in enumerate(data['models']) if model in selected_models]\n",
        "        filtered_data[dataset] = {\n",
        "            'models': np.array(data['models'])[selected_indices],\n",
        "            'accuracies': np.array(data['accuracies'])[selected_indices],\n",
        "            'time': np.array(data['time'])[selected_indices]\n",
        "        }\n",
        "    return filtered_data\n",
        "\n",
        "# Get the filtered data for the selected models\n",
        "filtered_data = filter_selected_models(datasets, selected_models)\n",
        "\n",
        "# Plotting accuracy and time performance for selected models\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))\n",
        "\n",
        "# Plot for Accuracy\n",
        "for dataset, data in filtered_data.items():\n",
        "    ax1.bar(data['models'], data['accuracies'], label=dataset, width=0.15, align='center')\n",
        "\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_title('Top Models by Accuracy (Selected Models)')\n",
        "ax1.legend()\n",
        "\n",
        "# Plot for Time Performance\n",
        "for dataset, data in filtered_data.items():\n",
        "    ax2.bar(data['models'], data['time'], label=dataset, width=0.15, align='center')\n",
        "\n",
        "ax2.set_ylabel('Time (s)')\n",
        "ax2.set_title('Top Models by Time Performance (Selected Models)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AGQi79Y_BPE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    # Add other datasets here...\n",
        "}\n",
        "\n",
        "# Function to filter selected models\n",
        "def filter_selected_models(datasets, selected_models):\n",
        "    filtered_data = {}\n",
        "    for dataset, data in datasets.items():\n",
        "        selected_indices = [i for i, model in enumerate(data['models']) if model in selected_models]\n",
        "        filtered_data[dataset] = {\n",
        "            'models': np.array(data['models'])[selected_indices],\n",
        "            'accuracies': np.array(data['accuracies'])[selected_indices],\n",
        "            'time': np.array(data['time'])[selected_indices]\n",
        "        }\n",
        "    return filtered_data\n",
        "\n",
        "# Get the filtered data for the selected models\n",
        "filtered_data = filter_selected_models(datasets, selected_models)\n",
        "\n",
        "# Plotting accuracy and time performance for selected models\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "# Set width of bars and adjust bar positions\n",
        "bar_width = 0.15\n",
        "index = np.arange(len(filtered_data['Dataset 1']['models']))\n",
        "\n",
        "# Plot for Accuracy\n",
        "for i, (dataset, data) in enumerate(filtered_data.items()):\n",
        "    ax1.barh(index + i * bar_width, data['accuracies'], bar_width, label=dataset, alpha=0.7)\n",
        "\n",
        "ax1.set_yticks(index + bar_width * (len(filtered_data) - 1) / 2)\n",
        "ax1.set_yticklabels(filtered_data['Dataset 1']['models'])\n",
        "ax1.set_xlabel('Accuracy')\n",
        "ax1.set_title('Top Models by Accuracy (Selected Models)')\n",
        "ax1.legend()\n",
        "\n",
        "# Plot for Time Performance\n",
        "for i, (dataset, data) in enumerate(filtered_data.items()):\n",
        "    ax2.barh(index + i * bar_width, data['time'], bar_width, label=dataset, alpha=0.7)\n",
        "\n",
        "ax2.set_yticks(index + bar_width * (len(filtered_data) - 1) / 2)\n",
        "ax2.set_yticklabels(filtered_data['Dataset 1']['models'])\n",
        "ax2.set_xlabel('Time (s)')\n",
        "ax2.set_title('Top Models by Time Performance (Selected Models)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SXBkPeeqBobY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.61, 0.62, 0.55, 0.57, 0.61, 0.49, 0.61, 0.59, 0.55, 0.58, 0.60, 0.63, 0.58,\n",
        "                       0.58, 0.58, 0.45, 0.58, 0.58, 0.58, 0.58, 0.57],\n",
        "        'time': [1.00, 2.47, 1.50, 1.10, 0.53, 0.37, 0.02, 1.01, 0.07, 0.04, 0.13, 0.04, 0.09, 0.06, 0.01, 0.18, 0.13,\n",
        "                 0.06, 0.17, 0.09, 0.03, 0.07, 0.04, 0.08, 0.14],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Set positions for bars\n",
        "bar_width = 0.15\n",
        "index = np.arange(len(selected_models))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Plot accuracies and times for each dataset and model\n",
        "for i, dataset in enumerate(datasets.keys()):\n",
        "    accuracies = datasets[dataset]['accuracies']\n",
        "    times = datasets[dataset]['time']\n",
        "\n",
        "    ax.bar(index + i * bar_width, accuracies, bar_width, label=f'{dataset} Accuracy')\n",
        "    ax.bar(index + i * bar_width + bar_width / 2, times, bar_width, label=f'{dataset} Time')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Model Performance across Datasets')\n",
        "ax.set_xticks(index + 2 * bar_width)\n",
        "ax.set_xticklabels(selected_models, rotation=45)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KLxxRnd7B7vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.62, 0.61, 0.60, 0.60, 0.60, 0.59, 0.59, 0.58, 0.57, 0.56, 0.55, 0.53, 0.53, 0.52],\n",
        "        'time': [0.16, 2.70, 1.21, 0.43, 2.29, 0.39, 0.37, 1.57, 2.48, 2.65, 0.33, 0.57, 0.12, 0.37, 0.57, 0.08, 0.09, 0.11],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Filter the accuracies and times to only include the selected models\n",
        "bar_width = 0.15\n",
        "index = np.arange(len(selected_models))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Plot accuracies and times for each dataset and model\n",
        "for i, dataset in enumerate(datasets.keys()):\n",
        "    accuracies = [datasets[dataset]['accuracies'][datasets[dataset]['models'].index(model)] for model in selected_models]\n",
        "    times = [datasets[dataset]['time'][datasets[dataset]['models'].index(model)] for model in selected_models]\n",
        "\n",
        "    ax.bar(index + i * bar_width, accuracies, bar_width, label=f'{dataset} Accuracy')\n",
        "    ax.bar(index + i * bar_width + bar_width / 2, times, bar_width, label=f'{dataset} Time')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Model Performance across Datasets')\n",
        "ax.set_xticks(index + 2 * bar_width)\n",
        "ax.set_xticklabels(selected_models, rotation=45)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jaK3_Xo5Chp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.62, 0.61, 0.60, 0.60, 0.60, 0.59, 0.59, 0.58, 0.57, 0.56, 0.55, 0.53, 0.53, 0.52],\n",
        "        'time': [0.16, 2.70, 1.21, 0.43, 2.29, 0.39, 0.37, 1.57, 2.48, 2.65, 0.33, 0.57, 0.12, 0.37, 0.57, 0.08, 0.09, 0.11],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Filter the accuracies and times to only include the selected models\n",
        "bar_width = 0.15\n",
        "index = np.arange(len(selected_models))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Plot accuracies and times for each dataset and model\n",
        "for i, dataset in enumerate(datasets.keys()):\n",
        "    # Filter models for the current dataset that are in selected_models\n",
        "    valid_models = [model for model in selected_models if model in datasets[dataset]['models']]\n",
        "\n",
        "    # Get the accuracies and times only for valid models\n",
        "    accuracies = [datasets[dataset]['accuracies'][datasets[dataset]['models'].index(model)] for model in valid_models]\n",
        "    times = [datasets[dataset]['time'][datasets[dataset]['models'].index(model)] for model in valid_models]\n",
        "\n",
        "    # Plot bars\n",
        "    ax.bar(index + i * bar_width, accuracies, bar_width, label=f'{dataset} Accuracy')\n",
        "    ax.bar(index + i * bar_width + bar_width / 2, times, bar_width, label=f'{dataset} Time')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Model Performance across Datasets')\n",
        "ax.set_xticks(index + 2 * bar_width)\n",
        "ax.set_xticklabels(selected_models, rotation=45)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pYz670Z6C2XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.62, 0.61, 0.60, 0.60, 0.60, 0.59, 0.59, 0.58, 0.57, 0.56, 0.55, 0.53, 0.53, 0.52],\n",
        "        'time': [0.16, 2.70, 1.21, 0.43, 2.29, 0.39, 0.37, 1.57, 2.48, 2.65, 0.33, 0.57, 0.12, 0.37, 0.57, 0.08, 0.09, 0.11],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Filter the accuracies and times to only include the selected models\n",
        "bar_width = 0.15\n",
        "index = np.arange(len(selected_models))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Plot accuracies and times for each dataset and model\n",
        "for i, dataset in enumerate(datasets.keys()):\n",
        "    # Filter models for the current dataset that are in selected_models\n",
        "    valid_models = [model for model in selected_models if model in datasets[dataset]['models']]\n",
        "\n",
        "    # Get the accuracies and times only for valid models\n",
        "    accuracies = [datasets[dataset]['accuracies'][datasets[dataset]['models'].index(model)] for model in valid_models]\n",
        "    times = [datasets[dataset]['time'][datasets[dataset]['models'].index(model)] for model in valid_models]\n",
        "\n",
        "    # Plot bars\n",
        "    ax.bar(index + i * bar_width, accuracies, bar_width, label=f'{dataset} Accuracy')\n",
        "    ax.bar(index + i * bar_width + bar_width / 2, times, bar_width, label=f'{dataset} Time')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Model Performance across Datasets')\n",
        "ax.set_xticks(index + 2 * bar_width)\n",
        "ax.set_xticklabels(selected_models, rotation=45)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tWBCIevMDfQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.62, 0.61, 0.60, 0.60, 0.60, 0.59, 0.59, 0.58, 0.57, 0.56, 0.55, 0.53, 0.53, 0.52],\n",
        "        'time': [0.16, 2.70, 1.21, 0.43, 2.29, 0.39, 0.37, 1.57, 2.48, 2.65, 0.33, 0.57, 0.12, 0.37, 0.57, 0.08, 0.09, 0.11],\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "# Sorting models based on the selected models\n",
        "def filter_selected_models(datasets, selected_models):\n",
        "    filtered_data = {}\n",
        "    for dataset, data in datasets.items():\n",
        "        selected_indices = [i for i, model in enumerate(data['models']) if model in selected_models]\n",
        "        filtered_data[dataset] = {\n",
        "            'models': np.array(data['models'])[selected_indices],\n",
        "            'accuracies': np.array(data['accuracies'])[selected_indices],\n",
        "            'time': np.array(data['time'])[selected_indices]\n",
        "        }\n",
        "    return filtered_data\n",
        "\n",
        "# Get the filtered data for the selected models\n",
        "filtered_data = filter_selected_models(datasets, selected_models)\n",
        "\n",
        "# Plotting accuracy and time performance for selected models\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# Plot for Accuracy\n",
        "bar_width = 0.15  # Width of the bars\n",
        "index_offset = 0.2  # Offset for the bars for each dataset\n",
        "for i, (dataset, data) in enumerate(filtered_data.items()):\n",
        "    # Offset each dataset by index * bar_width for separation\n",
        "    positions = np.arange(len(data['models'])) + (i - len(filtered_data) / 2) * bar_width\n",
        "    ax1.barh(positions, data['accuracies'], height=bar_width, label=dataset, alpha=0.7)\n",
        "\n",
        "ax1.set_yticks(np.arange(len(filtered_data['Dataset 1']['models'])))\n",
        "ax1.set_yticklabels(filtered_data['Dataset 1']['models'])\n",
        "ax1.set_xlabel('Accuracy')\n",
        "ax1.set_title('Top Models by Accuracy (Selected Models)')\n",
        "ax1.legend()\n",
        "\n",
        "# Plot for Time Performance\n",
        "for i, (dataset, data) in enumerate(filtered_data.items()):\n",
        "    # Offset each dataset by index * bar_width for separation\n",
        "    positions = np.arange(len(data['models'])) + (i - len(filtered_data) / 2) * bar_width\n",
        "    ax2.barh(positions, data['time'], height=bar_width, label=dataset, alpha=0.7)\n",
        "\n",
        "ax2.set_yticks(np.arange(len(filtered_data['Dataset 1']['models'])))\n",
        "ax2.set_yticklabels(filtered_data['Dataset 1']['models'])\n",
        "ax2.set_xlabel('Time (s)')\n",
        "ax2.set_title('Top Models by Time Performance (Selected Models)')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IniYDNUSDfwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['ExtraTreesClassifier', 'XGBClassifier', 'LGBMClassifier', 'RandomForestClassifier', 'LabelPropagation',\n",
        "                   'KNeighborsClassifier', 'LabelSpreading', 'BaggingClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier',\n",
        "                   'SVC', 'QuadraticDiscriminantAnalysis', 'GaussianNB', 'AdaBoostClassifier', 'NearestCentroid', 'LogisticRegression',\n",
        "                   'LinearDiscriminantAnalysis', 'CalibratedClassifierCV'],\n",
        "        'accuracies': [0.91, 0.89, 0.89, 0.89, 0.86, 0.87, 0.86, 0.86, 0.82, 0.81, 0.82, 0.73, 0.69, 0.65, 0.63, 0.71, 0.70, 0.70],\n",
        "        'time': [2.98, 9.66, 4.62, 1.31, 2.44, 0.70, 1.50, 1.31, 1.31, 1.14, 2.10, 0.07, 0.02, 0.04, 0.62, 0.07, 0.07, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'BaggingClassifier',\n",
        "                   'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier', 'LabelPropagation', 'NearestCentroid',\n",
        "                   'ExtraTreesClassifier', 'GaussianNB', 'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'SVC', 'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression', 'LinearDiscriminantAnalysis',\n",
        "                   'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV', 'RidgeClassifier', 'DummyClassifier'],\n",
        "        'accuracies': [0.64, 0.65, 0.63, 0.63, 0.62, 0.61, 0.60, 0.60, 0.60, 0.59, 0.59, 0.58, 0.57, 0.56, 0.55, 0.53, 0.53, 0.52],\n",
        "        'time': [0.16, 2.70, 1.21, 0.43, 2.29, 0.39, 0.37, 1.57, 2.48, 2.65, 2.56, 2.36, 3.45, 0.05, 0.40, 0.03, 0.13, 0.18],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Color map\n",
        "colors = plt.cm.Paired(np.arange(len(datasets)))\n",
        "\n",
        "# Plot for each dataset\n",
        "for i, (dataset, data) in enumerate(datasets.items()):\n",
        "    bar_width = 0.15\n",
        "    x_pos = np.arange(len(selected_models)) + i * bar_width\n",
        "\n",
        "    ax.bar(x_pos, data['accuracies'], bar_width, label=f'{dataset} Accuracies', color=colors[i])\n",
        "    ax.bar(x_pos + bar_width, data['time'], bar_width, label=f'{dataset} Time', color=colors[i], alpha=0.6)\n",
        "\n",
        "ax.set_xticks(np.arange(len(selected_models)) + bar_width * (len(datasets) - 1) / 2)\n",
        "ax.set_xticklabels(selected_models, rotation=45)\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Scores and Time (in seconds)')\n",
        "ax.set_title('Model Performance Comparison')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hncm2qCuIkrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot (these should match the models available in each dataset)\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Filter the datasets to include only selected models\n",
        "for dataset in datasets:\n",
        "    indices = [i for i, model in enumerate(datasets[dataset]['models']) if model in selected_models]\n",
        "    datasets[dataset]['models'] = np.array(datasets[dataset]['models'])[indices]\n",
        "    datasets[dataset]['accuracies'] = np.array(datasets[dataset]['accuracies'])[indices]\n",
        "    datasets[dataset]['time'] = np.array(datasets[dataset]['time'])[indices]\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Color map\n",
        "colors = plt.cm.Paired(np.arange(len(datasets)))\n",
        "\n",
        "# Plot for each dataset\n",
        "bar_width = 0.15\n",
        "for i, (dataset, data) in enumerate(datasets.items()):\n",
        "    x_pos = np.arange(len(selected_models)) + i * bar_width\n",
        "    ax.bar(x_pos, data['accuracies'], bar_width, label=f'{dataset} Accuracies', color=colors[i])\n",
        "    ax.bar(x_pos + bar_width, data['time'], bar_width, label=f'{dataset} Time', color=colors[i], alpha=0.6)\n",
        "\n",
        "ax.set_xticks(np.arange(len(selected_models)) + bar_width * (len(datasets) - 1) / 2)\n",
        "ax.set_xticklabels(selected_models, rotation=45)\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Scores and Time (in seconds)')\n",
        "ax.set_title('Model Performance Comparison')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_a6WRSRzIqOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot (these should match the models available in each dataset)\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset (5 datasets in total)\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['KNeighborsClassifier', 'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'SVC', 'GaussianNB',\n",
        "                   'ExtraTreesClassifier', 'LogisticRegression', 'BaggingClassifier', 'DecisionTreeClassifier', 'AdaBoostClassifier',\n",
        "                   'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'CalibratedClassifierCV', 'RidgeClassifier', 'RidgeClassifierCV', 'SGDClassifier', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'BernoulliNB', 'ExtraTreeClassifier', 'LinearSVC'],\n",
        "        'accuracies': [0.73, 0.72, 0.76, 0.75, 0.75, 0.62, 0.79, 0.75, 0.61, 0.67, 0.68, 0.68, 0.68, 0.61, 0.75, 0.64, 0.56,\n",
        "                       0.60, 0.69, 0.69, 0.64, 0.61, 0.61, 0.50, 0.46, 0.40],\n",
        "        'time': [0.05, 0.09, 0.22, 0.09, 0.02, 0.02, 1.03, 0.07, 0.10, 0.09, 0.32, 0.04, 0.08, 0.22, 0.18, 0.03, 0.10,\n",
        "                 0.09, 0.05, 0.04, 0.15, 0.17, 0.10, 0.07, 0.04, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['RandomForestClassifier', 'LogisticRegression', 'SVC', 'XGBClassifier', 'LGBMClassifier', 'GaussianNB',\n",
        "                   'AdaBoostClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier',\n",
        "                   'BaggingClassifier', 'LabelSpreading', 'LabelPropagation', 'SGDClassifier', 'Perceptron', 'LinearSVC',\n",
        "                   'CalibratedClassifierCV', 'RidgeClassifier', 'RidgeClassifierCV', 'QuadraticDiscriminantAnalysis', 'LinearDiscriminantAnalysis',\n",
        "                   'NearestCentroid', 'ExtraTreeClassifier', 'BernoulliNB'],\n",
        "        'accuracies': [0.69, 0.67, 0.66, 0.66, 0.74, 0.64, 0.61, 0.68, 0.64, 0.68, 0.67, 0.64, 0.63, 0.59, 0.63, 0.61, 0.55,\n",
        "                       0.52, 0.51, 0.50, 0.45, 0.48, 0.48, 0.46, 0.47],\n",
        "        'time': [0.10, 0.16, 0.14, 0.04, 0.05, 0.01, 0.06, 0.07, 0.16, 0.23, 0.17, 0.02, 0.11, 0.14, 0.08, 0.15, 0.05,\n",
        "                 0.03, 0.18, 0.09, 0.07, 0.12, 0.16, 0.03, 0.04],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to filter and plot results\n",
        "def plot_dataset(dataset_name, dataset_results, selected_models):\n",
        "    # Filter models\n",
        "    filtered_models = [model for model in selected_models if model in dataset_results['models']]\n",
        "    filtered_accuracies = [dataset_results['accuracies'][dataset_results['models'].index(model)] for model in filtered_models]\n",
        "    filtered_times = [dataset_results['time'][dataset_results['models'].index(model)] for model in filtered_models]\n",
        "\n",
        "    # Number of models selected for plotting\n",
        "    print(f\"{dataset_name}: {len(filtered_models)} models selected\")\n",
        "\n",
        "    # Plot the accuracies and times for the filtered models\n",
        "    x_pos = np.arange(len(filtered_models))\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    ax1.bar(x_pos - 0.2, filtered_accuracies, 0.4, label='Accuracy', color='b')\n",
        "    ax1.set_xlabel('Model')\n",
        "    ax1.set_ylabel('Accuracy', color='b')\n",
        "    ax1.set_xticks(x_pos)\n",
        "    ax1.set_xticklabels(filtered_models, rotation=90)\n",
        "    ax1.tick_params(axis='y', labelcolor='b')\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(x_pos + 0.2, filtered_times, 0.4, label='Time', color='r')\n",
        "    ax2.set_ylabel('Time (seconds)', color='r')\n",
        "    ax2.tick_params(axis='y', labelcolor='r')\n",
        "\n",
        "    plt.title(f\"Models Performance: {dataset_name}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot all datasets\n",
        "for dataset_name, dataset_results in datasets.items():\n",
        "    plot_dataset(dataset_name, dataset_results, selected_models)"
      ],
      "metadata": {
        "id": "Vyyz0zHrI6On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot (these should match the models available in each dataset)\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset (5 datasets in total)\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.16],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['KNeighborsClassifier', 'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'SVC', 'GaussianNB',\n",
        "                   'ExtraTreesClassifier', 'LogisticRegression', 'BaggingClassifier', 'DecisionTreeClassifier', 'AdaBoostClassifier',\n",
        "                   'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'CalibratedClassifierCV', 'RidgeClassifier', 'RidgeClassifierCV', 'SGDClassifier', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'BernoulliNB', 'ExtraTreeClassifier', 'LinearSVC'],\n",
        "        'accuracies': [0.73, 0.72, 0.76, 0.75, 0.75, 0.62, 0.79, 0.75, 0.61, 0.67, 0.68, 0.68, 0.68, 0.61, 0.75, 0.64, 0.56,\n",
        "                       0.60, 0.69, 0.69, 0.64, 0.61, 0.61, 0.50, 0.46, 0.40],\n",
        "        'time': [0.05, 0.09, 0.22, 0.09, 0.02, 0.02, 1.03, 0.07, 0.10, 0.09, 0.32, 0.04, 0.08, 0.22, 0.18, 0.03, 0.10,\n",
        "                 0.09, 0.05, 0.04, 0.15, 0.17, 0.10, 0.07, 0.04, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['RandomForestClassifier', 'LogisticRegression', 'SVC', 'XGBClassifier', 'LGBMClassifier', 'GaussianNB',\n",
        "                   'AdaBoostClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier',\n",
        "                   'BaggingClassifier', 'LabelSpreading', 'LabelPropagation', 'SGDClassifier', 'Perceptron', 'LinearSVC',\n",
        "                   'CalibratedClassifierCV', 'RidgeClassifier', 'RidgeClassifierCV', 'QuadraticDiscriminantAnalysis', 'LinearDiscriminantAnalysis',\n",
        "                   'NearestCentroid', 'ExtraTreeClassifier', 'BernoulliNB'],\n",
        "        'accuracies': [0.69, 0.67, 0.66, 0.66, 0.74, 0.64, 0.61, 0.72, 0.71, 0.60, 0.67, 0.68, 0.69, 0.64, 0.61, 0.62, 0.60,\n",
        "                       0.58, 0.61, 0.56, 0.59, 0.58, 0.62, 0.55, 0.50],\n",
        "        'time': [0.45, 0.53, 0.71, 0.59, 0.46, 0.19, 0.36, 0.69, 0.58, 0.33, 0.31, 0.24, 0.41, 0.50, 0.38, 0.21, 0.36,\n",
        "                 0.22, 0.15, 0.12, 0.08, 0.16, 0.07, 0.11, 0.08],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to plot all datasets on one plot\n",
        "def plot_all_datasets_on_one_plot(datasets, selected_models):\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    x_pos = np.arange(len(selected_models))\n",
        "\n",
        "    colors = ['b', 'g', 'r', 'c', 'm']  # Different colors for each dataset\n",
        "\n",
        "    for i, (dataset_name, dataset_results) in enumerate(datasets.items()):\n",
        "        filtered_models = [model for model in selected_models if model in dataset_results['models']]\n",
        "        filtered_accuracies = [dataset_results['accuracies'][dataset_results['models'].index(model)] for model in filtered_models]\n",
        "        filtered_times = [dataset_results['time'][dataset_results['models'].index(model)] for model in filtered_models]\n",
        "\n",
        "        ax1.bar(x_pos - 0.2 + (i * 0.1), filtered_accuracies, 0.4, label=f'Accuracy - {dataset_name}', color=colors[i % len(colors)])\n",
        "        ax1.set_xlabel('Model')\n",
        "        ax1.set_ylabel('Accuracy', color='b')\n",
        "        ax1.set_xticks(x_pos)\n",
        "        ax1.set_xticklabels(selected_models, rotation=90)\n",
        "        ax1.tick_params(axis='y', labelcolor='b')\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    for i, (dataset_name, dataset_results) in enumerate(datasets.items()):\n",
        "        filtered_models = [model for model in selected_models if model in dataset_results['models']]\n",
        "        filtered_accuracies = [dataset_results['accuracies'][dataset_results['models'].index(model)] for model in filtered_models]\n",
        "        filtered_times = [dataset_results['time'][dataset_results['models'].index(model)] for model in filtered_models]\n",
        "\n",
        "        ax2.plot(x_pos + 0.2 + (i * 0.1), filtered_times, 0.4, label=f'Time - {dataset_name}', color=colors[i % len(colors)])\n",
        "\n",
        "    ax2.set_ylabel('Time (seconds)', color='r')\n",
        "    ax2.tick_params(axis='y', labelcolor='r')\n",
        "\n",
        "    plt.title(\"Models Performance Across Datasets\")\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax2.legend(loc='upper right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot all datasets on one plot\n",
        "plot_all_datasets_on_one_plot(datasets, selected_models)"
      ],
      "metadata": {
        "id": "j1Nl1SmlJh8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot (these should match the models available in each dataset)\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset (5 datasets in total)\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['XGBClassifier, ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier', 'XGBClassifier'],\n",
        "        'accuracies': [0.97, 0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.9660],\n",
        "        'time': [34.4, 2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04, 3.4],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['KNeighborsClassifier', 'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'SVC', 'GaussianNB',\n",
        "                   'ExtraTreesClassifier', 'LogisticRegression', 'BaggingClassifier', 'DecisionTreeClassifier', 'AdaBoostClassifier',\n",
        "                   'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'CalibratedClassifierCV', 'RidgeClassifier', 'RidgeClassifierCV', 'SGDClassifier', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'BernoulliNB', 'ExtraTreeClassifier', 'LinearSVC'],\n",
        "        'accuracies': [0.73, 0.72, 0.76, 0.75, 0.75, 0.62, 0.79, 0.75, 0.61, 0.67, 0.68, 0.68, 0.68, 0.61, 0.75, 0.64, 0.56,\n",
        "                       0.60, 0.69, 0.69, 0.64, 0.61, 0.61, 0.50, 0.46, 0.40],\n",
        "        'time': [0.05, 0.09, 0.22, 0.09, 0.02, 0.02, 1.03, 0.07, 0.10, 0.09, 0.32, 0.04, 0.08, 0.22, 0.18, 0.03, 0.10,\n",
        "                 0.09, 0.05, 0.04, 0.15, 0.17, 0.10, 0.07, 0.04, 0.07],\n",
        "    },\n",
        "# Data for Dataset 5\n",
        "models = [\n",
        "    'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier', 'RandomForestClassifier',\n",
        "    'BaggingClassifier', 'LabelSpreading', 'PassiveAggressiveClassifier', 'DecisionTreeClassifier',\n",
        "    'LabelPropagation', 'NearestCentroid', 'ExtraTreesClassifier', 'GaussianNB',\n",
        "    'ExtraTreeClassifier', 'AdaBoostClassifier', 'QuadraticDiscriminantAnalysis', 'SVC',\n",
        "    'SGDClassifier', 'BernoulliNB', 'Perceptron', 'LogisticRegression',\n",
        "    'LinearDiscriminantAnalysis', 'LinearSVC', 'CalibratedClassifierCV', 'RidgeClassifierCV',\n",
        "    'RidgeClassifier', 'DummyClassifier'\n",
        "]\n",
        "\n",
        "accuracies = [\n",
        "    0.64, 0.65, 0.63, 0.63, 0.61, 0.62, 0.55, 0.57, 0.61, 0.49, 0.61, 0.59,\n",
        "    0.55, 0.58, 0.60, 0.63, 0.58, 0.58, 0.45, 0.58, 0.58, 0.58, 0.58, 0.58,\n",
        "    0.58, 0.57\n",
        "]\n",
        "\n",
        "times = [\n",
        "    1.26, 0.20, 0.06, 0.35, 0.08, 0.27, 0.02, 0.02, 0.26, 0.02, 0.29, 0.01,\n",
        "    0.01, 0.15, 0.03, 0.21, 0.03, 0.02, 0.02, 0.05, 0.03, 0.02, 0.08, 0.01,\n",
        "    0.01, 0.01\n",
        "]\n",
        "\n",
        "}\n",
        "\n",
        "# Function to plot model comparison\n",
        "def plot_comparison(dataset_results):\n",
        "    for dataset_name, result in dataset_results.items():\n",
        "        accuracies = result['accuracies']\n",
        "        time = result['time']\n",
        "\n",
        "        # Only plot selected models\n",
        "        accuracies_selected = [accuracies[selected_models.index(model)] if model in result['models'] else None for model in selected_models]\n",
        "        time_selected = [time[selected_models.index(model)] if model in result['models'] else None for model in selected_models]\n",
        "\n",
        "        # Create the figure\n",
        "        fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "        ax2 = ax1.twinx()\n",
        "        ax1.bar(selected_models, accuracies_selected, color='b', alpha=0.6, label=\"Accuracy\")\n",
        "        ax2.plot(selected_models, time_selected, 'g', label=\"Training Time (s)\")\n",
        "\n",
        "        ax1.set_xlabel('Model')\n",
        "        ax1.set_ylabel('Accuracy', color='b')\n",
        "        ax2.set_ylabel('Training Time (s)', color='g')\n",
        "\n",
        "        ax1.tick_params(axis='x', rotation=90)\n",
        "        ax1.set_title(f\"Model Comparison for {dataset_name}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Plot the model comparisons for each dataset\n",
        "plot_comparison(datasets)\n"
      ],
      "metadata": {
        "id": "GIZyWmy6KLP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot (these should match the models available in each dataset)\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset (5 datasets in total)\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['LGBMClassifier', 'RandomForestClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier',\n",
        "                   'BaggingClassifier', 'LabelPropagation', 'LabelSpreading', 'AdaBoostClassifier', 'GaussianNB',\n",
        "                   'QuadraticDiscriminantAnalysis', 'ExtraTreeClassifier', 'SVC', 'DecisionTreeClassifier', 'LinearSVC',\n",
        "                   'RidgeClassifierCV', 'RidgeClassifier', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV',\n",
        "                   'SGDClassifier', 'LogisticRegression', 'BernoulliNB', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'DummyClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.63, 0.62, 0.62, 0.64, 0.64, 0.60, 0.52, 0.51, 0.57, 0.63, 0.56, 0.61, 0.61,\n",
        "                       0.61, 0.61, 0.60, 0.61, 0.60, 0.39, 0.59, 0.27, 0.48],\n",
        "        'time': [1.66, 1.97, 1.55, 1.45, 0.33, 0.41, 2.44, 5.71, 0.49, 0.02, 0.06, 0.03, 6.17, 0.09, 0.08, 0.03, 0.03,\n",
        "                 0.08, 0.30, 0.14, 0.19, 0.04, 0.12, 0.12, 0.05, 0.03],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['BaggingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'NearestCentroid',\n",
        "                   'ExtraTreeClassifier', 'XGBClassifier', 'ExtraTreesClassifier', 'RandomForestClassifier', 'GaussianNB',\n",
        "                   'LabelPropagation', 'LabelSpreading', 'PassiveAggressiveClassifier', 'LGBMClassifier', 'Perceptron',\n",
        "                   'LogisticRegression', 'LinearDiscriminantAnalysis', 'CalibratedClassifierCV', 'SVC', 'DummyClassifier',\n",
        "                   'BernoulliNB', 'AdaBoostClassifier', 'SGDClassifier', 'RidgeClassifier', 'RidgeClassifierCV', 'LinearSVC'],\n",
        "        'accuracies': [0.67, 0.61, 0.67, 0.16, 0.60, 0.68, 0.69, 0.69, 0.44, 0.65, 0.65, 0.23, 0.40, 0.53, 0.63, 0.63,\n",
        "                       0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63, 0.63],\n",
        "        'time': [0.48, 0.09, 0.31, 0.02, 0.03, 4.64, 1.50, 1.31, 0.03, 2.17, 2.74, 0.07, 2.10, 0.07, 0.34, 0.06, 0.57,\n",
        "                 3.15, 0.03, 0.05, 0.05, 0.90, 0.15, 0.03, 0.05, 0.07],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['ExtraTreesClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'BaggingClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'SVC', 'NuSVC',\n",
        "                   'LogisticRegression', 'CalibratedClassifierCV', 'LinearSVC', 'SGDClassifier', 'QuadraticDiscriminantAnalysis',\n",
        "                   'RidgeClassifier', 'RidgeClassifierCV', 'AdaBoostClassifier', 'LinearDiscriminantAnalysis', 'PassiveAggressiveClassifier',\n",
        "                   'Perceptron', 'NearestCentroid', 'BernoulliNB', 'GaussianNB', 'DummyClassifier', 'XGBClassifier'],\n",
        "        'accuracies': [0.97, 0.96, 0.96, 0.94, 0.94, 0.94, 0.89, 0.89, 0.86, 0.81, 0.81, 0.73, 0.64, 0.62, 0.62, 0.58, 0.58,\n",
        "                       0.54, 0.54, 0.54, 0.53, 0.53, 0.53, 0.49, 0.40, 0.39, 0.35, 0.9660],\n",
        "        'time': [2.98, 9.66, 4.62, 23.73, 14.60, 8.72, 0.70, 1.14, 0.07, 13.10, 32.57, 0.62, 10.63, 1.62, 0.64, 0.15, 0.05,\n",
        "                 0.20, 8.19, 0.13, 0.30, 0.26, 0.05, 0.09, 0.07, 0.04, 3.4],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['KNeighborsClassifier', 'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'SVC', 'GaussianNB',\n",
        "                   'ExtraTreesClassifier', 'LogisticRegression', 'BaggingClassifier', 'DecisionTreeClassifier', 'AdaBoostClassifier',\n",
        "                   'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'LabelSpreading', 'LabelPropagation',\n",
        "                   'CalibratedClassifierCV', 'RidgeClassifier', 'RidgeClassifierCV', 'SGDClassifier', 'Perceptron', 'PassiveAggressiveClassifier',\n",
        "                   'NearestCentroid', 'BernoulliNB', 'ExtraTreeClassifier', 'LinearSVC'],\n",
        "        'accuracies': [0.73, 0.72, 0.76, 0.75, 0.75, 0.62, 0.79, 0.75, 0.61, 0.67, 0.68, 0.68, 0.68, 0.61, 0.75, 0.64, 0.56,\n",
        "                       0.60, 0.69, 0.69, 0.64, 0.61, 0.61, 0.50, 0.46, 0.40],\n",
        "        'time': [0.05, 0.09, 0.22, 0.09, 0.02, 0.02, 1.03, 0.07, 0.10, 0.09, 0.32, 0.04, 0.08, 0.22, 0.18, 0.03, 0.10,\n",
        "                 0.09, 0.05, 0.04, 0.15, 0.17, 0.10, 0.07, 0.04, 0.07],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['RandomForestClassifier', 'LogisticRegression', 'SVC', 'XGBClassifier', 'LGBMClassifier', 'GaussianNB',\n",
        "                   'AdaBoostClassifier', 'ExtraTreesClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier',\n",
        "                   'BaggingClassifier', 'LabelSpreading', 'LabelPropagation', 'SGDClassifier', 'Perceptron', 'LinearSVC',\n",
        "                   'CalibratedClassifierCV', 'RidgeClassifier', 'RidgeClassifierCV', 'QuadraticDiscriminantAnalysis', 'LinearDiscriminantAnalysis',\n",
        "                   'PassiveAggressiveClassifier', 'ExtraTreeClassifier', 'NearestCentroid', 'BernoulliNB'],\n",
        "        'accuracies': [0.97, 0.96, 0.95, 0.97, 0.96, 0.90, 0.93, 0.92, 0.91, 0.94, 0.93, 0.78, 0.82, 0.75, 0.77, 0.76, 0.79,\n",
        "                       0.72, 0.74, 0.74, 0.73, 0.71, 0.72, 0.70, 0.67, 0.65],\n",
        "        'time': [0.07, 0.02, 1.64, 4.15, 3.20, 2.61, 2.34, 1.89, 1.25, 0.40, 0.58, 0.04, 0.02, 0.32, 0.34, 0.32, 0.10, 0.05,\n",
        "                 0.04, 0.07, 0.03, 0.12, 0.18, 0.02, 0.09, 0.11],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create a combined plot for all datasets\n",
        "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Plot the accuracies for each dataset\n",
        "for idx, (dataset_name, result) in enumerate(datasets.items()):\n",
        "    accuracies = result['accuracies']\n",
        "    time = result['time']\n",
        "\n",
        "    # Only plot selected models\n",
        "    accuracies_selected = [accuracies[selected_models.index(model)] if model in result['models'] else None for model in selected_models]\n",
        "    time_selected = [time[selected_models.index(model)] if model in result['models'] else None for model in selected_models]\n",
        "\n",
        "    ax1.bar(np.arange(len(selected_models)) + (idx * 0.1), accuracies_selected, width=0.1, label=f\"Accuracy - {dataset_name}\")\n",
        "\n",
        "# Add labels and title\n",
        "ax1.set_xticks(np.arange(len(selected_models)))\n",
        "ax1.set_xticklabels(selected_models, rotation=90)\n",
        "ax1.set_ylabel('Test Accuracy')\n",
        "ax1.set_xlabel('Models')\n",
        "ax1.set_title('Model Comparison across Datasets')\n",
        "\n",
        "# Display the legend\n",
        "ax1.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MlmxGzU1MqdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot (these should match the models available in each dataset)\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.62, 0.61, 0.56, 0.63, 0.60, 0.52, 0.63],\n",
        "        'time': [1.66, 1.97, 1.55, 0.33, 0.14, 0.09, 6.17, 0.49, 0.02, 1.45],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.69, 0.68, 0.69, 0.67, 0.63, 0.61, 0.63, 0.63, 0.44, 0.69],\n",
        "        'time': [1.31, 4.64, 2.10, 0.31, 0.34, 0.09, 3.15, 0.05, 0.03, 1.50],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.97, 0.97, 0.96, 0.94, 0.81, 0.89, 0.86, 0.54, 0.49, 0.96],\n",
        "        'time': [2.98, 34.4, 9.66, 8.72, 32.57, 0.70, 13.10, 0.20, 0.09, 1.14],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.72, 0.76, 0.75, 0.73, 0.75, 0.67, 0.75, 0.68, 0.62, 0.79],\n",
        "        'time': [0.09, 0.22, 0.09, 0.05, 0.07, 0.09, 0.02, 0.32, 0.02, 1.03],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.63, 0.64, 0.65, 0.63, 0.58, 0.57, 0.63, 0.58, 0.59, 0.61],\n",
        "        'time': [0.35, 1.26, 0.20, 0.06, 0.05, 0.02, 0.21, 0.08, 0.01, 0.29],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Colors for each dataset\n",
        "colors = ['b', 'g', 'r', 'c', 'm']\n",
        "\n",
        "# Function to plot model comparison\n",
        "def plot_all_datasets(dataset_results):\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    for i, (dataset_name, result) in enumerate(dataset_results.items()):\n",
        "        accuracies_selected = [result['accuracies'][result['models'].index(model)] if model in result['models'] else None\n",
        "                               for model in selected_models]\n",
        "        time_selected = [result['time'][result['models'].index(model)] if model in result['models'] else None\n",
        "                         for model in selected_models]\n",
        "\n",
        "        # Plot accuracy as bar plots\n",
        "        ax1.bar(np.arange(len(selected_models)) + i * 0.15, accuracies_selected,\n",
        "                width=0.15, color=colors[i], alpha=0.6, label=f\"{dataset_name} Accuracy\")\n",
        "\n",
        "        # Plot training time as line plots\n",
        "        ax2.plot(np.arange(len(selected_models)) + i * 0.15, time_selected,\n",
        "                 marker='o', color=colors[i], label=f\"{dataset_name} Training Time\")\n",
        "\n",
        "    ax1.set_xlabel('Model')\n",
        "    ax1.set_ylabel('Test Accuracy')\n",
        "    ax2.set_ylabel('Training Time (s)')\n",
        "\n",
        "    ax1.set_xticks(np.arange(len(selected_models)))\n",
        "    ax1.set_xticklabels(selected_models, rotation=90)\n",
        "\n",
        "\n",
        "    ax1.legend(loc='upper left', bbox_to_anchor=(1.05, 1), title=\"Accuracy\")\n",
        "    ax2.legend(loc='lower left', bbox_to_anchor=(1.05, 0), title=\"Training Time\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot all datasets on one plot\n",
        "plot_all_datasets(datasets)"
      ],
      "metadata": {
        "id": "fH6YYftrM51y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot (these should match the models available in each dataset)\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.62, 0.61, 0.56, 0.63, 0.60, 0.52, 0.63],\n",
        "        'time': [1.66, 1.97, 1.55, 0.33, 0.14, 0.09, 6.17, 0.49, 0.02, 1.45],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.69, 0.68, 0.69, 0.67, 0.63, 0.61, 0.63, 0.63, 0.44, 0.69],\n",
        "        'time': [1.31, 4.64, 2.10, 0.31, 0.34, 0.09, 3.15, 0.05, 0.03, 1.50],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.97, 0.97, 0.96, 0.94, 0.81, 0.89, 0.86, 0.54, 0.49, 0.96],\n",
        "        'time': [2.98, 34.4, 9.66, 8.72, 32.57, 0.70, 13.10, 0.20, 0.09, 1.14],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.72, 0.76, 0.75, 0.73, 0.75, 0.67, 0.75, 0.68, 0.62, 0.79],\n",
        "        'time': [0.09, 0.22, 0.09, 0.05, 0.07, 0.09, 0.02, 0.32, 0.02, 1.03],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.63, 0.64, 0.65, 0.63, 0.58, 0.57, 0.63, 0.58, 0.59, 0.61],\n",
        "        'time': [0.35, 1.26, 0.20, 0.06, 0.05, 0.02, 0.21, 0.08, 0.01, 0.29],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Colorblind-friendly palette\n",
        "colors = ['#117733', '#44AA99', '#88CCEE', '#DDCC77', '#CC6677']\n",
        "\n",
        "# Function to plot model comparison\n",
        "def plot_all_datasets(dataset_results):\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    for i, (dataset_name, result) in enumerate(dataset_results.items()):\n",
        "        accuracies_selected = [result['accuracies'][result['models'].index(model)] if model in result['models'] else None\n",
        "                               for model in selected_models]\n",
        "        time_selected = [result['time'][result['models'].index(model)] if model in result['models'] else None\n",
        "                         for model in selected_models]\n",
        "\n",
        "        # Plot accuracy as translucent bar plots\n",
        "        ax1.bar(np.arange(len(selected_models)) + i * 0.15, accuracies_selected,\n",
        "                width=0.15, color=colors[i], alpha=0.8, label=f\"{dataset_name} Accuracy\")\n",
        "\n",
        "        # Plot training time as line plots\n",
        "        ax2.plot(np.arange(len(selected_models)) + i * 0.15, time_selected,\n",
        "                 marker='o', color=colors[i], label=f\"{dataset_name} Training Time\", linewidth=2)\n",
        "\n",
        "    ax1.set_xlabel('Model')\n",
        "    ax1.set_ylabel('Test Accuracy')\n",
        "    ax2.set_ylabel('Training Time (s)')\n",
        "\n",
        "    ax1.set_xticks(np.arange(len(selected_models)))\n",
        "    ax1.set_xticklabels(selected_models, rotation=90)\n",
        "\n",
        "    ax1.legend(loc='upper left', bbox_to_anchor=(1.05, 1), title=\"Accuracy\")\n",
        "    ax2.legend(loc='lower left', bbox_to_anchor=(1.05, 0), title=\"Training Time\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot all datasets on one plot\n",
        "plot_all_datasets(datasets)"
      ],
      "metadata": {
        "id": "sPQMlinrX3x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Selected models to plot (these should match the models available in each dataset)\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.62, 0.61, 0.56, 0.63, 0.60, 0.52, 0.63],\n",
        "        'time': [1.66, 1.97, 1.55, 0.33, 0.14, 0.09, 6.17, 0.49, 0.02, 1.45],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.69, 0.68, 0.69, 0.67, 0.63, 0.61, 0.63, 0.63, 0.44, 0.69],\n",
        "        'time': [1.31, 4.64, 2.10, 0.31, 0.34, 0.09, 3.15, 0.05, 0.03, 1.50],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.97, 0.97, 0.96, 0.94, 0.81, 0.89, 0.86, 0.54, 0.49, 0.96],\n",
        "        'time': [2.98, 34.4, 9.66, 8.72, 32.57, 0.70, 13.10, 0.20, 0.09, 1.14],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.72, 0.76, 0.75, 0.73, 0.75, 0.67, 0.75, 0.68, 0.62, 0.79],\n",
        "        'time': [0.09, 0.22, 0.09, 0.05, 0.07, 0.09, 0.02, 0.32, 0.02, 1.03],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.63, 0.64, 0.65, 0.63, 0.58, 0.57, 0.63, 0.58, 0.59, 0.61],\n",
        "        'time': [0.35, 1.26, 0.20, 0.06, 0.05, 0.02, 0.21, 0.08, 0.01, 0.29],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Use colorblind-friendly palette\n",
        "palette = sns.color_palette(\"colorblind\", len(datasets))\n",
        "\n",
        "# Plot the results\n",
        "def plot_model_performance(dataset_results):\n",
        "    fig, ax1 = plt.subplots(figsize=(14, 8))\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    for i, (dataset_name, result) in enumerate(dataset_results.items()):\n",
        "        accuracies = [result['accuracies'][result['models'].index(model)] for model in selected_models]\n",
        "        times = [result['time'][result['models'].index(model)] for model in selected_models]\n",
        "\n",
        "        # Plot accuracy\n",
        "        ax1.plot(selected_models, accuracies, marker='o', label=f\"{dataset_name} Accuracy\", color=palette[i])\n",
        "\n",
        "        # Plot training time\n",
        "        ax2.plot(selected_models, times, marker='x', linestyle='--', label=f\"{dataset_name} Training Time\", color=palette[i])\n",
        "\n",
        "    ax1.set_xlabel('Model', fontsize=16, weight='bold')\n",
        "    ax1.set_ylabel('Accuracy', fontsize=16 , weight='bold')\n",
        "    ax2.set_ylabel('Training Time (s)', fontsize=16 , weight='bold')\n",
        "\n",
        "    ax1.set_xticks(range(len(selected_models)))\n",
        "    ax1.set_xticklabels(selected_models, rotation=70, fontsize=16)\n",
        "\n",
        "    ax1.legend(loc='upper left', bbox_to_anchor=(1.05, 1), title=\"Accuracy\", fontsize=14)\n",
        "    ax2.legend(loc='lower left', bbox_to_anchor=(1.05, 0), title=\"Training Time\", fontsize=14)\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_model_performance(datasets)"
      ],
      "metadata": {
        "id": "MvubvZjYW1ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Selected models to plot (these should match the models available in each dataset)\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.62, 0.61, 0.56, 0.63, 0.60, 0.52, 0.63],\n",
        "        'time': [1.66, 1.97, 1.55, 0.33, 0.14, 0.09, 6.17, 0.49, 0.02, 1.45],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.69, 0.68, 0.69, 0.67, 0.63, 0.61, 0.63, 0.63, 0.44, 0.69],\n",
        "        'time': [1.31, 4.64, 2.10, 0.31, 0.34, 0.09, 3.15, 0.05, 0.03, 1.50],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.97, 0.97, 0.96, 0.94, 0.81, 0.89, 0.86, 0.54, 0.49, 0.96],\n",
        "        'time': [2.98, 34.4, 9.66, 8.72, 32.57, 0.70, 13.10, 0.20, 0.09, 1.14],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.72, 0.76, 0.75, 0.73, 0.75, 0.67, 0.75, 0.68, 0.62, 0.79],\n",
        "        'time': [0.09, 0.22, 0.09, 0.05, 0.07, 0.09, 0.02, 0.32, 0.02, 1.03],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.63, 0.64, 0.65, 0.63, 0.58, 0.57, 0.63, 0.58, 0.59, 0.61],\n",
        "        'time': [0.35, 1.26, 0.20, 0.06, 0.05, 0.02, 0.21, 0.08, 0.01, 0.29],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Use colorblind-friendly palette\n",
        "palette = sns.color_palette(\"colorblind\", len(datasets))\n",
        "\n",
        "# Plot the results\n",
        "def plot_model_performance(dataset_results):\n",
        "    fig, ax1 = plt.subplots(figsize=(14, 6))\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    # Plotting accuracy and training time for each dataset\n",
        "    for i, (dataset_name, result) in enumerate(dataset_results.items()):\n",
        "        accuracies = [result['accuracies'][result['models'].index(model)] for model in selected_models]\n",
        "        times = [result['time'][result['models'].index(model)] for model in selected_models]\n",
        "\n",
        "        # Plot accuracy with line style changes\n",
        "        ax1.plot(selected_models, accuracies, marker='o', label=f\"{dataset_name} Accuracy\", color=palette[i], linestyle='-')\n",
        "\n",
        "        # Plot training time with different line style and markers\n",
        "        ax2.plot(selected_models, times, marker='x', linestyle='--', label=f\"{dataset_name} Training Time\", color=palette[i])\n",
        "\n",
        "    # Set labels and title with increased font size for readability\n",
        "    ax1.set_xlabel('Model', fontsize=14, weight='bold')\n",
        "    ax1.set_ylabel('Accuracy', fontsize=14, weight='bold')\n",
        "    ax2.set_ylabel('Training Time (s)', fontsize=14, weight='bold')\n",
        "\n",
        "    ax1.set_xticks(range(len(selected_models)))\n",
        "    ax1.set_xticklabels(selected_models, rotation=45, fontsize=12)\n",
        "\n",
        "    # Adjust legend\n",
        "    ax1.legend(loc='upper left', bbox_to_anchor=(1.05, 1), title=\"Accuracy\", fontsize=12)\n",
        "    ax2.legend(loc='lower left', bbox_to_anchor=(1.05, 0), title=\"Training Time\", fontsize=12)\n",
        "\n",
        "    # Ensure tight layout so everything fits\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the model performance\n",
        "plot_model_performance(datasets)\n"
      ],
      "metadata": {
        "id": "-GrgqOFUpNzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selected models to plot (these should match the models available in each dataset)\n",
        "selected_models = [\n",
        "    'RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "    'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "    'GaussianNB', 'ExtraTreesClassifier'\n",
        "]\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.62, 0.61, 0.56, 0.63, 0.60, 0.52, 0.63],\n",
        "        'time': [1.66, 1.97, 1.55, 0.33, 0.14, 0.09, 6.17, 0.49, 0.02, 1.45],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.69, 0.68, 0.69, 0.67, 0.63, 0.61, 0.63, 0.63, 0.44, 0.69],\n",
        "        'time': [1.31, 4.64, 2.10, 0.31, 0.34, 0.09, 3.15, 0.05, 0.03, 1.50],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.97, 0.97, 0.96, 0.94, 0.81, 0.89, 0.86, 0.54, 0.49, 0.96],\n",
        "        'time': [2.98, 34.4, 9.66, 8.72, 32.57, 0.70, 13.10, 0.20, 0.09, 1.14],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.72, 0.76, 0.75, 0.73, 0.75, 0.67, 0.75, 0.68, 0.62, 0.79],\n",
        "        'time': [0.09, 0.22, 0.09, 0.05, 0.07, 0.09, 0.02, 0.32, 0.02, 1.03],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.63, 0.64, 0.65, 0.63, 0.58, 0.57, 0.63, 0.58, 0.59, 0.61],\n",
        "        'time': [0.35, 1.26, 0.20, 0.06, 0.05, 0.02, 0.21, 0.08, 0.01, 0.29],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Colorblind-friendly colors for each dataset\n",
        "colors = ['#D55E00', '#0072B2', '#F0E442', '#009E73', '#CC79A7']\n",
        "\n",
        "# Function to plot model comparison\n",
        "def plot_all_datasets(dataset_results):\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    for i, (dataset_name, result) in enumerate(dataset_results.items()):\n",
        "        accuracies_selected = [result['accuracies'][result['models'].index(model)] if model in result['models'] else None\n",
        "                               for model in selected_models]\n",
        "        time_selected = [result['time'][result['models'].index(model)] if model in result['models'] else None\n",
        "                         for model in selected_models]\n",
        "\n",
        "        # Plot accuracy as bar plots\n",
        "        ax1.bar(np.arange(len(selected_models)) + i * 0.15, accuracies_selected,\n",
        "                width=0.15, color=colors[i], alpha=0.8, label=f\"{dataset_name} Accuracy\")\n",
        "\n",
        "        # Plot training time as line plots\n",
        "        ax2.plot(np.arange(len(selected_models)) + i * 0.15, time_selected,\n",
        "                 marker='o', color=colors[i], linewidth=2, label=f\"{dataset_name} Training Time\")\n",
        "\n",
        "    ax1.set_xlabel('Model')\n",
        "    ax1.set_ylabel('Test Accuracy', fontsize=12)\n",
        "    ax2.set_ylabel('Training Time (s)', fontsize=12)\n",
        "\n",
        "    ax1.set_xticks(np.arange(len(selected_models)))\n",
        "    ax1.set_xticklabels(selected_models, rotation=45, ha='right')\n",
        "\n",
        "    ax1.legend(loc='upper left', bbox_to_anchor=(1.05, 1), title=\"Accuracy\")\n",
        "    ax2.legend(loc='lower left', bbox_to_anchor=(1.05, 0), title=\"Training Time\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot all datasets on one plot\n",
        "plot_all_datasets(datasets)"
      ],
      "metadata": {
        "id": "6hpVetDeYIKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.62, 0.61, 0.56, 0.63, 0.60, 0.52, 0.63],\n",
        "        'time': [1.66, 1.97, 1.55, 0.33, 0.14, 0.09, 6.17, 0.49, 0.02, 1.45],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.69, 0.68, 0.69, 0.67, 0.63, 0.61, 0.63, 0.63, 0.44, 0.69],\n",
        "        'time': [1.31, 4.64, 2.10, 0.31, 0.34, 0.09, 3.15, 0.05, 0.03, 1.50],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.97, 0.97, 0.96, 0.94, 0.81, 0.89, 0.86, 0.54, 0.49, 0.96],\n",
        "        'time': [2.98, 34.4, 9.66, 8.72, 32.57, 0.70, 13.10, 0.20, 0.09, 1.14],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.72, 0.76, 0.75, 0.73, 0.75, 0.67, 0.75, 0.68, 0.62, 0.79],\n",
        "        'time': [0.09, 0.22, 0.09, 0.05, 0.07, 0.09, 0.02, 0.32, 0.02, 1.03],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.63, 0.64, 0.65, 0.63, 0.58, 0.57, 0.63, 0.58, 0.59, 0.61],\n",
        "        'time': [0.35, 1.26, 0.20, 0.06, 0.05, 0.02, 0.21, 0.08, 0.01, 0.29],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Function to plot accuracy and training time side by side for each dataset\n",
        "def plot_accuracy_time_side_by_side(dataset_results):\n",
        "    fig, axes = plt.subplots(len(dataset_results), 2, figsize=(15, len(dataset_results) * 5))\n",
        "    fig.subplots_adjust(hspace=0.5)\n",
        "\n",
        "    for i, (dataset_name, result) in enumerate(dataset_results.items()):\n",
        "        models = result['models']\n",
        "        accuracies = result['accuracies']\n",
        "        time = result['time']\n",
        "\n",
        "        # Plot Accuracy\n",
        "        axes[i, 0].bar(models, accuracies, color='skyblue', alpha=0.8)\n",
        "        axes[i, 0].set_title(f\"{dataset_name} - Accuracy\")\n",
        "        axes[i, 0].set_ylabel('Accuracy')\n",
        "        axes[i, 0].set_xlabel('Models')\n",
        "        axes[i, 0].set_ylim(0, 1)\n",
        "        axes[i, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Plot Training Time\n",
        "        axes[i, 1].bar(models, time, color='orange', alpha=0.8)\n",
        "        axes[i, 1].set_title(f\"{dataset_name} - Training Time\")\n",
        "        axes[i, 1].set_ylabel('Training Time (s)')\n",
        "        axes[i, 1].set_xlabel('Models')\n",
        "        axes[i, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the datasets\n",
        "plot_accuracy_time_side_by_side(datasets)"
      ],
      "metadata": {
        "id": "i4qciHhARMO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Dataset results for each dataset\n",
        "datasets = {\n",
        "    'Dataset 1': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.65, 0.64, 0.64, 0.62, 0.61, 0.56, 0.63, 0.60, 0.52, 0.63],\n",
        "        'time': [1.66, 1.97, 1.55, 0.33, 0.14, 0.09, 6.17, 0.49, 0.02, 1.45],\n",
        "    },\n",
        "    'Dataset 2': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.69, 0.68, 0.69, 0.67, 0.63, 0.61, 0.63, 0.63, 0.44, 0.69],\n",
        "        'time': [1.31, 4.64, 2.10, 0.31, 0.34, 0.09, 3.15, 0.05, 0.03, 1.50],\n",
        "    },\n",
        "    'Dataset 3': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.97, 0.97, 0.96, 0.94, 0.81, 0.89, 0.86, 0.54, 0.49, 0.96],\n",
        "        'time': [2.98, 34.4, 9.66, 8.72, 32.57, 0.70, 13.10, 0.20, 0.09, 1.14],\n",
        "    },\n",
        "    'Dataset 4': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.72, 0.76, 0.75, 0.73, 0.75, 0.67, 0.75, 0.68, 0.62, 0.79],\n",
        "        'time': [0.09, 0.22, 0.09, 0.05, 0.07, 0.09, 0.02, 0.32, 0.02, 1.03],\n",
        "    },\n",
        "    'Dataset 5': {\n",
        "        'models': ['RandomForestClassifier', 'XGBClassifier', 'LGBMClassifier', 'KNeighborsClassifier',\n",
        "                   'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'AdaBoostClassifier',\n",
        "                   'GaussianNB', 'ExtraTreesClassifier'],\n",
        "        'accuracies': [0.63, 0.64, 0.65, 0.63, 0.58, 0.57, 0.63, 0.58, 0.59, 0.61],\n",
        "        'time': [0.35, 1.26, 0.20, 0.06, 0.05, 0.02, 0.21, 0.08, 0.01, 0.29],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Models are consistent across datasets\n",
        "models = list(datasets['Dataset 1']['models'])\n",
        "\n",
        "# Combine accuracies and training times across datasets\n",
        "accuracy_data = [datasets[ds]['accuracies'] for ds in datasets]\n",
        "time_data = [datasets[ds]['time'] for ds in datasets]\n",
        "dataset_names = list(datasets.keys())\n",
        "\n",
        "# Create grouped bar plots\n",
        "x = np.arange(len(models))  # Positions for the models\n",
        "width = 0.15  # Width of each bar\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(16, 12))\n",
        "\n",
        "# Accuracy plot\n",
        "for i, dataset_name in enumerate(dataset_names):\n",
        "    axes[0].bar(x + i * width, accuracy_data[i], width, label=dataset_name)\n",
        "axes[0].set_title('Model Accuracy Across Datasets', fontsize=16)\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[0].set_xticks(x + width * (len(dataset_names) - 1) / 2)\n",
        "axes[0].set_xticklabels(models, rotation=45, ha='right', fontsize=10)\n",
        "axes[0].set_ylim(0, 1)\n",
        "axes[0].legend(title='Datasets', fontsize=10)\n",
        "\n",
        "# Training time plot\n",
        "for i, dataset_name in enumerate(dataset_names):\n",
        "    axes[1].bar(x + i * width, time_data[i], width, label=dataset_name)\n",
        "axes[1].set_title('Training Time Across Datasets', fontsize=16)\n",
        "axes[1].set_ylabel('Training Time (s)', fontsize=12)\n",
        "axes[1].set_xticks(x + width * (len(dataset_names) - 1) / 2)\n",
        "axes[1].set_xticklabels(models, rotation=45, ha='right', fontsize=10)\n",
        "axes[1].legend(title='Datasets', fontsize=10)\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J7AVD1erRqOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKrKB7c3ScsU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}